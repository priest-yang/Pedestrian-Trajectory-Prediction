{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cur_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # Gets the current notebook directory\n",
    "src_dir = os.path.join(cur_dir, '../')  # Constructs the path to the 'src' directory\n",
    "# Add the 'src' directory to sys.path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.constant import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.MyDataset import MyDataset, save_dataset, load_dataset\n",
    "# from src.TFT_Flowmatching import TemporalFusionTransformerDiffusion\n",
    "\n",
    "from src.VQVAE import VQVAE\n",
    "from typing import Optional\n",
    "import pickle\n",
    "\n",
    "import torch.utils\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: direct load data from Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset('../data/.cache/train.pkl')\n",
    "test = load_dataset('../data/.cache/test.pkl')\n",
    "stats_dict = pickle.load(open('../data/.cache/stats_dict.pkl', 'rb'))\n",
    "feature_dim = stats_dict['feature_dim']\n",
    "features = stats_dict['features']\n",
    "\n",
    "lookback = 30\n",
    "future_steps = 40\n",
    "resample = False\n",
    "dir = '../data/Phase3/Modified/'\n",
    "ds = MyDataset(lookback=lookback)\n",
    "train_batch_size = 32\n",
    "test_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_data(df_dir : str, target_freq : int = 10):\n",
    "    df: pd.DataFrame = pd.read_pickle(df_dir)\n",
    "    df.columns = df.columns.str.strip() \n",
    "    \n",
    "    df = df.rename(columns={'State': 'state'})\n",
    "\n",
    "    states = ['At Station', 'Error', 'Wait', 'Cross', 'Approach Sidewalk',\n",
    "       'Approach Target Station', 'Move Along Sidewalk']\n",
    "\n",
    "    states_ohe = pd.get_dummies(df['state'], prefix='state')\n",
    "    cur_states = df['state'].unique()\n",
    "    for state in states:\n",
    "        if state not in cur_states:\n",
    "            states_ohe['state_'+state] = 0\n",
    "\n",
    "    df = pd.concat([df, states_ohe], axis=1)\n",
    "    df.drop(columns=['state'], inplace=True)\n",
    "    \n",
    "    df.dropna(inplace=True, how='any')\n",
    "    if resample:\n",
    "        f_per_sec = df.groupby('TimestampID').count().mean().mean()\n",
    "        if f_per_sec < target_freq:\n",
    "            raise ValueError('The frequency of the data is lower than the target frequency')\n",
    "        elif int(f_per_sec) == target_freq:\n",
    "            pass\n",
    "        else:\n",
    "            resample_ratio = int(f_per_sec/target_freq)\n",
    "            df = df.iloc[::resample_ratio, :]\n",
    "    # # for origin\n",
    "    for drop_column in ['Confidence', 'Timestamp', 'TimestampID', \n",
    "                          'DatapointID', 'PID', 'SCN', 'U_X', 'U_Y', 'U_Z', \n",
    "                          'AGV_Z', 'User_Z', 'GazeOrigin_Z', 'User_Pitch', 'User_Yaw', 'User_Roll', \n",
    "                          'EyeTarget', \n",
    "                          'start_station_X', 'start_station_Y', 'end_station_X', 'end_station_Y',\n",
    "                          'distance_from_start_station_X',\n",
    "                            'distance_from_start_station_Y', 'distance_from_end_station_X',\n",
    "                            'distance_from_end_station_Y', 'facing_start_station',\n",
    "                            'facing_end_station', \n",
    "                            'rolling_avg', \n",
    "                            'User', 'Type', \n",
    "                            'possible_interaction'\n",
    "                          ]:\n",
    "        df = df.drop(columns=[drop_column], errors='ignore')\n",
    "\n",
    "    target_columns = ['User_X', 'User_Y']\n",
    "    # Reorder columns\n",
    "    new_columns = target_columns + [col for col in df.columns if col not in target_columns]\n",
    "    df = df[new_columns]\n",
    "    \n",
    "    # keep numeric columns\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith('.pkl'):\n",
    "        df = process_data(dir+file)\n",
    "        ds.read_data(df, agv_col_name=\"scenario\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = process_data(dir+file)\n",
    "# df = df[df['scenario'] == 7]\n",
    "\n",
    "# uer_x, uer_y = df['User_X'].values[10:40], df['User_Y'].values[10:40]\n",
    "\n",
    "# plt.plot(uer_x, uer_y)\n",
    "# # same\n",
    "# plt.title('User Position')\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# # equal aspect ratio\n",
    "# plt.gca().set_aspect('equal', adjustable='box')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(ds.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns : Index(['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
      "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
      "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
      "       'intent_to_cross', 'Gazing_station', 'facing_along_sidewalk',\n",
      "       'facing_to_road', 'On_sidewalks', 'On_road', 'closest_station',\n",
      "       'distance_to_closest_station', 'distance_to_closest_station_X',\n",
      "       'distance_to_closest_station_Y', 'looking_at_AGV', 'GazeDirection_X',\n",
      "       'GazeDirection_Y', 'GazeDirection_Z', 'AGV_X', 'AGV_Y',\n",
      "       'looking_at_closest_station', 'data_active', 'scenario',\n",
      "       'state_Approach Sidewalk', 'state_Approach Target Station',\n",
      "       'state_At Station', 'state_Cross', 'state_Error',\n",
      "       'state_Move Along Sidewalk', 'state_Wait'],\n",
      "      dtype='object') \n",
      "feature_dim : 38\n"
     ]
    }
   ],
   "source": [
    "stats_dict = {'mean': 0, 'std': 0, 'min': 0, 'max': 0}\n",
    "stats_dict = ds.normalize_dataset()\n",
    "ds.generate_data(future_steps=future_steps)\n",
    "\n",
    "train:torch.utils.data.DataLoader\n",
    "test:torch.utils.data.DataLoader\n",
    "\n",
    "train, test = ds.split_data(frac=0.9, shuffle=True, train_batch_size=train_batch_size, test_batch_size=test_batch_size)\n",
    "\n",
    "feature_dim = ds.feature_dim\n",
    "stats_dict['feature_dim'] = feature_dim\n",
    "stats_dict['features'] = ds.dataset[0].columns\n",
    "columns = [_ for _ in ds.dataset[0].columns if _ not in ['AGV_name']]\n",
    "print(f\"columns : {df.columns} \\nfeature_dim : {feature_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "       'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "       'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "       'closest_station', 'distance_to_closest_station',\n",
    "       'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "       'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "       'GazeDirection_Z', 'AGV_X', 'AGV_Y', 'looking_at_closest_station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30, 38]) torch.Size([32, 40, 38])\n",
      "317856 70656\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train):\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "\n",
    "print(len(train) * train_batch_size, len(test) * test_batch_size)\n",
    "\n",
    "# # save it to cache to speed up\n",
    "# save_dataset(train, type='train', file_path='../data/.cache/train.pkl')\n",
    "# save_dataset(test, type='test', file_path='../data/.cache/test.pkl')\n",
    "# pickle.dump(stats_dict, open('../data/.cache/stats_dict.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from src.VQVAE import VQVAE\n",
    "import math\n",
    "\n",
    "###############################################\n",
    "# Original Blocks (with minor efficiency tweaks)\n",
    "###############################################\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=3, dropout_rate=0.1):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)]\n",
    "        )\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "        self.gate = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_input = x\n",
    "        for layer, norm in zip(self.layers, self.norms):\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "            x = norm(x)\n",
    "        gate = torch.sigmoid(self.gate(x))\n",
    "        x2 = self.fc2(x)\n",
    "        return self.fc3(x_input) + gate * x2\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout_rate)\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size * 4, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask: Optional[torch.Tensor] = None):\n",
    "        # x: (seq_len, batch, hidden_size)\n",
    "        x2 = x\n",
    "        x = self.norm1(x)\n",
    "        x, _ = self.attention(x, x, x, key_padding_mask=mask)\n",
    "        x = x + x2\n",
    "        x2 = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = x + x2\n",
    "        return x\n",
    "\n",
    "###############################################\n",
    "# Diffusion–based Decoder\n",
    "###############################################\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Computes a sinusoidal embedding for a scalar timestep.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SinusoidalTimeEmbedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        # t: Tensor of shape (batch,) or (batch, 1)\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.unsqueeze(1)  # (batch, 1)\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        # Compute constant\n",
    "        emb_factor = math.log(10000) / (half_dim - 1)\n",
    "        # Create a tensor of shape (half_dim,)\n",
    "        dims = torch.arange(half_dim, device=t.device, dtype=t.dtype)\n",
    "        # (batch, half_dim)\n",
    "        emb = t * torch.exp(-dims * emb_factor)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        # If embedding_dim is odd, pad an extra zero.\n",
    "        if self.embedding_dim % 2 == 1:\n",
    "            emb = F.pad(emb, (0, 1))\n",
    "        return emb  # (batch, embedding_dim)\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "\n",
    "def compute_flow_target(noise, y_batch, t):\n",
    "    \"\"\"\n",
    "    Compute the intermediate sample x_t and target velocity for flow-matching.\n",
    "    \n",
    "    Args:\n",
    "        noise: Tensor of shape (batch, num_action_steps, action_dim), noise sample\n",
    "        y_batch: Tensor of shape (batch, num_action_steps, action_dim), ground truth actions\n",
    "        t: Tensor of shape (batch, 1, 1), time steps\n",
    "    \n",
    "    Returns:\n",
    "        x_t: Intermediate sample at time t\n",
    "        v_target: Target velocity\n",
    "    \"\"\"\n",
    "    t = t.view(-1, 1, 1)  # Ensure t is [batch, 1, 1]\n",
    "    x_t = t * noise + (1 - t) * y_batch\n",
    "\n",
    "    v_target = noise - y_batch\n",
    "    return x_t, v_target\n",
    "\n",
    "class DiffusionDecoder(nn.Module):\n",
    "    def __init__(self, action_dim, conditioning_dim, num_diffusion_steps=10,\n",
    "                 num_action_steps=20, hidden_dim=128, num_layers=2, noise_weight=1, num_heads=4, ):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dim\n",
    "        self.num_diffusion_steps = num_diffusion_steps  # Number of integration steps\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_action_steps = num_action_steps\n",
    "        self.noise_weight = noise_weight\n",
    "\n",
    "        self.time_embed = SinusoidalTimeEmbedding(hidden_dim)\n",
    "        self.time_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "\n",
    "        input_dim = hidden_dim + hidden_dim + num_action_steps * action_dim\n",
    "\n",
    "        # # Output processing\n",
    "        # self.output_proj = nn.Sequential(\n",
    "        #     nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "        #     nn.LayerNorm(hidden_dim * 2),\n",
    "        #     nn.SiLU(),\n",
    "        #     nn.Linear(hidden_dim * 2, num_action_steps * action_dim)\n",
    "        # )\n",
    "\n",
    "        # Build a deeper network with LayerNorm and residual connections\n",
    "        self.fc1 = nn.Linear(input_dim, 512)\n",
    "        self.ln1 = nn.LayerNorm(512)\n",
    "        \n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.ln2 = nn.LayerNorm(512)\n",
    "        \n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.ln3 = nn.LayerNorm(512)\n",
    "        \n",
    "        self.fc_out = nn.Linear(512, num_action_steps * action_dim)\n",
    "\n",
    "        # Final output projection\n",
    "        self.out = nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "        # self.gate = nn.Linear(conditioning_dim, action_dim * num_action_steps)\n",
    "        # self.fc_direct = nn.Linear(num_action_steps * action_dim, num_action_steps * action_dim)\n",
    "\n",
    "    def forward(self, conditioning, x_t, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, hidden_dim)\n",
    "            x_t: Tensor of shape (batch, num_action_steps, action_dim)\n",
    "            t: Tensor of shape (batch,) with time values in [0,1]\n",
    "        \"\"\"\n",
    "        # Time embedding\n",
    "        t_emb = self.time_embed(t)  # [batch, hidden_dim]\n",
    "\n",
    "        x_t = x_t.view(x_t.size(0), -1)  # Flatten the last two dimensions\n",
    "        x_with_time = torch.cat([x_t, t_emb], dim=-1)  # [batch, hidden_dim + cond_dim]\n",
    "\n",
    "        conditioning = torch.mean(conditioning, dim=1)  # [batch, hidden_dim]\n",
    "        x_proj = torch.cat([x_with_time, conditioning], dim=-1)  # [batch, hidden_dim + cond_dim]\n",
    "\n",
    "        # Pass through the network with normalization and residual connections\n",
    "        x = F.relu(self.ln1(self.fc1(x_proj)))\n",
    "        residual = x\n",
    "        x = F.relu(self.ln2(self.fc2(x)) + residual)\n",
    "        residual = x\n",
    "        x = F.relu(self.ln3(self.fc3(x)) + residual)\n",
    "        h = self.fc_out(x)\n",
    "\n",
    "        # gate = torch.sigmoid(self.gate(conditioning))\n",
    "        # h = h * gate + self.fc_direct(x_t)\n",
    "        \n",
    "        h = h.view(h.size(0), self.num_action_steps, self.action_dim)  # Reshape to [batch, num_action_steps, action_dim]\n",
    "        \n",
    "        \n",
    "        return h  # [batch, num_action_steps, action_dim]\n",
    "\n",
    "    def decoder_train_step(self, conditioning, y_batch, device):\n",
    "        \"\"\"\n",
    "        Performs one training step for the flow-matching decoder.\n",
    "        \n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "            y_batch: Ground truth trajectory (batch, num_action_steps, action_dim)\n",
    "            device: torch.device\n",
    "        \n",
    "        Returns:\n",
    "            loss: The MSE loss between predicted and target velocity\n",
    "        \"\"\"\n",
    "        batch_size = y_batch.size(0)\n",
    "        # Sample t uniformly from [0,1]\n",
    "        t = torch.rand(batch_size, device=device)  # [batch]\n",
    "        t = t.unsqueeze(1).unsqueeze(2)  # [batch, 1, 1]\n",
    "        \n",
    "        # Sample noise\n",
    "        noise = torch.randn_like(y_batch) * self.noise_weight\n",
    "        \n",
    "        # Compute x_t and v_target\n",
    "        x_t, v_target = compute_flow_target(noise, y_batch, t)\n",
    "        \n",
    "        # Predict velocity\n",
    "        v_pred = self.forward(conditioning, x_t, t.squeeze(2).squeeze(1))  # t: [batch]\n",
    "        \n",
    "        # MSE loss\n",
    "        loss = F.mse_loss(v_pred, v_target, reduce=False)\n",
    "        loss = loss.mean(dim=[1, 2])  # Sum over action steps and dimensions\n",
    "        return loss\n",
    "    \n",
    "    def influence(self, conditioning, device):\n",
    "        \"\"\"\n",
    "        Runs the flow-matching integration process and returns a list of intermediate trajectories.\n",
    "        \n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "            device: torch.device\n",
    "        \n",
    "        Returns:\n",
    "            intermediates: A list of tensors, each of shape (batch, num_action_steps, action_dim),\n",
    "                           representing the trajectory at each integration step\n",
    "        \"\"\"\n",
    "        batch_size = conditioning.size(0)\n",
    "        x = torch.randn(batch_size, self.num_action_steps, self.action_dim, device=device) * self.noise_weight\n",
    "        intermediates = []\n",
    "        dt = -1.0 / self.num_diffusion_steps  # Negative dt for backward integration\n",
    "        for i in range(self.num_diffusion_steps):\n",
    "            t = 1.0 + i * dt  # t decreases from 1.0 to almost 0\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.float)\n",
    "            v_pred = self.forward(conditioning, x, t_tensor)\n",
    "            x = x + v_pred * dt  # Since dt < 0, moves x towards data\n",
    "            intermediates.append(x.clone())\n",
    "        return intermediates\n",
    "    \n",
    "###############################################\n",
    "# Modified Temporal Fusion Transformer with Diffusion Decoder\n",
    "###############################################\n",
    "\n",
    "class TemporalFusionTransformerDiffusion(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_outputs, num_steps, his_steps = 15, \n",
    "                 num_attention_heads=8, diffusion_steps=10, vqvae: VQVAE = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_features (int): Number of input features.\n",
    "            num_hidden (int): Hidden dimension size.\n",
    "            num_outputs (int): Dimensionality of each output (e.g. action dimension).\n",
    "            num_steps (int): Desired output sequence length (e.g. number of action steps).\n",
    "            num_attention_heads (int): Number of heads for the transformer blocks.\n",
    "            diffusion_steps (int): Number of diffusion (denoising) steps.\n",
    "        \"\"\"\n",
    "        super(TemporalFusionTransformerDiffusion, self).__init__()\n",
    "        if vqvae is None:\n",
    "            self.vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "        else:\n",
    "            self.vqvae = vqvae\n",
    "        num_features = num_features + self.vqvae.encoder.fc2.out_features\n",
    "        self.encoder_grn = GatedResidualNetwork(num_features, num_hidden, num_hidden)\n",
    "        self.transformer_block = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        self.transformer_block2 = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        \n",
    "        self.his_steps = his_steps\n",
    "        # To condition the diffusion process we project the transformer output.\n",
    "        self.condition_proj = nn.Linear(num_hidden, num_hidden)\n",
    "        # Diffusion decoder: we set action_dim=num_outputs and produce a sequence of length num_steps.\n",
    "        self.diffusion_decoder = DiffusionDecoder(\n",
    "            action_dim=num_outputs,\n",
    "            conditioning_dim=num_hidden,\n",
    "            num_diffusion_steps=diffusion_steps,\n",
    "            num_action_steps=num_steps,\n",
    "            num_heads=num_attention_heads,  \n",
    "            hidden_dim=num_hidden, \n",
    "            num_layers=2,  # you can adjust as needed\n",
    "            noise_weight=0.5  # you can adjust as needed\n",
    "        )\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        self.his_steps = his_steps\n",
    "\n",
    "        self.stationary_branch = nn.Sequential(\n",
    "            nn.Linear(his_steps * num_outputs, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y_batch=None , mask: Optional[torch.Tensor] = None, influence=False, return_all=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, seq_len, num_features).\n",
    "            mask: Optional attention mask for the transformer blocks.\n",
    "            \n",
    "        Returns:\n",
    "            actions: Tensor of shape (batch, num_steps, num_outputs)\n",
    "        \"\"\"\n",
    "        # If given a 2D input, add a batch dimension.\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Stationary branch\n",
    "        if self.his_steps != x.shape[1]:\n",
    "            print(f\"his_steps : {self.his_steps} != x.shape[1] : {x.shape[1]}\")\n",
    "            print(f\"Reset his_steps to x.shape[1]\")\n",
    "            self.his_steps = x.shape[1]\n",
    "            self.stationary_branch = nn.Sequential(\n",
    "                nn.Linear(self.his_steps * self.num_outputs, self.num_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.num_hidden, self.num_hidden // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.num_hidden // 2, 1)\n",
    "            )\n",
    "        # hist traj\n",
    "        hist_traj = x[:, -self.his_steps:, :self.num_outputs].reshape(batch_size, -1)\n",
    "        stationary = self.stationary_branch(hist_traj)\n",
    "        stationary = torch.sigmoid(stationary)\n",
    "\n",
    "\n",
    "\n",
    "        # VQ-VAE\n",
    "        x_recon, vq_loss, perplexity, embedding = self.vqvae(x)\n",
    "        x = torch.cat((x, embedding), dim=-1)\n",
    "        \n",
    "        # Encoder GRN.\n",
    "        x = self.encoder_grn(x)  # (batch, seq_len, num_hidden)\n",
    "        \n",
    "        # Transformer expects (seq_len, batch, hidden_size).\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer_block(x, mask=mask)\n",
    "        x = self.transformer_block2(x, mask=mask)\n",
    "        x = x.permute(1, 0, 2)  # back to (batch, seq_len, num_hidden)\n",
    "        \n",
    "        # Use a summary of the encoder output as conditioning.\n",
    "        # Here we use the last time–step (you might also try an average or more complex pooling).\n",
    "\n",
    "        # attention\n",
    "        # attention_weights = torch.softmax(torch.mean(x, dim=-1), dim=1).unsqueeze(-1)\n",
    "        # pooled_output = torch.sum(attention_weights * x, dim=1, keepdim=True)\n",
    "\n",
    "        # conditioning = self.condition_proj(pooled_output)  # (batch, 1, num_hidden)\n",
    "        conditioning = x[:, -1:, :] #self.condition_proj()  # (batch, 1, num_hidden)\n",
    "        # conditioning = self.condition_proj(x[:, :, :])  # (batch, 1, num_hidden)\n",
    "\n",
    "        # flow matching during training\n",
    "        self.device = next(self.parameters()).device\n",
    "        \n",
    "        if influence:\n",
    "            stationary = torch.where(stationary > 0.5, 1.0, 0.0).to(self.device)\n",
    "            # match size\n",
    "            stationary = stationary.unsqueeze(1).expand(-1, self.num_steps, self.num_outputs)\n",
    "            \n",
    "            if return_all:\n",
    "                return [traj * stationary for traj in self.diffusion_decoder.influence(conditioning, self.device)]\n",
    "            return self.diffusion_decoder.influence(conditioning, self.device)[-1] * stationary\n",
    "        else:\n",
    "            if self.training:\n",
    "                max_displace = torch.max(y_batch, dim=1).values - torch.min(y_batch, dim=1).values\n",
    "                max_displace = torch.linalg.norm(max_displace, dim=1)\n",
    "                stationary_gt = torch.where(max_displace > 5e-4, 1.0, 0.0).to(self.device)\n",
    "                stationary_loss = F.binary_cross_entropy(stationary.squeeze(1), stationary_gt)\n",
    "                diff_loss = self.diffusion_decoder.decoder_train_step(conditioning, y_batch, self.device)\n",
    "                diff_loss = diff_loss * stationary_gt.detach()\n",
    "                diff_loss = diff_loss.mean()\n",
    "                return diff_loss, vq_loss, stationary_loss\n",
    "            \n",
    "\n",
    "    def influence(self, x):\n",
    "        User_trajectory = self.forward(x, influence=True)\n",
    "        return User_trajectory\n",
    "\n",
    "\n",
    "# class DecayLoss(nn.Module):\n",
    "#     def __init__(self, num_steps, baseline_loss_fn=nn.L1Loss()):\n",
    "#         super(DecayLoss, self).__init__()\n",
    "#         # Weight decreases as we move further into the future\n",
    "#         self.weights = torch.linspace(1.0, 1.0, num_steps)\n",
    "#         self.baseline_loss_fn = baseline_loss_fn\n",
    "        \n",
    "\n",
    "#     def forward(self, predictions, targets):\n",
    "#         loss = 0\n",
    "#         for i in range(predictions.shape[1]):\n",
    "#             loss += self.weights[i] * self.baseline_loss_fn(predictions[:, i], targets[:, i])\n",
    "#         return loss\n",
    "    \n",
    "    \n",
    "# baseline_loss_fn = nn.L1Loss() #nn.MSELoss()\n",
    "# loss_fn = DecayLoss(future_steps, baseline_loss_fn=baseline_loss_fn)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using {device}\")\n",
    "\n",
    "# vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "# model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps, diffusion_steps=10, vqvae=vqvae)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# model.to(device)\n",
    "\n",
    "# X_batch, y_batch = next(iter(train))\n",
    "# X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "# model(X_batch, y_batch[:, :future_steps, :2], influence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalFusionTransformerDiffusion(\n",
       "  (vqvae): VQVAE(\n",
       "    (encoder): VQVAEEncoder(\n",
       "      (fc1): Linear(in_features=38, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "    (quantizer): VectorQuantizer(\n",
       "      (embedding): Embedding(128, 128)\n",
       "    )\n",
       "    (decoder): VQVAEDecoder(\n",
       "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=38, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_grn): GatedResidualNetwork(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=166, out_features=128, bias=True)\n",
       "      (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-2): 3 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=166, out_features=128, bias=True)\n",
       "    (gate): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (transformer_block): TransformerBlock(\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer_block2): TransformerBlock(\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (condition_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (diffusion_decoder): DiffusionDecoder(\n",
       "    (time_embed): SinusoidalTimeEmbedding()\n",
       "    (time_proj): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (fc1): Linear(in_features=296, out_features=512, bias=True)\n",
       "    (ln1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (ln2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (fc3): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (ln3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "    (fc_out): Linear(in_features=512, out_features=40, bias=True)\n",
       "    (out): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       "  (stationary_branch): Sequential(\n",
       "    (0): AdaptiveAvgPool1d(output_size=32)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=64, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecayLoss(nn.Module):\n",
    "    def __init__(self, num_steps, baseline_loss_fn=nn.L1Loss()):\n",
    "        super(DecayLoss, self).__init__()\n",
    "        # Weight decreases as we move further into the future\n",
    "        self.weights = torch.linspace(1.0, 1.0, num_steps)\n",
    "        self.baseline_loss_fn = baseline_loss_fn\n",
    "        \n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        loss = 0\n",
    "        for i in range(predictions.shape[1]):\n",
    "            loss += self.weights[i] * self.baseline_loss_fn(predictions[:, i], targets[:, i])\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "baseline_loss_fn = nn.L1Loss() #nn.MSELoss()\n",
    "loss_fn = DecayLoss(future_steps, baseline_loss_fn=baseline_loss_fn)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps // 2, diffusion_steps=10, vqvae=vqvae)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer with early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at ../model/TFT_Flowmatching/Feb25_17-19-35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed220f792d1461ebbd8602bfcad2255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 500, Loss: 0.717768, VQ Loss: 0.010135, Stationary Loss: 0.062760, Diff Loss: 0.080028, learning rate: 5.00e-05\n",
      "Epoch 1, Step 1000, Loss: 0.603154, VQ Loss: 0.005160, Stationary Loss: 0.055602, Diff Loss: 0.041971, learning rate: 5.00e-05\n",
      "Epoch 1, Step 1500, Loss: 0.509556, VQ Loss: 0.004012, Stationary Loss: 0.047761, Diff Loss: 0.027930, learning rate: 5.00e-05\n",
      "Epoch 1, Step 2000, Loss: 0.471963, VQ Loss: 0.003417, Stationary Loss: 0.044614, Diff Loss: 0.022408, learning rate: 5.00e-05\n",
      "Steps 2000: test RMSE 0.8523, moving average RMSE 0.8523, learning rate 5.00e-05\n",
      "Epoch 1, Step 2500, Loss: 0.421412, VQ Loss: 0.003029, Stationary Loss: 0.039854, Diff Loss: 0.019846, learning rate: 5.00e-05\n",
      "Epoch 1, Step 3000, Loss: 0.404717, VQ Loss: 0.002788, Stationary Loss: 0.038301, Diff Loss: 0.018917, learning rate: 5.00e-05\n",
      "Epoch 1, Step 3500, Loss: 0.361223, VQ Loss: 0.002540, Stationary Loss: 0.034193, Diff Loss: 0.016752, learning rate: 5.00e-05\n",
      "Epoch 1, Step 4000, Loss: 0.357737, VQ Loss: 0.002280, Stationary Loss: 0.034108, Diff Loss: 0.014374, learning rate: 5.00e-05\n",
      "Steps 4000: test RMSE 0.6046, moving average RMSE 0.7037, learning rate 5.00e-05\n",
      "Epoch 1, Step 4500, Loss: 0.376087, VQ Loss: 0.002133, Stationary Loss: 0.036077, Diff Loss: 0.013187, learning rate: 5.00e-05\n",
      "Epoch 1, Step 5000, Loss: 0.349444, VQ Loss: 0.002084, Stationary Loss: 0.033454, Diff Loss: 0.012821, learning rate: 5.00e-05\n",
      "Epoch 1, Step 5500, Loss: 0.356399, VQ Loss: 0.001923, Stationary Loss: 0.034221, Diff Loss: 0.012263, learning rate: 5.00e-05\n",
      "Epoch 1, Step 6000, Loss: 0.344339, VQ Loss: 0.001823, Stationary Loss: 0.032957, Diff Loss: 0.012947, learning rate: 5.00e-05\n",
      "Steps 6000: test RMSE 0.5266, moving average RMSE 0.5975, learning rate 5.00e-05\n",
      "Epoch 1, Step 6500, Loss: 0.378885, VQ Loss: 0.001743, Stationary Loss: 0.036532, Diff Loss: 0.011822, learning rate: 5.00e-05\n",
      "Epoch 1, Step 7000, Loss: 0.362167, VQ Loss: 0.001667, Stationary Loss: 0.035011, Diff Loss: 0.010386, learning rate: 5.00e-05\n",
      "Epoch 1, Step 7500, Loss: 0.352224, VQ Loss: 0.001582, Stationary Loss: 0.033974, Diff Loss: 0.010900, learning rate: 5.00e-05\n",
      "Epoch 1, Step 8000, Loss: 0.353992, VQ Loss: 0.001550, Stationary Loss: 0.034086, Diff Loss: 0.011581, learning rate: 5.00e-05\n",
      "Steps 8000: test RMSE 0.5001, moving average RMSE 0.5390, learning rate 5.00e-05\n",
      "Epoch 1, Step 8500, Loss: 0.345496, VQ Loss: 0.001487, Stationary Loss: 0.033372, Diff Loss: 0.010290, learning rate: 5.00e-05\n",
      "Epoch 1, Step 9000, Loss: 0.341615, VQ Loss: 0.001432, Stationary Loss: 0.032937, Diff Loss: 0.010818, learning rate: 5.00e-05\n",
      "Epoch 1, Step 9500, Loss: 0.344602, VQ Loss: 0.001340, Stationary Loss: 0.033632, Diff Loss: 0.006944, learning rate: 1.00e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9218e01bee4eeda7b26e8af7e1a6f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 67, Loss: 0.332764, VQ Loss: 0.001302, Stationary Loss: 0.032374, Diff Loss: 0.007723, learning rate: 1.00e-05\n",
      "Model saved at ../model/TFT_Flowmatching/Feb25_17-19-35/model_10000.pt\n",
      "Steps 10000: test RMSE 0.4627, moving average RMSE 0.4932, learning rate 1.00e-05\n",
      "Epoch 2, Step 567, Loss: 0.324458, VQ Loss: 0.001279, Stationary Loss: 0.031544, Diff Loss: 0.007738, learning rate: 1.00e-05\n",
      "Epoch 2, Step 1067, Loss: 0.331703, VQ Loss: 0.001252, Stationary Loss: 0.032361, Diff Loss: 0.006836, learning rate: 1.00e-05\n",
      "Epoch 2, Step 1567, Loss: 0.330070, VQ Loss: 0.001242, Stationary Loss: 0.032158, Diff Loss: 0.007249, learning rate: 1.00e-05\n",
      "Epoch 2, Step 2067, Loss: 0.337624, VQ Loss: 0.001258, Stationary Loss: 0.032984, Diff Loss: 0.006529, learning rate: 1.00e-05\n",
      "Steps 12000: test RMSE 0.4558, moving average RMSE 0.4708, learning rate 1.00e-05\n",
      "Epoch 2, Step 2567, Loss: 0.334036, VQ Loss: 0.001231, Stationary Loss: 0.032627, Diff Loss: 0.006534, learning rate: 1.00e-05\n",
      "Epoch 2, Step 3067, Loss: 0.330524, VQ Loss: 0.001228, Stationary Loss: 0.032308, Diff Loss: 0.006220, learning rate: 2.00e-06\n",
      "Epoch 2, Step 3567, Loss: 0.318051, VQ Loss: 0.001229, Stationary Loss: 0.031064, Diff Loss: 0.006182, learning rate: 2.00e-06\n",
      "Epoch 2, Step 4067, Loss: 0.340447, VQ Loss: 0.001202, Stationary Loss: 0.033301, Diff Loss: 0.006238, learning rate: 2.00e-06\n",
      "Steps 14000: test RMSE 0.4515, moving average RMSE 0.4592, learning rate 2.00e-06\n",
      "Epoch 2, Step 4567, Loss: 0.345088, VQ Loss: 0.001195, Stationary Loss: 0.033805, Diff Loss: 0.005844, learning rate: 2.00e-06\n",
      "Epoch 2, Step 5067, Loss: 0.345701, VQ Loss: 0.001199, Stationary Loss: 0.033882, Diff Loss: 0.005686, learning rate: 2.00e-06\n",
      "Epoch 2, Step 5567, Loss: 0.335364, VQ Loss: 0.001220, Stationary Loss: 0.032789, Diff Loss: 0.006255, learning rate: 2.00e-06\n",
      "Epoch 2, Step 6067, Loss: 0.322428, VQ Loss: 0.001216, Stationary Loss: 0.031521, Diff Loss: 0.006002, learning rate: 4.00e-07\n",
      "Steps 16000: test RMSE 0.4471, moving average RMSE 0.4519, learning rate 4.00e-07\n",
      "Epoch 2, Step 6567, Loss: 0.329901, VQ Loss: 0.001183, Stationary Loss: 0.032307, Diff Loss: 0.005646, learning rate: 4.00e-07\n",
      "Epoch 2, Step 7067, Loss: 0.329868, VQ Loss: 0.001194, Stationary Loss: 0.032276, Diff Loss: 0.005918, learning rate: 4.00e-07\n",
      "Epoch 2, Step 7567, Loss: 0.334958, VQ Loss: 0.001199, Stationary Loss: 0.032806, Diff Loss: 0.005698, learning rate: 4.00e-07\n",
      "Epoch 2, Step 8067, Loss: 0.341635, VQ Loss: 0.001184, Stationary Loss: 0.033519, Diff Loss: 0.005258, learning rate: 4.00e-07\n",
      "Steps 18000: test RMSE 0.4441, moving average RMSE 0.4472, learning rate 4.00e-07\n",
      "Epoch 2, Step 8567, Loss: 0.329838, VQ Loss: 0.001229, Stationary Loss: 0.032318, Diff Loss: 0.005430, learning rate: 4.00e-07\n",
      "Epoch 2, Step 9067, Loss: 0.329200, VQ Loss: 0.001195, Stationary Loss: 0.032225, Diff Loss: 0.005758, learning rate: 8.00e-08\n",
      "Epoch 2, Step 9567, Loss: 0.329708, VQ Loss: 0.001221, Stationary Loss: 0.032208, Diff Loss: 0.006402, learning rate: 8.00e-08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a3ec802b303433bb366a1de960cc398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 134, Loss: 0.347945, VQ Loss: 0.001187, Stationary Loss: 0.034076, Diff Loss: 0.005999, learning rate: 8.00e-08\n",
      "Model saved at ../model/TFT_Flowmatching/Feb25_17-19-35/model_20000.pt\n",
      "Steps 20000: test RMSE 0.4442, moving average RMSE 0.4454, learning rate 8.00e-08\n",
      "Epoch 3, Step 634, Loss: 0.325130, VQ Loss: 0.001186, Stationary Loss: 0.031700, Diff Loss: 0.006940, learning rate: 8.00e-08\n",
      "Epoch 3, Step 1134, Loss: 0.324678, VQ Loss: 0.001196, Stationary Loss: 0.031733, Diff Loss: 0.006156, learning rate: 8.00e-08\n",
      "Epoch 3, Step 1634, Loss: 0.319484, VQ Loss: 0.001223, Stationary Loss: 0.031228, Diff Loss: 0.005978, learning rate: 8.00e-08\n",
      "Epoch 3, Step 2134, Loss: 0.336213, VQ Loss: 0.001196, Stationary Loss: 0.032895, Diff Loss: 0.006063, learning rate: 1.60e-08\n",
      "Steps 22000: test RMSE 0.4444, moving average RMSE 0.4448, learning rate 1.60e-08\n",
      "Epoch 3, Step 2634, Loss: 0.339840, VQ Loss: 0.001201, Stationary Loss: 0.033318, Diff Loss: 0.005461, learning rate: 1.60e-08\n",
      "Epoch 3, Step 3134, Loss: 0.381748, VQ Loss: 0.001185, Stationary Loss: 0.037471, Diff Loss: 0.005850, learning rate: 1.60e-08\n",
      "Epoch 3, Step 3634, Loss: 0.340335, VQ Loss: 0.001192, Stationary Loss: 0.033250, Diff Loss: 0.006639, learning rate: 1.60e-08\n",
      "Epoch 3, Step 4134, Loss: 0.327065, VQ Loss: 0.001193, Stationary Loss: 0.031975, Diff Loss: 0.006117, learning rate: 1.60e-08\n",
      "Steps 24000: test RMSE 0.4434, moving average RMSE 0.4440, learning rate 1.60e-08\n",
      "Epoch 3, Step 4634, Loss: 0.323757, VQ Loss: 0.001194, Stationary Loss: 0.031539, Diff Loss: 0.007176, learning rate: 1.60e-08\n",
      "Epoch 3, Step 5134, Loss: 0.324504, VQ Loss: 0.001196, Stationary Loss: 0.031756, Diff Loss: 0.005746, learning rate: 1.60e-08\n",
      "Epoch 3, Step 5634, Loss: 0.324542, VQ Loss: 0.001220, Stationary Loss: 0.031724, Diff Loss: 0.006078, learning rate: 1.60e-08\n",
      "Epoch 3, Step 6134, Loss: 0.327471, VQ Loss: 0.001205, Stationary Loss: 0.032016, Diff Loss: 0.006104, learning rate: 1.60e-08\n",
      "Steps 26000: test RMSE 0.4434, moving average RMSE 0.4436, learning rate 1.60e-08\n",
      "Epoch 3, Step 6634, Loss: 0.336992, VQ Loss: 0.001195, Stationary Loss: 0.032981, Diff Loss: 0.005988, learning rate: 1.60e-08\n",
      "Epoch 3, Step 7134, Loss: 0.336414, VQ Loss: 0.001186, Stationary Loss: 0.032957, Diff Loss: 0.005659, learning rate: 1.60e-08\n",
      "Epoch 3, Step 7634, Loss: 0.331451, VQ Loss: 0.001197, Stationary Loss: 0.032458, Diff Loss: 0.005675, learning rate: 1.60e-08\n",
      "Epoch 3, Step 8134, Loss: 0.324966, VQ Loss: 0.001202, Stationary Loss: 0.031703, Diff Loss: 0.006730, learning rate: 1.60e-08\n",
      "Steps 28000: test RMSE 0.4447, moving average RMSE 0.4443, learning rate 1.60e-08\n",
      "Epoch 3, Step 8634, Loss: 0.326222, VQ Loss: 0.001193, Stationary Loss: 0.031939, Diff Loss: 0.005636, learning rate: 1.60e-08\n",
      "Epoch 3, Step 9134, Loss: 0.319261, VQ Loss: 0.001191, Stationary Loss: 0.031211, Diff Loss: 0.005965, learning rate: 1.60e-08\n",
      "Epoch 3, Step 9634, Loss: 0.322444, VQ Loss: 0.001212, Stationary Loss: 0.031519, Diff Loss: 0.006041, learning rate: 1.60e-08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c4722b4ecb4802831f567f85a786af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 201, Loss: 0.327055, VQ Loss: 0.001185, Stationary Loss: 0.032035, Diff Loss: 0.005521, learning rate: 1.60e-08\n",
      "Model saved at ../model/TFT_Flowmatching/Feb25_17-19-35/model_30000.pt\n",
      "Steps 30000: test RMSE 0.4443, moving average RMSE 0.4443, learning rate 1.60e-08\n",
      "Epoch 4, Step 701, Loss: 0.335595, VQ Loss: 0.001180, Stationary Loss: 0.032921, Diff Loss: 0.005203, learning rate: 1.60e-08\n",
      "Epoch 4, Step 1201, Loss: 0.333514, VQ Loss: 0.001176, Stationary Loss: 0.032617, Diff Loss: 0.006165, learning rate: 1.60e-08\n",
      "Epoch 4, Step 1701, Loss: 0.331587, VQ Loss: 0.001194, Stationary Loss: 0.032475, Diff Loss: 0.005646, learning rate: 1.60e-08\n",
      "Epoch 4, Step 2201, Loss: 0.325789, VQ Loss: 0.001208, Stationary Loss: 0.031842, Diff Loss: 0.006160, learning rate: 1.60e-08\n",
      "Steps 32000: test RMSE 0.4431, moving average RMSE 0.4436, learning rate 1.60e-08\n",
      "Epoch 4, Step 2701, Loss: 0.313640, VQ Loss: 0.001200, Stationary Loss: 0.030645, Diff Loss: 0.005987, learning rate: 1.60e-08\n",
      "Epoch 4, Step 3201, Loss: 0.342874, VQ Loss: 0.001188, Stationary Loss: 0.033550, Diff Loss: 0.006183, learning rate: 1.60e-08\n",
      "Epoch 4, Step 3701, Loss: 0.333061, VQ Loss: 0.001206, Stationary Loss: 0.032681, Diff Loss: 0.005050, learning rate: 1.60e-08\n",
      "Epoch 4, Step 4201, Loss: 0.335579, VQ Loss: 0.001178, Stationary Loss: 0.032900, Diff Loss: 0.005400, learning rate: 1.60e-08\n",
      "Steps 34000: test RMSE 0.4441, moving average RMSE 0.4439, learning rate 1.60e-08\n",
      "Epoch 4, Step 4701, Loss: 0.331955, VQ Loss: 0.001186, Stationary Loss: 0.032494, Diff Loss: 0.005830, learning rate: 1.60e-08\n",
      "Epoch 4, Step 5201, Loss: 0.329250, VQ Loss: 0.001218, Stationary Loss: 0.032185, Diff Loss: 0.006180, learning rate: 1.60e-08\n",
      "Epoch 4, Step 5701, Loss: 0.326584, VQ Loss: 0.001191, Stationary Loss: 0.031944, Diff Loss: 0.005957, learning rate: 1.60e-08\n",
      "Epoch 4, Step 6201, Loss: 0.338908, VQ Loss: 0.001193, Stationary Loss: 0.033205, Diff Loss: 0.005663, learning rate: 1.60e-08\n",
      "Steps 36000: test RMSE 0.4441, moving average RMSE 0.4440, learning rate 1.60e-08\n",
      "Epoch 4, Step 6701, Loss: 0.315911, VQ Loss: 0.001192, Stationary Loss: 0.030868, Diff Loss: 0.006042, learning rate: 1.60e-08\n",
      "Epoch 4, Step 7201, Loss: 0.318429, VQ Loss: 0.001175, Stationary Loss: 0.031079, Diff Loss: 0.006459, learning rate: 1.60e-08\n",
      "Epoch 4, Step 7701, Loss: 0.331426, VQ Loss: 0.001198, Stationary Loss: 0.032507, Diff Loss: 0.005153, learning rate: 1.60e-08\n",
      "Epoch 4, Step 8201, Loss: 0.334062, VQ Loss: 0.001222, Stationary Loss: 0.032630, Diff Loss: 0.006544, learning rate: 1.60e-08\n",
      "Steps 38000: test RMSE 0.4430, moving average RMSE 0.4434, learning rate 1.60e-08\n",
      "Epoch 4, Step 8701, Loss: 0.337134, VQ Loss: 0.001165, Stationary Loss: 0.033008, Diff Loss: 0.005891, learning rate: 1.60e-08\n",
      "Epoch 4, Step 9201, Loss: 0.330678, VQ Loss: 0.001178, Stationary Loss: 0.032368, Diff Loss: 0.005818, learning rate: 1.60e-08\n",
      "Epoch 4, Step 9701, Loss: 0.333408, VQ Loss: 0.001213, Stationary Loss: 0.032669, Diff Loss: 0.005508, learning rate: 1.60e-08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61a96b0590664b17ba8b947048ef45ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5, Step 268, Loss: 0.339342, VQ Loss: 0.001189, Stationary Loss: 0.033246, Diff Loss: 0.005693, learning rate: 1.60e-08\n",
      "Model saved at ../model/TFT_Flowmatching/Feb25_17-19-35/model_40000.pt\n",
      "Steps 40000: test RMSE 0.4433, moving average RMSE 0.4433, learning rate 1.60e-08\n",
      "Epoch 5, Step 768, Loss: 0.329618, VQ Loss: 0.001219, Stationary Loss: 0.032232, Diff Loss: 0.006084, learning rate: 1.60e-08\n",
      "Epoch 5, Step 1268, Loss: 0.331670, VQ Loss: 0.001181, Stationary Loss: 0.032458, Diff Loss: 0.005907, learning rate: 1.60e-08\n",
      "Epoch 5, Step 1768, Loss: 0.314860, VQ Loss: 0.001194, Stationary Loss: 0.030675, Diff Loss: 0.006920, learning rate: 1.60e-08\n",
      "Epoch 5, Step 2268, Loss: 0.362948, VQ Loss: 0.001189, Stationary Loss: 0.035635, Diff Loss: 0.005414, learning rate: 1.60e-08\n",
      "Steps 42000: test RMSE 0.4432, moving average RMSE 0.4432, learning rate 1.60e-08\n",
      "Epoch 5, Step 2768, Loss: 0.334818, VQ Loss: 0.001195, Stationary Loss: 0.032782, Diff Loss: 0.005801, learning rate: 1.60e-08\n",
      "Epoch 5, Step 3268, Loss: 0.323442, VQ Loss: 0.001195, Stationary Loss: 0.031693, Diff Loss: 0.005315, learning rate: 1.60e-08\n",
      "Epoch 5, Step 3768, Loss: 0.329821, VQ Loss: 0.001189, Stationary Loss: 0.032302, Diff Loss: 0.005613, learning rate: 1.60e-08\n",
      "Epoch 5, Step 4268, Loss: 0.354290, VQ Loss: 0.001179, Stationary Loss: 0.034762, Diff Loss: 0.005491, learning rate: 1.60e-08\n",
      "Steps 44000: test RMSE 0.4427, moving average RMSE 0.4429, learning rate 1.60e-08\n",
      "Epoch 5, Step 4768, Loss: 0.320462, VQ Loss: 0.001206, Stationary Loss: 0.031336, Diff Loss: 0.005892, learning rate: 1.60e-08\n",
      "Epoch 5, Step 5268, Loss: 0.352998, VQ Loss: 0.001184, Stationary Loss: 0.034647, Diff Loss: 0.005345, learning rate: 1.60e-08\n",
      "Epoch 5, Step 5768, Loss: 0.341805, VQ Loss: 0.001216, Stationary Loss: 0.033482, Diff Loss: 0.005768, learning rate: 1.60e-08\n",
      "Epoch 5, Step 6268, Loss: 0.337087, VQ Loss: 0.001214, Stationary Loss: 0.032981, Diff Loss: 0.006061, learning rate: 1.60e-08\n",
      "Steps 46000: test RMSE 0.4440, moving average RMSE 0.4436, learning rate 1.60e-08\n",
      "Epoch 5, Step 6768, Loss: 0.318891, VQ Loss: 0.001198, Stationary Loss: 0.031106, Diff Loss: 0.006634, learning rate: 1.60e-08\n",
      "Epoch 5, Step 7268, Loss: 0.323881, VQ Loss: 0.001208, Stationary Loss: 0.031694, Diff Loss: 0.005736, learning rate: 1.60e-08\n",
      "Epoch 5, Step 7768, Loss: 0.338846, VQ Loss: 0.001211, Stationary Loss: 0.033180, Diff Loss: 0.005831, learning rate: 1.60e-08\n",
      "Epoch 5, Step 8268, Loss: 0.324346, VQ Loss: 0.001193, Stationary Loss: 0.031716, Diff Loss: 0.005989, learning rate: 1.60e-08\n",
      "Steps 48000: test RMSE 0.4433, moving average RMSE 0.4434, learning rate 1.60e-08\n",
      "Epoch 5, Step 8768, Loss: 0.326175, VQ Loss: 0.001227, Stationary Loss: 0.031888, Diff Loss: 0.006065, learning rate: 1.60e-08\n",
      "Epoch 5, Step 9268, Loss: 0.331434, VQ Loss: 0.001188, Stationary Loss: 0.032413, Diff Loss: 0.006120, learning rate: 1.60e-08\n",
      "Epoch 5, Step 9768, Loss: 0.335147, VQ Loss: 0.001196, Stationary Loss: 0.032821, Diff Loss: 0.005740, learning rate: 1.60e-08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bce49fd4f6141b5b6bee575bc863f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6, Step 335, Loss: 0.340969, VQ Loss: 0.001188, Stationary Loss: 0.033436, Diff Loss: 0.005425, learning rate: 1.60e-08\n",
      "Model saved at ../model/TFT_Flowmatching/Feb25_17-19-35/model_50000.pt\n",
      "Steps 50000: test RMSE 0.4442, moving average RMSE 0.4439, learning rate 1.60e-08\n",
      "Epoch 6, Step 835, Loss: 0.323387, VQ Loss: 0.001217, Stationary Loss: 0.031552, Diff Loss: 0.006651, learning rate: 1.60e-08\n",
      "Epoch 6, Step 1335, Loss: 0.337006, VQ Loss: 0.001180, Stationary Loss: 0.033015, Diff Loss: 0.005671, learning rate: 1.60e-08\n",
      "Epoch 6, Step 1835, Loss: 0.322133, VQ Loss: 0.001202, Stationary Loss: 0.031439, Diff Loss: 0.006540, learning rate: 1.60e-08\n",
      "Epoch 6, Step 2335, Loss: 0.340347, VQ Loss: 0.001204, Stationary Loss: 0.033349, Diff Loss: 0.005652, learning rate: 1.60e-08\n",
      "Steps 52000: test RMSE 0.4440, moving average RMSE 0.4440, learning rate 1.60e-08\n",
      "Epoch 6, Step 2835, Loss: 0.333689, VQ Loss: 0.001205, Stationary Loss: 0.032617, Diff Loss: 0.006316, learning rate: 1.60e-08\n",
      "Epoch 6, Step 3335, Loss: 0.311530, VQ Loss: 0.001190, Stationary Loss: 0.030388, Diff Loss: 0.006458, learning rate: 1.60e-08\n",
      "Epoch 6, Step 3835, Loss: 0.329553, VQ Loss: 0.001220, Stationary Loss: 0.032305, Diff Loss: 0.005282, learning rate: 1.60e-08\n",
      "Epoch 6, Step 4335, Loss: 0.315437, VQ Loss: 0.001170, Stationary Loss: 0.030884, Diff Loss: 0.005424, learning rate: 1.60e-08\n",
      "Steps 54000: test RMSE 0.4437, moving average RMSE 0.4438, learning rate 1.60e-08\n",
      "Epoch 6, Step 4835, Loss: 0.334407, VQ Loss: 0.001193, Stationary Loss: 0.032670, Diff Loss: 0.006510, learning rate: 1.60e-08\n",
      "Epoch 6, Step 5335, Loss: 0.321236, VQ Loss: 0.001187, Stationary Loss: 0.031512, Diff Loss: 0.004932, learning rate: 1.60e-08\n",
      "Epoch 6, Step 5835, Loss: 0.329386, VQ Loss: 0.001167, Stationary Loss: 0.032256, Diff Loss: 0.005654, learning rate: 1.60e-08\n",
      "Epoch 6, Step 6335, Loss: 0.334358, VQ Loss: 0.001192, Stationary Loss: 0.032691, Diff Loss: 0.006255, learning rate: 1.60e-08\n",
      "Steps 56000: test RMSE 0.4437, moving average RMSE 0.4438, learning rate 1.60e-08\n",
      "Epoch 6, Step 6835, Loss: 0.350536, VQ Loss: 0.001189, Stationary Loss: 0.034347, Diff Loss: 0.005877, learning rate: 1.60e-08\n",
      "Epoch 6, Step 7335, Loss: 0.323851, VQ Loss: 0.001186, Stationary Loss: 0.031714, Diff Loss: 0.005523, learning rate: 1.60e-08\n",
      "Epoch 6, Step 7835, Loss: 0.312431, VQ Loss: 0.001167, Stationary Loss: 0.030514, Diff Loss: 0.006120, learning rate: 1.60e-08\n",
      "Epoch 6, Step 8335, Loss: 0.331709, VQ Loss: 0.001200, Stationary Loss: 0.032485, Diff Loss: 0.005657, learning rate: 1.60e-08\n",
      "Steps 58000: test RMSE 0.4440, moving average RMSE 0.4439, learning rate 1.60e-08\n",
      "Epoch 6, Step 8835, Loss: 0.318565, VQ Loss: 0.001182, Stationary Loss: 0.031144, Diff Loss: 0.005941, learning rate: 1.60e-08\n",
      "Epoch 6, Step 9335, Loss: 0.366005, VQ Loss: 0.001184, Stationary Loss: 0.035907, Diff Loss: 0.005747, learning rate: 1.60e-08\n",
      "Epoch 6, Step 9835, Loss: 0.327714, VQ Loss: 0.001210, Stationary Loss: 0.032032, Diff Loss: 0.006181, learning rate: 1.60e-08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b43f878c6e4008a976dbbfa9c2841a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7, Step 402, Loss: 0.330343, VQ Loss: 0.001166, Stationary Loss: 0.032353, Diff Loss: 0.005643, learning rate: 1.60e-08\n",
      "Model saved at ../model/TFT_Flowmatching/Feb25_17-19-35/model_60000.pt\n",
      "Steps 60000: test RMSE 0.4432, moving average RMSE 0.4435, learning rate 1.60e-08\n",
      "Epoch 7, Step 902, Loss: 0.361025, VQ Loss: 0.001204, Stationary Loss: 0.035447, Diff Loss: 0.005354, learning rate: 1.60e-08\n",
      "Epoch 7, Step 1402, Loss: 0.329998, VQ Loss: 0.001195, Stationary Loss: 0.032320, Diff Loss: 0.005600, learning rate: 1.60e-08\n",
      "Epoch 7, Step 1902, Loss: 0.332111, VQ Loss: 0.001188, Stationary Loss: 0.032560, Diff Loss: 0.005321, learning rate: 1.60e-08\n",
      "Epoch 7, Step 2402, Loss: 0.320621, VQ Loss: 0.001171, Stationary Loss: 0.031362, Diff Loss: 0.005827, learning rate: 1.60e-08\n",
      "Steps 62000: test RMSE 0.4426, moving average RMSE 0.4430, learning rate 1.60e-08\n",
      "Epoch 7, Step 2902, Loss: 0.325304, VQ Loss: 0.001205, Stationary Loss: 0.031840, Diff Loss: 0.005700, learning rate: 1.60e-08\n",
      "Epoch 7, Step 3402, Loss: 0.362519, VQ Loss: 0.001203, Stationary Loss: 0.035563, Diff Loss: 0.005681, learning rate: 1.60e-08\n",
      "Epoch 7, Step 3902, Loss: 0.352067, VQ Loss: 0.001198, Stationary Loss: 0.034408, Diff Loss: 0.006788, learning rate: 1.60e-08\n",
      "Epoch 7, Step 4402, Loss: 0.330559, VQ Loss: 0.001202, Stationary Loss: 0.032369, Diff Loss: 0.005663, learning rate: 1.60e-08\n",
      "Steps 64000: test RMSE 0.4429, moving average RMSE 0.4429, learning rate 1.60e-08\n",
      "Epoch 7, Step 4902, Loss: 0.329129, VQ Loss: 0.001194, Stationary Loss: 0.032199, Diff Loss: 0.005940, learning rate: 1.60e-08\n",
      "Epoch 7, Step 5402, Loss: 0.330394, VQ Loss: 0.001206, Stationary Loss: 0.032269, Diff Loss: 0.006503, learning rate: 1.60e-08\n",
      "Epoch 7, Step 5902, Loss: 0.373514, VQ Loss: 0.001203, Stationary Loss: 0.036624, Diff Loss: 0.006076, learning rate: 1.60e-08\n",
      "Epoch 7, Step 6402, Loss: 0.318139, VQ Loss: 0.001162, Stationary Loss: 0.031170, Diff Loss: 0.005280, learning rate: 1.60e-08\n",
      "Steps 66000: test RMSE 0.4436, moving average RMSE 0.4434, learning rate 1.60e-08\n",
      "Epoch 7, Step 6902, Loss: 0.325768, VQ Loss: 0.001184, Stationary Loss: 0.031864, Diff Loss: 0.005944, learning rate: 1.60e-08\n",
      "Epoch 7, Step 7402, Loss: 0.329106, VQ Loss: 0.001206, Stationary Loss: 0.032212, Diff Loss: 0.005777, learning rate: 1.60e-08\n",
      "Epoch 7, Step 7902, Loss: 0.357487, VQ Loss: 0.001179, Stationary Loss: 0.035074, Diff Loss: 0.005566, learning rate: 1.60e-08\n",
      "Epoch 7, Step 8402, Loss: 0.323820, VQ Loss: 0.001176, Stationary Loss: 0.031673, Diff Loss: 0.005909, learning rate: 1.60e-08\n",
      "Steps 68000: test RMSE 0.4426, moving average RMSE 0.4429, learning rate 1.60e-08\n",
      "Stopping early at epoch 7, step 8402\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_epochs = 50\n",
    "eval_step = 2000\n",
    "save_every = 10000\n",
    "patience = 8  # Number of evaluations to wait for improvement\n",
    "cooldown = 4  # Evaluations to wait after an improvement before counting non-improvements\n",
    "smooth_factor = 0.6  # Smoothing factor for moving average\n",
    "lambda_flow = 1e-3  # Weight for flow matching loss\n",
    "print_every = 500\n",
    "\n",
    "# Setup\n",
    "train_all = len(train)\n",
    "model_name = \"TFT_Flowmatching\"\n",
    "from collections import defaultdict\n",
    "loss_all = defaultdict(list)\n",
    "best_test_rmse = float('inf')\n",
    "early_stopping_counter = 0\n",
    "cooldown_counter = cooldown\n",
    "\n",
    "now = datetime.now()\n",
    "folder_name = now.strftime(\"%b%d_%H-%M-%S\")\n",
    "print(f\"Saving model at ../model/{model_name}/{folder_name}\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=min(len(train) * n_epochs, 100000), eta_min=1e-8)\n",
    "# Define scheduler: ReduceLROnPlateau\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',        # 'min' because we want to minimize loss\n",
    "    factor=0.2,        # Reduce LR by factor of 0.2 (i.e., lr / 5)\n",
    "    patience=3000,     # Number of steps with no significant improvement before reducing LR\n",
    "    threshold=5e-4,    # Minimum change in loss to qualify as \"significant\"\n",
    "    min_lr=1e-8,       # Minimum LR to stop at\n",
    "    verbose=True       # Prints a message when LR is reduced\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize moving average\n",
    "moving_avg_test_rmse = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, (X_batch, y_batch) in tqdm(enumerate(train), total=train_all):\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        y_batch = y_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_batch[:, :, :2] = X_batch[:, :, :2] - current_pos_input\n",
    "        y_batch[:, :, :2] = y_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "        # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "        y_batch = y_batch[:, ::2, :2]\n",
    "        X_batch = X_batch[:, ::2, :]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # y_pred, vq_loss, perplexity = model(X_batch, y_batch=y_batch)\n",
    "        # loss = loss_fn(y_pred[:, :future_steps, :2], y_batch[:, :future_steps, :2])\n",
    "        diff_loss, vq_loss, stationary_loss = model(X_batch, y_batch[:, :future_steps, :2])\n",
    "\n",
    "\n",
    "        loss_all['diff_loss'].append(diff_loss.item())\n",
    "        loss_all['vq_loss'].append(vq_loss.item() * 10)\n",
    "        loss_all['stationary_loss'].append(0.1 * stationary_loss.item())\n",
    "        loss_all['loss'].append(diff_loss.item() + vq_loss.item() * 10 + stationary_loss.item())\n",
    "        # add vq_loss\n",
    "        loss = diff_loss  + 10 * vq_loss + 0.1 * stationary_loss\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss.item())\n",
    "\n",
    "        if (epoch * train_all + step + 1) % print_every == 0:\n",
    "            loss_item = sum(loss_all['loss'][-100:]) / 100\n",
    "            vq_loss_item = sum(loss_all['vq_loss'][-100:]) / 100\n",
    "            diff_loss_item = sum(loss_all['diff_loss'][-100:]) / 100\n",
    "            stationary_loss_item = sum(loss_all['stationary_loss'][-100:]) / 100\n",
    "            print(f\"Epoch {epoch+1}, Step {step+1}, Loss: {loss_item:.6f}, VQ Loss: {vq_loss_item:.6f}, Stationary Loss: {stationary_loss_item:.6f}, Diff Loss: {diff_loss_item:.6f}, learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # Save model\n",
    "        if (epoch * train_all + step + 1) % save_every == 0:\n",
    "            os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "            save_path = f\"../model/{model_name}/{folder_name}/model_{epoch * train_all + step + 1}.pt\"\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at {save_path}\")\n",
    "\n",
    "        # Validation and early stopping\n",
    "        if (epoch * train_all + step + 1) % eval_step == 0:\n",
    "            model.eval()\n",
    "            test_rmse_all = []\n",
    "            with torch.no_grad():\n",
    "                for X_test_batch, y_test_batch in test:\n",
    "                    X_test_batch = X_test_batch.float().to(device)\n",
    "                    y_test_batch = y_test_batch.float().to(device)\n",
    "                    \n",
    "                    current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "                    current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "                    X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "                    y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "                    # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "                    y_test_batch = y_test_batch[:, ::2, :2]\n",
    "                    X_test_batch = X_test_batch[:, ::2, :]\n",
    "                    \n",
    "\n",
    "                    y_pred_test = model(X_test_batch, influence=True)\n",
    "                    loss_test = loss_fn(y_pred_test[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "                    test_rmse = torch.sqrt(loss_test)\n",
    "                    if not torch.isnan(test_rmse):\n",
    "                        test_rmse_all.append(test_rmse.item())\n",
    "            \n",
    "            current_rmse = sum(test_rmse_all) / len(test_rmse_all)\n",
    "            if moving_avg_test_rmse is None:\n",
    "                moving_avg_test_rmse = current_rmse\n",
    "            else:\n",
    "                moving_avg_test_rmse = smooth_factor * current_rmse + (1 - smooth_factor) * moving_avg_test_rmse\n",
    "\n",
    "            print(f\"Steps {epoch * train_all + step + 1}: test RMSE {current_rmse:.4f}, moving average RMSE {moving_avg_test_rmse:.4f}, learning rate {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            # Check if the moving average RMSE is better; if not, increment counter\n",
    "            if moving_avg_test_rmse < best_test_rmse:\n",
    "                best_test_rmse = moving_avg_test_rmse\n",
    "                early_stopping_counter = 0  # Reset counter\n",
    "                cooldown_counter = cooldown  # Reset cooldown\n",
    "                # Optionally save the best model\n",
    "                os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "                best_model_path = f\"../model/{model_name}/{folder_name}/best_model.pt\"\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                if cooldown_counter > 0:\n",
    "                    cooldown_counter -= 1\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Stopping early at epoch {epoch+1}, step {step+1}\")\n",
    "                break\n",
    "\n",
    "            model.train()\n",
    "        \n",
    "    if early_stopping_counter >= patience:\n",
    "        break\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8cb526df54b4004874794a2a12f93c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.4437188070969305\n"
     ]
    }
   ],
   "source": [
    "validation_step = future_steps\n",
    "\n",
    "predictions = []\n",
    "truths = []\n",
    "\n",
    "test_loss_all = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    all_test = len(test)\n",
    "    test_rmse_all = []\n",
    "    for X_test_batch, y_test_batch in tqdm(test):\n",
    "        X_test_batch = X_test_batch.float().to(device)\n",
    "        y_test_batch = y_test_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "        y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "        # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "        y_test_batch = y_test_batch[:, ::2, :2]\n",
    "        X_test_batch = X_test_batch[:, ::2, :]\n",
    "        \n",
    "        y_preds = model(X_test_batch, influence=True, return_all=True)\n",
    "        # slect the one with minimum loss\n",
    "\n",
    "        min_loss = float('inf')\n",
    "        best_pred = None\n",
    "        for y_pred in y_preds:\n",
    "            loss_test = loss_fn(y_pred[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "            test_rmse = torch.sqrt(loss_test)\n",
    "            if test_rmse < min_loss:\n",
    "                min_loss = test_rmse\n",
    "                best_pred = y_pred\n",
    "        \n",
    "        test_loss_all.append(min_loss.item())\n",
    "\n",
    "        predictions.append(y_pred[:, :validation_step, :2] + current_pos_output[:, :y_pred.shape[1], :2])\n",
    "        truths.append(y_test_batch[:, :validation_step, :2] + current_pos_output[:, :y_pred.shape[1], :2])\n",
    "\n",
    "\n",
    "print(f\"Test RMSE: {sum(test_loss_all) / len(test_loss_all)}\")       \n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "truths = torch.cat(truths, dim=0)\n",
    "\n",
    "# reverse normalization\n",
    "normalize_dict = stats_dict\n",
    "\n",
    "for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB7LElEQVR4nO3dd3zV1f3H8dfN3UnuvdmLTMIm7LDFrYgWxV0HDqwWt9Laiv6q1bZSt7YKdaJU6xbUCghV9hBBwt4EAiF7z5vk3u/vjxMuRFYCSW7uzef5eORRvuPenG9uIW/P+BydpmkaQgghhBB+IsDbDRBCCCGEaE0SboQQQgjhVyTcCCGEEMKvSLgRQgghhF+RcCOEEEIIvyLhRgghhBB+RcKNEEIIIfyKwdsNaG9ut5tDhw5hs9nQ6XTebo4QQgghmkHTNCoqKoiLiyMg4OR9M50u3Bw6dIiEhARvN0MIIYQQp+HAgQPEx8ef9J5OF25sNhugfjh2u93LrRFCCCFEc5SXl5OQkOD5PX4ynS7cHB6KstvtEm6EEEIIH9OcKSUyoVgIIYQQfkXCjRBCCCH8ilfDzdKlSxk/fjxxcXHodDrmzJlzytd8+OGHDBgwgMDAQGJjY7n99tspKipq+8YKIYQQwid4dc5NVVUVAwYM4Pbbb+fqq68+5f3Lly/nlltu4eWXX2b8+PFkZ2czefJkfvOb3zB79uxWbZvL5aK+vr5V31OA0WhEr9d7uxlCCCH8mFfDzbhx4xg3blyz71+9ejXJyck88MADAKSkpPDb3/6W5557rtXapGkaubm5lJaWttp7iqZCQkKIiYmROkNCCCHahE+tlho1ahSPP/44c+fOZdy4ceTn5/P5559z2WWXnfA1TqcTp9PpOS4vLz/p9zgcbKKioggMDJRfwK1I0zSqq6vJz88HIDY21sstEkII4Y98Ltx8+OGHXH/99dTW1tLQ0MDll1/OP//5zxO+Ztq0aTz11FPNen+Xy+UJNuHh4a3VbHEUq9UKQH5+PlFRUTJEJYQQotX51GqprVu38sADD/DEE0+wbt065s+fT2ZmJpMnTz7ha6ZOnUpZWZnn68CBAye89/Acm8DAwFZvuzji8M9X5jQJIYRoCz7VczNt2jRGjx7NI488AkD//v0JCgpizJgx/PWvfz3uMIfZbMZsNrfo+8hQVNuSn68QQoi25FM9N9XV1cdslnV4WEPTNG80SQghhBAdjFfDTWVlJRkZGWRkZACQmZlJRkYGWVlZgBpSuuWWWzz3jx8/ni+//JIZM2awd+9eVqxYwQMPPMCwYcOIi4vzxiMIIYQQooPx6rDU2rVrOe+88zzHU6ZMAeDWW2/lvffeIycnxxN0AG677TYqKip47bXX+N3vfkdISAjnn38+zz77bLu3XQghhBAdk07rZOM55eXlOBwOysrKjtk4s7a2lszMTFJSUrBYLO3etnPPPZeBAwfyyiuvtPv3bk/e/jkLIYTwPSf7/f1LPjXnRgghhBAdnKZBg/PU97UhCTcdxG233caSJUt49dVX0el06HQ6DAYDL7zwQpP7Nm/eTEBAAHv27AHUyqMZM2Ywbtw4rFYrKSkpfPbZZ01ek52dzfXXX09oaCjh4eFcccUV7Nu3r70eTQghRGfR4IT8bXBoA7jdXmuGhJsO4tVXX2XkyJHceeed5OTkkJOTw1NPPcXMmTOb3Pfuu+8yZswYUlNTPef+9Kc/cfXVV7NhwwZuvvlmbrjhBrZt2waoFWbnnXcewcHBLF26lOXLlxMcHMwll1xCXV1duz6jEEIIP1ZTAofWQ8F2aKgBvDfrRcJNB+FwODCZTAQGBhITE0NMTAyTJk1ix44drFmzBlBF7z744AMmTZrU5LXXXnstv/nNb+jRowd/+ctfSE9P91Rt/vjjjwkICODtt9+mX79+9O7dm5kzZ5KVlcXixYvb+zGFEEL4G7cbSrMg+2eoLoGiXZC32atN8qkifp1NbGwsl112Ge+++y7Dhg3jv//9L7W1tVx77bVN7hs5cuQxx4eX169bt47du3djs9ma3FNbW+sZ2hJCCCFOS30NFO6GsizQG2HLl7DpU7CGQdrVYIvxSrMk3HRwv/nNb5g4cSIvv/wyM2fO5Prrr2/W9hCHqwC73W6GDBnChx9+eMw9kZGRrd5eIYQQnURVERTsgOpCQIMf/qLm2wCkjAGLw2tNk3DTgZhMJlwuV5Nzl156KUFBQcyYMYN58+axdOnSY163evXqJsUOV69ezaBBgwAYPHgwn3zyCVFRUadcOieEEEKcktulhqGKdoPmgtL9sORZcFaAKRhGPwgJw0Fv8loTZc5NB5KcnMyPP/7Ivn37KCwsxO12o9frue2225g6dSrdunU7ZggK4LPPPuPdd99l586dPPnkk6xZs4b77rsPgJtuuomIiAiuuOIKli1bRmZmJkuWLOHBBx/k4MGD7f2IQgghfFldFeRuVl8Betj8JSz4PxVsInvD1W9B4ghvt1LCTUfy+9//Hr1eT58+fYiMjPRUZ77jjjuoq6s7ZiLxYU899RQff/wx/fv35/333+fDDz+kT58+gNqBe+nSpSQmJnLVVVfRu3dvJk2aRE1NjfTkCCGEaL7KfDVpuDQLdMB3j8PGT9S1tGvg8n+A7dgNrL1BhqU6kB49erBq1apjzufk5GAwGJoMPR0tLi6OBQsWnPB9Y2JieP/991utnUIIIToRVwMUZ0LxHggIUOFmybTGYaggOPdRSB6j7m2ohZpSsMeBznv9JxJuOjCn08mBAwf405/+xHXXXUd0dLS3mySEEKIzcVZAwU4ozwaLHTL+c6S3JrIXXPAk2Bt7a2pKoK4awlIhPBUaF7Z4gwxLdWAfffQRPXv2pKysjOeee87bzRFCCNFZaBqU58DBdVCRo+bXfPfYUcNQV8Pl/1TBxt0A5YdA00HcQIjuA0bv7hsoPTcd2G233cZtt9120ns62b6nQggh2lpDHRTvVV8Gk1oNtfjv4CxXw1DnPKqWegPUV6sl4bZYiOgO1hCvNv0wCTdCCCGEUGpKoXAnVOSC1QEZH8GGj9S1yJ6Nw1BxqmenplgFoYieEJaiglAHIeFGCCGE6Ow0Tc2rKdip9oUK0MP8x45so5B2NQz/rapd426Aijww2yCur6pC7MX5Nccj4UYIIYTozBqcaguFkkwwBarVUIueOWoY6o+Qcra6t65S9e7Y4iCyhwo4HZCEGyGEEKKzqi5WvTVV+RAYCus/PDIMFdEDLvzzkWGoqgJ1PqoPhCSBvuNGiI7bMiGEEEK0Dbcbyg6oHbxd9WrTy3mPHhmG6nsljLhbDUO56lQBP0uIWv4d3PH3JZRwI4QQQnQmddVQtEetgjIHqyGpRX9Tw1DGIDjnEeh6rrq3tlyddySq1VCmU2/c3BFIuBFCCCE6A01Tq6CKdkNtKVjDIOMDVZgPGoehngR7F9DcUJkHAUaIToOQRDXJ2EdIuBFCCCH8XX3tkd4avRECTDD/j5C7SV3vMwFG3qOGoRqcahgqKFIt/w4M82rTT4dUKPYT5557Lvfffz8PPfQQoaGhREdH8+abb1JVVcXtt9+OzWYjNTWVefPmeV6zdetWLr30UoKDg4mOjmbixIkUFhZ6rs+fP5+zzjqLkJAQwsPD+dWvfsWePXs81/ft24dOp+PLL7/kvPPOIzAwkAEDBhx3fywhhBBeUpkP2evU3lDWEBVyZt+pgo0xUE0aPushFWxqSqGqEMK6Qtwgnww2IOHmlDRNo7quwStfLa0+/P777xMREcGaNWu4//77ufvuu7n22msZNWoUP//8M2PHjmXixIlUV1eTk5PDOeecw8CBA1m7di3z588nLy+P6667zvN+VVVVTJkyhZ9++onvv/+egIAArrzyStxud5Pv+/jjj/P73/+ejIwMevTowQ033EBDQ0Or/PyFEEKcpoY6tRIq+2e1hDsoHH58Q/XY1JZBeHe46k01v8azhYKmtlCI8v4WCmdCp3Wy+v3l5eU4HA7Kysqw2+1NrtXW1pKZmUlKSgoWi/pQq+sa6PPEd95oKlufHkugqXkjh+eeey4ul4tly5YB4HK5cDgcXHXVVcyaNQuA3NxcYmNjWbVqFXPnzuXHH3/ku++OPNvBgwdJSEhgx44d9OjR45jvUVBQQFRUFJs2bSItLY19+/aRkpLC22+/zR133KHavHUrffv2Zdu2bfTq1eu4bT3ez1kIIUQrqi5WlYYr8yEwXA1HLXpGrZAC6HuVKspnMB+1hUKMmnfTQbZQ+KWT/f7+JZlz40f69+/v+bNeryc8PJx+/fp5zh3eVTw/P59169axaNEigoODj3mfPXv20KNHD/bs2cOf/vQnVq9eTWFhoafHJisri7S0tON+39jYWM/3OFG4EUII0UZc9VB6QA1BueshOEpNGF7/bzVJODACzn0U4tNVL011UeMWCj3UUFQH2kLhTEi4OQWrUc/Wp8d67Xu3hNFobHKs0+manNM1lsd2u9243W7Gjx/Ps88+e8z7HA4o48ePJyEhgbfeeou4uDjcbjdpaWnU1dWd8Pse/T2EEEK0o5pStRKq/JDqfamphm8egIId6nrq+TD6IbDYfWILhTMh4eYUdDpds4eGfMngwYP54osvSE5OxmA49vmKiorYtm0bb7zxBmPGqN1fly9f3t7NFEIIcSpuV2NBvj3QUKuCyrZv1PwalxNMwXDWw9DtAnW/s0IFIXuXDr2FwpmQCcWd1L333ktxcTE33HADa9asYe/evSxYsIBJkybhcrkIDQ0lPDycN998k927d/PDDz8wZcoUbzdbCCHE0WrLIXcj5GxSdWj0RvjuMVj5DxVsuqTDNe+qYKO5VZ2b+lqI7guxA/wy2ICEm04rLi6OFStW4HK5GDt2LGlpaTz44IM4HA4CAgIICAjg448/Zt26daSlpfHwww/z/PPPe7vZQgghoHH7hINqiXdZNtii1Z8/nwQHf1LLukc9AJc+p+bd1Neo+ywh0GUIhKd26L2hzpSsljqKrOJpH/JzFkKIM1BXBUV7oSwLjFYIMMCKV2H3/9T1iB5w/uNqc0tNg5piNWk4LAVCU3x2ibeslhJCCCH8zeHtEwp3quGo4EhViG/J31XhPV0ADJoIgyeqwOOqg4p8NYHYDycNn4yEGyGEEKKjq69RvTWl+9Vy7aAIWPMmbP5CXXfEw3mPqeJ7oIr0OSvUnlDhqWqDzE5Ewo0QQgjRUWkaVBWo3prqYtVbU7IfFk1RQQegzxUwfLIaonI3qMJ9BgvE9Fehx4c2vGwtXp1QvHTpUsaPH09cXBw6nY45c+ac8jVOp5PHH3+cpKQkzGYzqampvPvuu23fWCGEEKI9NTgbt09Yp+bZ2GJg42cw5x4VbKxhcMmzapm30aruKc+BoCjoMhhCkzplsAEv99xUVVUxYMAAbr/9dq6++upmvea6664jLy+Pd955h27dupGfny/7GAkhhPAv1cUq2FQ1bp9QUwzfPAj5W9X1lHNgzBSwONQS76pC1csT2RvCktWS8E7Mq+Fm3LhxjBs3rtn3z58/nyVLlrB3717CwtROpcnJySd9jdPpxOl0eo7Ly8tPq61CCCFEm9M0VWG4YJuaEGyLhR1zYfV0VaDPGARnPQjdLlKTgxtqobJA7d4d0VMNWwnfqnPz9ddfk56eznPPPUeXLl3o0aMHv//976mpqTnha6ZNm4bD4fB8JSQktGOLhRBCiGZyu6F4L+RsVCuf9CZY8H+w/CUVYuIGwbXvQveLVbCpLlZfYV1V7RoJNh4+NaF47969LF++HIvFwuzZsyksLOSee+6huLj4hPNupk6d2qSybnl5uQQcIYQQHUtDnZo0XLIPrA44uA6WvQjOcjXENPQu6He1Cj2uejVp2BQMsQPBHtdplng3l0+FG7fbjU6n48MPP8ThcADw0ksvcc011/D6669jtVqPeY3ZbMZsNrd3U4UQQojmqauC/O1Qng3WULUn1LZv1LXw7mqJd1iKOq4tV18h8RDezW+3TzhTPhVuYmNj6dKliyfYAPTu3RtN0zh48CDdu3f3YuuEEEKIFqopgbxtUF2kVjx995jaKwodDLwRhtymem7cLjW3Rm+AmDRVv6aTroRqDp+aczN69GgOHTpEZWWl59zOnTsJCAggPj7eiy0TQgghWqgiDw5lqIJ7DTXw1b0q2BiD4JJpMOxOFWzqqtUk46AwNbcmLEWCzSl4NdxUVlaSkZFBRkYGAJmZmWRkZJCVlQWo+TK33HKL5/4bb7yR8PBwbr/9drZu3crSpUt55JFHmDRp0nGHpIQQQogOR9PU3JqcDNBcULgdvr4fKvNU0b0rp0PiiCMF/GrL1Uqo2EFqVZQ4Ja+Gm7Vr1zJo0CAGDRoEwJQpUxg0aBBPPPEEADk5OZ6gAxAcHMzChQspLS0lPT2dm266ifHjx/OPf/zDK+3vSM4991zuv/9+HnroIUJDQ4mOjubNN9+kqqqK22+/HZvNRmpqKvPmzQPA5XJxxx13kJKSgtVqpWfPnrz66que96utraVv377cddddnnOZmZk4HA7eeuutdn8+IYTwC64GKNgBuZvVaqitX8P//qxWQ8UPhQkz1IaXDU41B8dgVQX5InuobRdEs3h1zs25557LyTYlf++9944516tXLxYuXNiGrfoFTYP66vb7fkczBrZoBvz777/PH/7wB9asWcMnn3zC3XffzZw5c7jyyit57LHHePnll5k4cSJZWVkYjUbi4+P59NNPiYiIYOXKldx1113ExsZy3XXXYbFY+PDDDxk+fDiXXnop48ePZ+LEiZx33nnceeedbfjQQgjhp+prVbAp3Q+mILUaat8yda3fdTD8LrXhpbOicdJwstoXyhTo1Wb7Ip12snThh062ZXptbS2ZmZmkpKRgsTRuCV9XBc/EeaGlwGOH1F+AZjj33HNxuVwsW6b+orhcLhwOB1dddRWzZs0CIDc3l9jYWFatWsWIESOOeY97772XvLw8Pv/8c8+5559/nueee44bbriBzz77jE2bNhEREXFGj3Xcn7MQQviz2nJVmK8iD9BUb03xXggwwtm/gx6XqP+Yrm6sNBzRQ/XgBPjU1Ng2dbLf37/kU6ulxMn179/f82e9Xk94eDj9+vXznIuOjgYgPz8fgH/961+8/fbb7N+/n5qaGurq6hg4cGCT9/zd737HV199xT//+U/mzZt3xsFGCCE6napCyNsKdRVqXs33T6v6NdYwuPgvEN23ccPLPDDZIKo3BEd5u9U+TcLNqRgDVQ+Kt753S243Nt1LRKfTNTmnaxzicrvdfPrppzz88MO8+OKLjBw5EpvNxvPPP8+PP/7Y5D3y8/PZsWMHer2eXbt2cckll5zmwwghRCejaWreTP42tZT7wI+w8p9qL6jInnDxXyEoUs2vqcxXWy1E9ZLaNa1Aws2p6HTNHhryJcuWLWPUqFHcc889nnN79uw55r5JkyaRlpbGnXfeyR133MEFF1xAnz592rOpQgjhe9wuKM6Eol2g08P6D2B7Y2G+bhfC2Y+AwayGq5wVEJYKEd1l0nArkXDTSXXr1o1Zs2bx3XffkZKSwr///W9++uknUlJSPPe8/vrrrFq1io0bN5KQkMC8efO46aab+PHHHzGZ5C+gEEIc1+GtFIoz1X8gL3nmSGG+YXfBgF+r+yrz1bnovjK/ppXJT7KTmjx5MldddRXXX389w4cPp6ioqEkvzvbt23nkkUeYPn26Zy+u119/ndLSUv70pz95q9lCCNGx1VWpIFO8V82r+XZK08J8A29QtW3KD6ll3nGDGovyya/j1iSrpY4iq3jah/ychRB+qboY8rdCTSkU7oAlz6n6NfYuMPYZCE1Sx5UFarPLyJ4yv6YFZLWUEEII0Z4qctUeUQ3VsOs7+FmV4CB+KFzwhAoxteVQVynza9qBhBshhBDidLndqihfwQ5w16sdvX9ZmE+nV/NrdAFqfo0jUYah2piEGyGEEOJ0uOqhaLeaX1NXBYunHVuYz92g5tdYHKp+TZDUCmsPEm6EEEKIlqqvgYLtUHpA1bJZ9MyxhfmazK/pBeZgb7e605BwcxydbI51u5OfrxDCp1UWqAnD1cVwYA2sfv3Ywny1ZeCsVHNrwlJlfk07k3BzlMPVfKurq7FarV5ujf+qrlYbkf6yorIQQnRornoo2Q/Fe9Tu3hs/ge3/VdcOF+bTm47Mr4ntD/Z4mV/jBRJujqLX6wkJCfHsvRQYGOjZskCcOU3TqK6uJj8/n5CQEPR6vbebJIQQzVNbBoW71PwZNFj6wrGF+TSXGqKyhMj8Gi+TcPMLMTExwJHNJUXrCwkJ8fychRCiQ3O7oeIQFOxSy7yL98KyF9X8GmMQXPB/kDhSzcGpKlQ1bSJ7yvwaL5Nw8ws6nY7Y2FiioqKor6/3dnP8jtFolB4bIYRvqK+Boj1Qsk9to5DxIWz/Vl0L766CTUgS1JaCs0rNrwnvBnoZcvc2CTcnoNfr5ZewEEJ0VlWFULATqougphiWPgdlBwGdGoJKnwQBBqjMU3VsYvuDI0GFIOF1Em6EEEKIw1wNqihf0W41JLX3B1j3vppPExQJ5z2m9oNqUr+mDwSFe7vl4igSboQQQghQ2yMU7lKTgl11sOIVyN2krnU9D8ZMUdsoOCvU/lH2LhDVC0xB3my1OA4JN0IIITo3TVO9MIU7ob5KbX654h/qz8ZAGP0gdL8Y0NQeUjo9RKdBSCLo5ddoRySfihBCiM6rvlYNQZXuB7cL1r0He75X16LT4LzHwR57ZDVUUCRE9JBhqA5Owo0QQojOyTNpuBAqctQS78o8VYBvyG0w8EbVS1NdBA11jdWGu4LB7O2Wi1OQcCOEEKJzcTVAaZbqsXHVwY65sOFjQFP7QJ3/f2qSsKsOKvLUPJu4vmCLkdVQPkLCjRBCiM7j8KThikNqYvDyl9VcG4Cel8Ko+9Q8m8N7QzkSIDxVivL5GAk3Qggh/J9n0vAuFWqyf4LV/wKXE8x2OPv3kHJ24xLvHLXRZUyaCjcBUvPM10i4EUII4d/qa1Wl4dJ90OCENW9B1kp1rcsQOPdRNVG4rkrt9G2LUfNrrKFebbY4fRJuhBBC+K+qIjXsVFWgtlFY/hLUlECAUW142e9qdV9lvurdiewFocmq50b4LAk3Qggh/I/bBSX7oXgP1FXDli9h6xx1LTRFTRoOT1U9OZX5EBimlngHR3m12aJ1SLgRQgjhX+pr1BLv0iyoKVKThkv2qWtpV6seG4NZ9eDUVavl3eGpYLR6tdmi9Ui4EUII4T+qi6Fgh6pXs385rH0P3PVgDVNzaxKGNU4azgZjEMQNBFscBAR4u+WiFUm4EUII4fs0TQWWgp0q2Pz0FmSvU9eSRsPZj4A1RK2Uqi1TgSaiO1jsXm22aBsSboQQQvg2Vz0U7VXza4r3qGGo6iIwWGDkfdDrMtDcal+oAANE9ZV9ofycV/vhli5dyvjx44mLi0On0zFnzpxmv3bFihUYDAYGDhzYZu0TQgjRwdVVQc5GKNgOuxfAwidUsAlNhqvegN6/goZaVePGEgJxgyG8qwQbP+fVcFNVVcWAAQN47bXXWvS6srIybrnlFi644II2apkQQogOr6oQsn9Whfl+nAFrZ6oemu4Xw4QZ4EhU99SWqSGoLoNlw8tOwqvRddy4cYwbN67Fr/vtb3/LjTfeiF6vb1FvjxBCCD/gdkP5QTVxuGgXLH8VKnNBb4RRD6phKHc9lGWrOTXRabIvVCfjc/1yM2fOZM+ePXzwwQf89a9/PeX9TqcTp9PpOS4vL2/L5gkhhGhLDXWqp6YkE/Ytg5/eUUHGFgsXPaVq1TgroKZMzauJ6AamIG+3WrQznwo3u3bt4tFHH2XZsmUYDM1r+rRp03jqqafauGVCCCHanLMC8rdDcSZs/A/sWaTOJ41Wy7xNQaogHzq1L1RIouwL1Un5zMJ+l8vFjTfeyFNPPUWPHj2a/bqpU6dSVlbm+Tpw4EAbtlIIIUSbqMhT82sO/QyL/qKCjS4Ahk+Gi/+qivKVH1IBp8tgCEuRYNOJ+UzPTUVFBWvXrmX9+vXcd999ALjdbjRNw2AwsGDBAs4///xjXmc2mzGbze3dXCGEEK3B7VKVhgt3wr7lsOZNtfopMBwueBJi+zfWrilXE4gjuoMp0NutFl7mM+HGbrezadOmJuemT5/ODz/8wOeff05KSoqXWiaEEKJN1Neq+TVFu2DTp7BjnjofN1jtDWUNUQX7dHqI7ivDUMLDq+GmsrKS3bt3e44zMzPJyMggLCyMxMREpk6dSnZ2NrNmzSIgIIC0tLQmr4+KisJisRxzXgghhI+rKVW1a/K2wI//Uj03AINvgcG3qi0UyrIhMAIie8oSb9GEV8PN2rVrOe+88zzHU6ZMAeDWW2/lvffeIycnh6ysLG81TwghRHvTNFVJuGB74zDUG2rYyWyH8x6HxOFqCMpZoXb3jugmG16KY+g0TdO83Yj2VF5ejsPhoKysDLtd9hQRQogOw9WgVkIV7IAtn8OW2ep8VG+48M8QFKlWQwUY1NwaR6JseNmJtOT3t8/MuRFCCOHH6qrV/JrcDfDjm5DXOMcy7Wq1Ikpzq2GooEg1DBUY5t32ig5Nwo0QQgjvqi5W9Wv2L4PVM6CmRA01nfNH6Hqu2j7BWdk4DNUdjBZvt1h0cBJuhBBCeIemQXk25G+DTZ+pL82tQsxFT4EjXs2/0RvVkm97vAxDiWaRcCOEEKL9NdRB8V7I2aBq12SvVed7jIWzHgZ0MgwlTpuEGyGEEO2rtgwKdsL+FbD6dTVJWG+E0Q9Bz0vBWabm4IR1hfBuMgwlWkzCjRBCiPahaWqLhIIdsHUOZPxHbXppj4MLn1JhpiIPDCaI6Q/2LjIMJU6LhBshhBBtr6EOivdA7mZY+zZkrVbnk8fAuX9Uy7vLD0FwlNrZW4ahxBmQcCOEEKJtHR6G2rccfpyhtkwIMMCw30K/a9T1mjIIS1VF+QyyH6A4MxJuhBBCtI3Dw1D5O2DrF7DhY7Vtgi1WbXoZ0V2thjJYIG4g2OJkGEq0Cgk3QgghWt/hYaicjU1XQ6WcDWc/oiYQlx8CW7QahrKGere9wq9IuBFCCNG6akqhcAdkLlObXlYVQIARRt4Lfa6A2lK1N1REdzWJWIahRCuTcCOEEKJ1eIrybYfNn8HGT1VRPke8GoYK6woVOWAIhNgBajWUTuftVgs/JOFGCCHEmWtwQtGexqJ8b8Ch9ep8twvhrCkqxJQfAltM4zBUiFebK/ybhBshhBBnpqYECnfCnsUq2FQXgd4Eox9URflqSlT4ieiuVkQZTN5usfBzEm6EEEKcHrf7yDDUxo9hy5dqGCokCS58EkISVW+NKahxGCpOhqFEu5BwI4QQouUanFC4Ww0/rfkX5G5S53tconpsAMpz1LLvyB5gcXivraLTkXAjhBCiZWpK1BYKe36AH99Qq58MFrXhZY+xUF3cOAzVo3E1lAxDifYl4UYIIUTzeIahtql9obbOATQVYC58Uq1+Kj8ExsDGonyxMgwlvELCjRBCiFOrr4Wi3ZC9TtWuyd+qzvceDyPvA82lhqHscWrisAxDCS+ScCOEEOLkqovV3lC7F8Cat8BZrnpnxvwOul2gVke56iGiJ4SlyDCU8DoJN0IIIY7P7Ybyg6qX5ucPYPs36nxED7jgCVWzpjwbjMEQ20eGoUSHIeFGCCHEseqqoGgvHFoHq6ar7RQA+l4FIyarDTA9w1A9wGL3bnuFOIqEGyGEEEe43WqLhKLdajXUT29DXaWqVXPOHyF5DNQUQ0M9RPZSw1B6o7dbLUQTEm6EEEIozkoo3gsF22HTZ7BrgTof2VsNQwVHQsUhNQwV11cNS8kwlOiAJNwIIURn53ar0FK4G/Yth59nQlWhutbvOhh2p5owXJ6jlntHdJdhKNGhSbgRQojOzFmh5tYUbocNH6uhKABbHJzzCMQOlGEo4XMk3AghRGfkdqmCe0W7IXMJrHtfhRh0kHY1DL1DhZjyQ2C2QZc0CI6WYSjhEyTcCCFEZ1NbDsV71IaXGR/CvmXqvCNBTRqOSYPaMlW/xhan9oYy27zbZiFaQMKNEEJ0Fm6XqktTsBsyf4Cf/632hdIFwIBfw+Bb1Z/Ls8Fgheg0FXj08qtC+Bb5f6wQQnQGtWVqwnD+Nsj4N2StVudDU+DcP6rqwrWlUFcNji5qvyjZQkH4KAk3Qgjhz1wNUHZATRrevRDWfwB1FaDTw6Cb1ZfmhrJsNfQUO0AV5gvQe7vlQpy20w439fX15ObmUl1dTWRkJGFhYa3ZLiGEEGeqphSK9kDuJlg/S216CRDeXfXWhKU2roRyQmiyWgllDvZmi4VoFQEtubmyspI33niDc889F4fDQXJyMn369CEyMpKkpCTuvPNOfvrpp2a/39KlSxk/fjxxcXHodDrmzJlz0vu//PJLLrroIiIjI7Hb7YwcOZLvvvuuJY8ghBD+z9UAxZlw8CfY8BF8N1UFmwAjDL0Trpyh6tWUZYPeDHGDIbqvBBvhN5odbl5++WWSk5N56623OP/88/nyyy/JyMhgx44drFq1iieffJKGhgYuuugiLrnkEnbt2nXK96yqqmLAgAG89tprzWrD0qVLueiii5g7dy7r1q3jvPPOY/z48axfv765jyGEEP6tpgRyMmDvIvj+L/DTW1BfDVG94eq3YOANapfvmjKI6Abx6WCPhYAW/beuEB2aTtM0rTk3XnvttTzxxBP069fvpPc5nU7eeecdTCYTv/nNb5rfEJ2O2bNnM2HChGa/BqBv375cf/31PPHEE826v7y8HIfDQVlZGXa7VNgUQvgJVz2UHoCiXbBjnuqxaagFvQmG/kbVrmmoVcEmMEIFm6BIqVsjfEZLfn83e87NZ5991qz7zGYz99xzT3Pf9oy43W4qKipOOt/H6XTidDo9x+Xl5e3RNCGEaD/VxaoY36EMWPce5G9R52P6wzl/UHtAVRWoScSRvSA0CQxmb7ZYiDbl06ulXnzxRaqqqrjuuutOeM+0adN46qmn2rFVQgjRTlz1UJoFhbtg2zew6VNw1YHBAsN/C32ugLoqtSeULVpNJA6UxR/C/51WuKmtreWf//wnixYtIj8/H7fb3eT6zz//3CqNO5mPPvqIP//5z3z11VdERUWd8L6pU6cyZcoUz3F5eTkJCQlt3j4hhGhTzgoo2AEHfoJ1M6FwhzrfZQic/Xs19FSeA0YLxPQDR7zsCSU6jdMKN5MmTWLhwoVcc801DBs2DF07j9l+8skn3HHHHXz22WdceOGFJ73XbDZjNkv3qxDCj1TkQd4WNa9my2xw14MxCEbeDT0vUwX7KvPBFgvhqWAN8XaLhWhXpxVuvv32W+bOncvo0aNbuz2n9NFHHzFp0iQ++ugjLrvssnb//kII4TWuBijdr6oLr3oN8req8wkjYMwUVVG4/BCYgiC2v1ruLcX4RCd0WuGmS5cu2GxnvolaZWUlu3fv9hxnZmaSkZFBWFgYiYmJTJ06lezsbGbNmgWoYHPLLbfw6quvMmLECHJzcwGwWq04HFImXAjhx+qq1dDT9rmw5g3VO2O0wugHodvFUFsCVYVqL6jwrrLRpejUTquwwYsvvsgf//hH9u/ff0bffO3atQwaNIhBgwYBMGXKFAYNGuRZ1p2Tk0NWVpbn/jfeeIOGhgbuvfdeYmNjPV8PPvjgGbVDCCE6tKpCVZBv6Yuw9DkVbMJT4co3oeu5aqPLABN0Gazm10iwEZ1cs+vcHK2goIDrrruOpUuXEhgYiNHYdJJacXFxqzWwtUmdGyGEz3C71TDUgR9h+ctQsF2d7305jLhX7RHlqoeQJLV1ginQu+0Vog21SZ2bo91www1kZ2fzzDPPEB0d3e4TioUQwu/V1zYu8f4KfvyXWh1lDISzH4Hks9SEYbNd9dQER0sxPiGOclrhZuXKlaxatYoBAwa0dnuEEEJUF6vVUKtnwI5v1bnw7nDhk2rScEUehMSrc7IflBDHOK1w06tXL2pqalq7LUII0blpGpQdhP0rYNmLULhTne8zAYZPBmeZ6tGJSYOQRFkJJcQJnFa4+fvf/87vfvc7/va3v9GvX79j5tzIXBYhhGihhjoo3gObPoMf31TzaYxBcM4jkDhSDUMFRkBkDwiK8HZrhejQTmtCcUDj7rG/nGujaRo6nQ6Xy9U6rWsDMqFYCNHh1JZB3lZY8SrsnKfORfaEC55Uk4TrqsGRqDa7NFq921YhvKTNJxQvWrTotBomhBDiKJoGFbmQuRSWPKt6bkDt4D30N1BTqlZMxfQDezwEnFb1DiE6ndMKN+ecc05rt0MIIToXVwMU74UNn8CaGWqDS1MwnPtH6JKuatvYoiGiB1hDvd1aIXxKs8NNVlYWiYmJzX7j7OxsunTpclqNEkIIv+ashNzNsPwl2PWdOhfZGy58AvQm1WMT0R3CUsFg8mpThfBFze7jHDp0KHfeeSdr1qw54T1lZWW89dZbpKWl8eWXX7ZKA4UQwq9U5sOOefDV3UeCTb/r4FcvgeYGnQHiBkJkLwk2QpymZvfcbNu2jWeeeYZLLrkEo9FIeno6cXFxWCwWSkpK2Lp1K1u2bCE9PZ3nn3+ecePGtWW7hRDCt7hdULIfMj5Q9Wvqq9U2CedOhdgBahjK3kWthpLtE4Q4Iy1eLVVbW8vcuXNZtmwZ+/bto6amhoiICAYNGsTYsWNJS0trq7a2ClktJYRod3XVqijfkudg9wJ1LrovnP8n0AWoicXh3SA0GfSnNRVSCL/Xkt/fp7UU3JdJuBFCtKuqItizCBb9FUoy1bkBN8DgiVBVDNYQtew7OMqrzRSio2vzpeBCCCFOob4WSg/Ahv/AjzOgvkbtBXXeVIjqC9UlqspwRHfZ8FKIVibhRgghWpPbpWrX5G5UlYb3/qDOR6epYSjc4KpTw1KyhYIQbULCjRBCtJbqYijaA5s+hQ0fg7NcnR94Ewy8UV0PilTDUIFh3m2rEH5Mwo0QQpypumoozVJza9a+DUW71fmQJDjrITVRuKZU1a0JTwWjxYuNFcL/tbiWd319Pbfffjt79+5ti/YIIYTvcDWoeTW7v4f5j8J3U1WwMQbCiHvgqjcgOBo0napdE91Hgo0Q7aDF4cZoNDJ79uy2aIsQQvgGTVOroA6uhWUvwpzJsHcRoEG3i+C6WdDtAnVPcDR0GQSOePjFZsNCiLZxWsNSV155JXPmzGHKlCmt3R4hhOjY6qqgeB/s/h+sfQdK96vzYakw+kEI76pWQllDVZVhW6xMGhainZ1WuOnWrRt/+ctfWLlyJUOGDCEoKKjJ9QceeKBVGieEEB2Gqx7KD0H2Olj7Luxbps6bgmHoHdDjEjVhuL5WhZqQBDBavdtmITqp0yril5KScuI31Ok69HwcKeInhGgRTYOqAijcCRkfwZYv1dYJAD0vhaG/Ac2lwo89DkJTVGE+IUSravMifpmZmafVMCGE8CnOCjUEtfM7+HkmlB1U5yN7wuiH1F5QtWUQGAHRKWp+TUCLpzIKIVrZGS8FP9zxo5OJckIIf9FQB+XZcOAnNa/mwGp13myH4XdB6vlqXo3bBTH9VMiRHbyF6DBO+z8xZs2aRb9+/bBarVitVvr378+///3v1mybEEK0L7dbVRfevxIWPQPf3KeCjS4A+kyAa9+D+KFQU65q2MSnQ1iKBBshOpjT6rl56aWX+NOf/sR9993H6NGj0TSNFStWMHnyZAoLC3n44Ydbu51CCNG2asvUENSOufDz+1CRo85Hp8GoB9TGls5KsEVBaFcIipCl3UJ0UKc9ofipp57illtuaXL+/fff589//nOHnpMjE4qFEE00OFUhvoM/wk/vQvZadd4aCsPvhqTRUFOshqTCu4ItDvRS3F2I9tbmE4pzcnIYNWrUMedHjRpFTk7O6bylEEK0v8p8yN0M62fB9m/Vhpa6AEi7Ru0FVV8L9VVq5+6QRDAFnfo9hRBed9p1bj799FMee+yxJuc/+eQTunfv3ioNE0KINtNQByX7YPMXasJwVYE6HzcIRt6nlnLXVakCfGEpssmlED7mtMLNU089xfXXX8/SpUsZPXo0Op2O5cuX8/333/Ppp5+2dhuFEKL1VBfDofWw/BXYt1SdC4pUe0F1GaLm3ujNENkbbDFSXVgIH3Ra4ebqq69mzZo1vPTSS8yZMwdN0+jTpw9r1qxh0KBBrd1GIYQ4c656NbdmyxeweroKOeig3zUw8CY1/OSqU6EmJEE2uBTCh7U43NTX13PXXXfxpz/9iQ8++KAt2iSEEK2rphRyNsLylxo3uERVEz77D+DooioO2xMgNEmqCwvhB2RXcCGE/3K71Nyade/B57cfCTZ9r4TLX4fAcDAGquGomH4SbITwE6dVxO/wruBnaunSpYwfP564uDh0Ol2z3nPJkiUMGTIEi8VC165d+de//nXG7RBC+CFnBRz4Eb79PfzvSaguVHNoLntRrYRqcKpVUF3SG+fWyLYJQvgLr+4KXlVVxYABA7j99tu5+uqrT3l/ZmYml156KXfeeScffPABK1as4J577iEyMrJZrxdCdAJuN1Qcgq1fwYpXoTJPne89HtJvB2cVGKwQ00MV5pNCfEL4nQ6zK7hOp2P27NlMmDDhhPf88Y9/5Ouvv2bbtm2ec5MnT2bDhg2sWrWqWd9HivgJ4cfqqiBvGyx/AXbMBzS1EursRyCsK7gbwJGoivEZrd5urRCiBdq0iJ+maSxatIioqCgCAwNPu5GnY9WqVVx88cVNzo0dO5Z33nmH+vp6jEbjMa9xOp04nU7PcXl5eZu3UwjRzjRN7Qm17RtY/qL6M0DPS2HoHVBXDQaLGoYKjpbeGiH8XIsHmTVNo0ePHmRnZ7dFe04qNzeX6OjoJueio6NpaGigsLDwuK+ZNm0aDofD85WQkNAeTRVCtJf6WsheD/P+APP/qIJNYDiMfUYFm4Y61WvTZYiaWyPBRgi/1+JwExAQQPfu3SkqKmqL9pyS7hf/MB0eVfvl+cOmTp1KWVmZ5+vAgQNt3kYhRDupzIcNH8GnN8O2r0FzQ7eL4Mo31HYJASZVdTi6L5jat6dZCOE9pzWh+LnnnuORRx5hxowZpKWltXabTigmJobc3Nwm5/Lz8zEYDISHhx/3NWazGbPZ3B7NE0K0l4Y6KNwFy55XE4c1t9ro8qwpEN1HrYQKSVZza2Q/KCE6ndMKNzfffDPV1dUMGDAAk8mE1dp0Yl5xcXGrNO6XRo4cyTfffNPk3IIFC0hPTz/ufBshhB+qKoKd82HxNChr7IlNPR+GT1ahJ8AIcX0gWJZ3C9FZnVa4eeWVV1rlm1dWVrJ7927PcWZmJhkZGYSFhZGYmMjUqVPJzs5m1qxZgFoZ9dprrzFlyhTuvPNOVq1axTvvvMNHH33UKu0RQnRgrnoo2gPLXoLNn4PmAosDRj8EsQOgvgZCk6W3RghxekvBW8vixYs577zzjjl/66238t5773Hbbbexb98+Fi9e7Lm2ZMkSHn74YbZs2UJcXBx//OMfmTx5crO/pywFF8IH1ZTAzoWw+BkoyVTnks+GUfeCqwFMwWollC1WemuE8FMt+f3donDz6aefMmHCBEwmEwD79u0jISEBvV7tmltdXc1rr73GH/7whzNoftuScCOED9E0FWaWvggbP1Z1asw21VsTNwgaasEeD+GpYA72dmuFEG2ozcKNXq8nJyeHqKgoAOx2OxkZGXTt2hWAvLw84uLicLlcZ9D8tiXhRggf4WqAvUth3u+heI86lzgSRj+g9ozy9NbESW+NEJ1AmxXx+2UO8uKIlhDCn9XXwoZPYMFjUFep5tCMuh/ih6sdvB3xEN5N9eIIIcQvnNaEYiGEaDO15bD8JVjxDzVpOLInnP9E40Wdmjxsj4MAvVebKYTouCTcCCE6joo8VWl46xx13PU8GHG3Winl6AJhqWCR4WQhxMm1ONx89913OBwOANxuN99//z2bN28GoLS0tFUbJ4ToJDQNCnbAnLvh0M/q3ODboOc40AVATD81FCW9NUKIZmjRhOKAZkza0+l0MqFYCNF8bhdkLoOv74Wyg6A3wTl/hKheYLJDVG8IjvR2K4UQXtZmE4rdbvcZNUwIIZpocMLGz+C7R8FZoTa8vOBJtZVCUBRE9pJhKCFEi8mcGyGEdzgrYfkrsOIl1XsT0QPOexx0elVpOLIHGGRfOCFEy0m4EUK0v8oCNXF4y5fqOOUctTcUOlW7JixF5tcIIU6bhBshRPsq3AWzJ0P2WnU8aCL0vAQMFjXPxhYLOp132yiE8GkSboQQ7cPthv0r1YqosizQG+HsRyCyD1hCIKoPBIZ5u5VCCD8g4UYI0fYa6mDT5zD/j+AsB2sYXPCEmkBsj2tcGSU7eQshWkeLNmRZs2ZNk2Xev1xF7nQ6+fTTT1unZUII/1BXBctehG/uV8EmvBtc9gIER6k/x/aXYCOEaFUtCjcjR46kqKjIc+xwONi7d6/nuLS0lBtuuKH1WieE8G3VRfDNQ7Dk72pH7+Sz4cI/q00vo/qopd56o7dbKYTwM62+caZspimEAKBoj5o4fHCNOh54k6o4bLKpwny2aO+2Twjht1p9zo1OVjkI0bm53XBgtQo2pftVz8xZUyA6DQIjIbo3WBzebqUQwo/JhGIhROtx1cOW2TD391BbpioNn/d/an5NSJIqzGe0eruVQgg/1+Jws3XrVnJzcwE1BLV9+3YqKysBKCwsbN3WCSF8R30NrPwnLHkO3PUQngrnPKrm14R3g7CuoJf/nhJCtL0Wb5yp0+mOO6/m8HnZOFOITqimBOY9Chs/VsdJo2HYXWAOVpOG7V2kMJ8Q4oy02caZmZmZZ9QwIYSfcbugeC98fT9krVLnBvwael6mhqSi+kBQuHfbKITodFoUbpKSktqqHUIIX1NdDDu/g8XT1MThACOMfhBiB6jCfJG9VM+NEEK0sxaFm+LiYqqrq4mPj/ec27JlCy+88AJVVVVMmDCBG2+8sdUbKYToQOpr4NAGWPY87P4e0NT2Cec/DrY4taN3RA8wmLzcUCFEZ9WicHPvvfcSGxvLSy+9BEB+fj5jxowhLi6O1NRUbrvtNlwuFxMnTmyTxgohvMjtgrIDsOp1WP8B1Fer890uhP7Xg9kGET1VuAloUX1QIYQfqGtwU1pTR2GlE2e9m4EJIV4rD9OicLN69WpmzpzpOZ41axZhYWFkZGRgMBh44YUXeP311yXcCOFvqorUEu8Vr6iAA2oF1PC7wRajtk+I7AX2WK82UwjRvhpcbkpr6impqmNvYRUrdxfy074Sgsx6Pr5rJHovrSNoUbjJzc0lJSXFc/zDDz9w5ZVXYjCot7n88suZNm1a67ZQCOE9ddVwYI3aPuHwhGGzHdJvh4SRoAPs8RCaBBZZfShEZ+Bya5TX1FNcVceB4mqW7y7kp33FbDlUToNbraY2BOioqK0nJNA7w9MtCjd2u53S0lLPxOI1a9Zwxx13eK7rdDqcTmfrtlAI0f5cDVCSCctehs2fgasOdAHQezykXaOWdQeGqto1QZGyzFsIP+d2a1TUNlBaU8f+ompW7ilkTWYxm7PLqXO5PfclhAUyIiWMEV3DsFm8t29ci8LNsGHD+Mc//sFbb73Fl19+SUVFBeeff77n+s6dO0lISGj1Rgoh2ommQVUhZHwIq16DqgJ1PqY/DL9LTRw22SAsRa2Ikk0vhfBbmqZR6WygtLqegyXVrNxTxOq9xWw6WEptw5FAE+uwcHb3SM7qFk6U3UJpdT12qxFv/idPi8LNX/7yFy688EI++OADGhoaeOyxxwgNDfVc//jjjznnnHNavZFCiHZQVwV7FsOSZyF3gzoXFAFD74LofqDXQ0ii+jIFebWpQoi2U12nAk12STWr9haxam8RGVll1NQfKdAbZTMzpnsEZ3WLINZhocrpot6t4Wxw0yXUSpTdTECA9+JNi8LNwIED2bZtGytXriQmJobhw4c3uf7rX/+aPn36tGoDhRBtzFUPBTth6bOw7b+guVTNmv7XqV280akdvMNSIDDM260VQrSB2noXpdX15JTVsHpPESv3FLH+QCmVzgbPPWFBJs7qpgJNYpiVSqeLBrdGnUsjxmEhwmbGYTViMeq9+CRKi7Zf8Aey/YIQjTQNKvPhpzdhzVtqo0uAxFEw5FYwBqoqw2Fd1YqoAO//gyWEaD3OBhdlNfXkV9SyancxK/YUsj6rlLKaes89DquRUanhjOkeQXJ4ENV1KtAEmvSEB5naNdC02fYLs2bNatZ9t9xyS0veVgjR3pyVsGOeGoIq2qXOOeJh2GQITwGDBUKS1TmjxatNFUK0nnqXm7KaeooqnKzeV8yynQWs219CSfWRQBNsNjAqNZyzukWQGhlMTb0KNA1ujdgO1kNzIi3eODM4OBiDwXDczTNBrZgqLi5utQa2Num5EZ2aqx5yNsKiZ2BPY3VhoxUG3gxdz1OrnuxdICwZLA5vt1YI0QoaGgNNcZWTnzJLWLqrkLX7iymsrPPcYzXqGdE1jDHdIugRbaO2we21HpoTabOem969e5OXl8fNN9/MpEmT6N+//xk1VAjRTjQNyg/Bin/A+llHVRe+CAbeoObYBIapIajgKFnaLYSPc7k1FWgqnazbX8KSXYWs3VdMfsWRci1mQwDDUlSg6RVjp86lAo0bfKaH5kRaFG62bNnCjz/+yLvvvsvZZ59Nt27duOOOO7jppptOuxdk+vTpPP/88+Tk5NC3b19eeeUVxowZc8L7P/zwQ5577jl27dqFw+Hgkksu4YUXXiA8XHYeFuK46qph46dqL6iyg+pceHe1tNsWC6bgxqXdXWRptxA+zOXWqKhV1YLX7i9hyc4CftpXTF75kUBj0geQnhzK6NRw+sY5PMNN6Hw/0BzttCcU19TU8NlnnzFz5kzWrFnDhAkTePfddzGbzc1+j08++YSJEycyffp0Ro8ezRtvvMHbb7/N1q1bSUxMPOb+5cuXc8455/Dyyy8zfvx4srOzmTx5Mt27d2f27NnN+p4yLCU6leJM+OZByFyijs12GDoJ4oappd2OBDUEJUu7hfBJRxfXW7e/hMU7VKDJKav13GPU60hPCmN0t3DSjgo0HWnIqTla8vv7jFdLLV26lCeffJKlS5dSWFjYpO7NqQwfPpzBgwczY8YMz7nevXszYcKE427j8MILLzBjxgz27NnjOffPf/6T5557jgMHDhz3ezidziZVk8vLy0lISJBwI/yb2w27voNvHoLK3MbqwldA3wkQYFCrn0JTIEh6PIXwNZqmUeFsoKy6nnVZJSzekc+azGIOlR4JNIYAHUOSVA9NWhcHbg2fDDRHa7M5N4dlZ2fz/vvvM3PmTKqqqrj55puZMWNGi4JNXV0d69at49FHH21y/uKLL2blypXHfc2oUaN4/PHHmTt3LuPGjSM/P5/PP/+cyy677ITfZ9q0aTz11FPNbpcQPq+uBpY+DytfBXcDBEfDOX+AoChZ2i2Ejzq6WvCGgyX8sL2ANZnFHCyp8dxjCNAxKDGEs7pF0O+oQGPQB/hsoDldLQo3n376KTNnzmTJkiWMHTuWF198kcsuuwy9vuU/qMLCQlwuF9HR0U3OR0dHk5ube9zXjBo1ig8//JDrr7+e2tpaGhoauPzyy/nnP/95wu8zdepUpkyZ4jk+3HMjhF8qzYKv7jsyDJU0CoZMAmuIWtodkiBLu4XwEZqmUVWnatFsPFDK99vy+DGzmANHBRp9gI6BCSGclRpOv/gQoPMGmqO1KNz8+te/JjExkYcffpjo6Gj27dvH66+/fsx9DzzwQLPfU/eLVRmaph1z7rCtW7fywAMP8MQTTzB27FhycnJ45JFHmDx5Mu+8885xX2M2m1s0D0gIn6RpsOt/8M39UJEDOj0MvQOSxqgtFCJ7yhCUED7i8PYHm7PL+N+2PH7cW8z+4mrP9QAdDEwIYXRqBAMTQtBQgcZk6NyB5mgtCjeJiYnodDr+85//nPAenU7XrHATERGBXq8/ppcmPz//mN6cw6ZNm8bo0aN55JFHAOjfvz9BQUGMGTOGv/71r8TGxrbgaYTwE/VOWP4iLHsJ3PVqGGrMFDVZOCQJwrtJb40QHdzh7Q+255bx3ZY8Vu0pYl9R00DTPz6Es7qFMyAhhAB01Ls1jBJojqtF4Wbfvn2t9o1NJhNDhgxh4cKFXHnllZ7zCxcu5Iorrjjua6qrqzEYmjb58JBYJ9tFQgilLBu+uhf2LlLHCSMg/TcQFAoRPcAeDwEB3m2jEOK4nA0uyqrr2ZNfyfwtuazcU8Tu/EoO/zYL0EFaFwdnpUYwKDGEAJ2OBk3DbNATFmQiUgLNCZ3WhOKTyc7OpkuXLs26d8qUKUycOJH09HRGjhzJm2++SVZWFpMnTwbUfJns7GzPtg/jx4/nzjvvZMaMGZ5hqYceeohhw4YRFxfX2o8iRMelabB3MXx1jyrOpwuA9Nsh+WwIjoHIHrLJpRAdUL3LTWl1PfuLqliwNY/luwrZnluO+6j/Pu8bZ+esbhEMTgzBEBCgAo1RBZqIYDMhgRJoTqXVwk1ubi5/+9vfePvtt6mpqTn1C4Drr7+eoqIinn76aXJyckhLS2Pu3LkkJSUBkJOTQ1ZWluf+2267jYqKCl577TV+97vfERISwvnnn8+zzz7bWo8hRMfXUAfLX1ZF+Vz1EBQJZ/1OTRYOTYGIbmCQeWZCdBSHtz84VFrDgi15LN1VwJZD5ap4XqNuUcGM6RZBenIoFqOeBrcbq9HgCTQOqxGrSQJNc7Wozk1paSn33nsvCxYswGg08uijj3Lffffx5z//mRdeeIG+ffsyZcoUbrjhhrZs8xmRIn7Cp1XkqmGo3f9Tx/HDVFG+oGjVW2PvIlsnCNEBuNwa5TX15JbV8v32PJbsLGTDgVLqXG7PPYlhgZzdI5JhyaEEm43Uu1xYjHpCg0xE2SwSaH6hzercPPbYYyxdupRbb72V+fPn8/DDDzN//nxqa2uZN28e55xzzhk1XAhxEplLYc7dagsFXQAMvhW6ngv2WIjoqZZ7CyG85nC14ILKWn7Yns+SHQX8nFVKTb3Lc0+M3cLZPSIZ0TWMsEATtQ1uLMYAQgPVHJqQQCOBplafMdLptOgn+O233zJz5kwuvPBC7rnnHrp160aPHj145ZVX2qh5QghcDWrDyyXTwFUHgRFw1kMQlqr2hApLBYPJ260UolM6XC24pKqOJTsLWLQjn7WZJVQ4Gzz3hAeZGNM9gpFdw4m2W6h1uTDrA7AHGuhmsxASaCLIpD9hGRTRci0KN4cOHaJPnz4AdO3aFYvFwm9+85s2aZgQAqgsgK/vhZ3fqeP4dBhyR2NvTQ+wx8kwlBDt7HBxvZIqJ6v3FqtaNJnFlFbXe+5xWI2M7hbBqK7hxIdZqa13YzToCLYYSLUH4wg0YjMbJNC0kRaFG7fbjdF4ZNdgvV5PUJBsuCdEm9i3Amb/FsoOqGGoQTdD6gVqXk1kD7A4vN1CITqNw4GmtLqONZnFLNqez+q9xRRUHtm7MMikZ2RqOKNTI0iJCMLpcqHXBRBo0pMSEURIoAmb2UBAgASattaicKNpGrfddpun4m9tbS2TJ08+JuB8+eWXrddCITobtwtWvQY//A1cTggMh9EPQnh3NQQV3hX0xlO/jxDijBwdaFbvLWLR9nzW7CuhoOJIoDEbAhieEsbobhH0iLZR1+AmQKfDYtKTZAskNMiEzWJEL4GmXbUo3Nx6661Njm+++eZWbYwQnV51Ecy5D3bOVcddhqhtFGxd1BYKthgZhhKiDR3ZoLKOlXuKWLyjgJ/2FVNYWee5x6QPYHBSCKO7RdA31k6DW0OnU0EnIcxKWJAZu8WAQS8FNL2lReFm5syZbdUOIUTWj/DlnVC6Xw1DDbwRUi+GkHg1DGW2ebuFQvilw4GmpLqOFbuLWLwjn5/2lVBcdVSgMQQwNCmUkakR9Im14dbA3VhcL8FmJjTIhMNqxCiBpkOQ9WZCeJumwerp8P3T0FAL1lAY9SBE9YKwbhCWLMNQQrSyowPNsp2FKtDsL2kyKdhiDGBYchgjuobTI9qGu7EsnNmoJyLYRGiQiRCrCZNBAk1HI+FGCG+qq1FF+bZ8oY5jB8LQOyEksXEY6vibyAohWu5woCmuqmPpzgIW7yhg7f4SymqOBBqrUc/wlDBGdA2jR7SdepebgAAdgSY9kY09NHaLUQJNByfhRghvKc+FT26E7HWADgb8GnqMg9BENXnYHOztFgrh8w4HmqIqJ4t3FLCkMdBU1B6pQxNk0jM8JZwRXcNIjQqm3uXGEBBAoFlPZPDhScEGGXLyIRJuhPCGQxtUsCk7CAYLjHpA1bAJ7wYhSaCXv5pCnC5PoKl08n1jpeB1WSVUOY9UCraZDYzoGs6wlDC6RgRR79Yw6HUEmw1E2804rCbsVlnl5KvkX1Ah2tvWr9U2CnWVjZteToHoNDXHJjjK260TwicdXrZdWOnkf1vzPIGmuu5IoLFbDIzsGs7Q5DCSIwJp0DRM+gBsFiPRjXs52SxSh8YfSLgRor1omtrN+4e/guaCyN4w4l6I6qH+bJGNXIVoqarDPTTb8vlhRz7r9jcNNCFWIyNTwxmaFEZieCANbg2LIQCb1aA2pww0EmySQONvJNwI0R4anPDNg7DhI3Xc9VwYNFHNrYnsCUaLV5snhC+prlOB5n/b8lm0XQWaqqMDTaCRUV3DSU8OJSE00LNkOzTQRIRN1aAJlq0P/JqEGyHaWmUhfHITHFitjgfepCYOR/SA8FSZXyNEM9TUuVQPzY48ftiWz9p9vwg0ViOjUo8KNGhYjHpCrGq3bYfVSKBsTtlpyL+qQrSl3C3w8Q2qMJ/eDKPuhYSRan6NI0GqDQtxErX1LoqqnPywLZ//bctn7f7iJpOCPUNOyWEkhFpxayrQhAYdHWjk11xnJJ+6EG1lx3xVcdhZrvaHOuthiOkPUb1l4rAQJ1Bb76K4ysmi7QUs3JbH2n0lVDqPLNt2NPbQDE0OIzE0EJfmVj00gSai7BJohCL/DxCiLax6HRY+Ae4Gtbx71AMQ0ROie8tu3kL8grNB9dAs3l7Awq15/HScQDOycdl2YlggLk3DbAggNPBID02QWX6diSPk/w1CtCZXA8z9Hax7Tx0njYYht0NEN4jsBUarV5snREdR1+CmqMrJkh0FLNiax0+ZxVQcFWjsFgMjUyMYnnzUKiejBBrRPPL/DCFaS00JfHoLZC5Vx/2vh97jVc9NeDfZH0p0eocDzeId+Szcmn9MoLFZDIxKjWBYcijJ4aqwnsUQgCPQSJRd1aEJkknBohkk3AjRGgp3wUfXQ9EeFWJG3KN6bSJ6qIrDAVK2XXROdQ1uCivVpOCF2/KOmRRssxgY1TjkpAKNG4tBjyPQSKTNTEigSQKNaDEJN0KcqT2L4PPbVc+NJURVHI5tnDhsi/F264Rod3UNbvIravl+Wz7/a5wUXFN/JNA4rEZGdA1naHIoyeGqUrBZH4DdaiS6sYdG6tCIMyHhRogz8dM7MO+P4K6H0BQY9aAqyhfdG6yh3m6dEO2mrsFNXnktC7fmsXBbHuuzSqitd3uuhwYaGZkaQXpSKIlhgTS43ZgNKtBE2SyEBEqgEa1Hwo0Qp8Ptgu8egx//pY4ThkP6HWpuTVRvMAV6t31CtIO6Bjc5ZTUs2JLH/7blsT6rlDrXkUATHmTyFNaLc1g9lYIdVjXkZLcasUmgEW1Awo0QLVVbDp/dDnv+p477XgV9rlTVhiN7yMRh4dfqGtxkl9Qwf0sO32/LZ8PBUupdmud6lM3MqNRwBieGEu1Q24pYjXpCGufQ2C1SKVi0PQk3QrRE8T41cbhgOwQYYNhdkHK2WuYtE4eFn6prcHOgpJp5G3P4fns+m7LLaHAfCTSxDgujuoYzKDGUKLsJ0BFo0hMWbCI8SAUaq0nvvQcQnY6EGyGaa/9K+ORmqC4Csx3OeghiB6lhKHust1snRKuqa3Czr7CKeZtVoNmcXcZReYb4UCsjuoYzMD6EiGATen0AQSa9Z4WT3WrAbJBAI7xDwo0QzfHzB/DtFHA5ISQRRj+kJg5H9YHAMG+3TohW4WxwsTu/km835rB4RwHbcsvRjgo0yeGBDE8JZ2BCCKFBJgwBOoItBiKDzYQEGrFbjRj10nspvE/CjRAn0+BUE4d/elsddxkCQ+9SFYejeoMpyLvtE+IM1da72JZTzrebDrFkRyG78iubXO8aGcTw5DD6xzsIDTZh0gdgsxiJaqwSbLMY0QfI/BnRsUi4EeJEijPhs9sgJ0Md9x4PadeqicMRPcBg8mbrhDhtNXUuMg6UMndTDkt3FbC/qLrJ9V4xNtKTQknr4iA0yIRZr6oERwSbcQQaCTYZCJBAIzowCTdCHM/mOfDfB6C2DAxWGHE3xA9VQ1GhyRAgcwmEb6msrWft/hLmbsph+e5CDpXWeq4F6KBvnIMhSaH0jbNjtxqxGAMIsZo8S7alSrDwJRJuhDhaQ91Rw1AahHWFEfc2LvPuCbZYkH/ghQ/QNI2K2gZW7S1i3qYcVuwuoqDS6bluCNDRPz6EIUkh9Im1E2jSE2g2EBZoIjxYDTnJCifhq7webqZPn87zzz9PTk4Offv25ZVXXmHMmDEnvN/pdPL000/zwQcfkJubS3x8PI8//jiTJk1qx1YLv1S8Dz679cgwVK/LVA2bkCRVv8bi8GbrhDglTdMoqa5j+a5C5m3OZdXeIkqr6z3XTYYABiWEMDgxlB4xwQSbDQSaDEQEmwgNMmG3GLEYJdAI3+fVcPPJJ5/w0EMPMX36dEaPHs0bb7zBuHHj2Lp1K4mJicd9zXXXXUdeXh7vvPMO3bp1Iz8/n4aGhuPeK0SzbZkD3xw9DDUZ4odBWCqEd5XCfKLDcrs1iqvrWLQ9n/mbc/kxs5jKo3bathr1pCeHMjAhhO5RQQSa1DYHETaTWrJtMWIyyAon4V90mnb0Qr/2NXz4cAYPHsyMGTM853r37s2ECROYNm3aMffPnz+fX//61+zdu5ewsNNbflteXo7D4aCsrAy73X7abRd+oqEOFjwGa34xDBXRXU0atsXIMJTocNxujYIKJwu25rJg67EbU9osBoYmh9K/SwipUUFYTQZsZgNRjTVobBYDBlmyLXxMS35/e63npq6ujnXr1vHoo482OX/xxRezcuXK477m66+/Jj09neeee45///vfBAUFcfnll/OXv/wFq9V63Nc4nU6cziPjzOXl5a33EMK3/XIYquelkHa12gAzsgeYbd5snRBNuN0aeeW1LNiay/wtefy8vwRnw5F9nMICTaQnhzIgPoSUiCCsJrVkO9puwW4xYrPICifReXgt3BQWFuJyuYiOjm5yPjo6mtzc3OO+Zu/evSxfvhyLxcLs2bMpLCzknnvuobi4mHffffe4r5k2bRpPPfVUq7df+LhfDkMN/y0kjoCwbhCWLMNQokM4HGjmb8nluy25/JxVSt1RgSbKZmZoYw2axDArVpOB0EAT4cEmHFbZZVt0Xl6fUPzLv3iapp3wL6Pb7Uan0/Hhhx/icKjJnS+99BLXXHMNr7/++nF7b6ZOncqUKVM8x+Xl5SQkJLTiEwif0lAHCx6HNW/RZBgqsmfjMFT0Kd9CiLbkdmvkltUyb0sO323JY31WSZONKaPtZoYlh9E/PoT4UCtBZgOhQaoGjWxKKYTitXATERGBXq8/ppcmPz//mN6cw2JjY+nSpYsn2ICao6NpGgcPHqR79+7HvMZsNmM2m1u38cI3leyHT285ahhqXGNRvq4Q3h3MwV5tnui83G6NQ2U1zNuUw3db88jIKm2yMWWM3cKwFNVDczjQhAWaiLDJppRCHI/Xwo3JZGLIkCEsXLiQK6+80nN+4cKFXHHFFcd9zejRo/nss8+orKwkOFj9Itq5cycBAQHEx8e3S7uFj9r6FXx9vxqGMlph2G8haZQKNSGJoPd6J6boZNxujezSGuZtzmH+5lw2Hmy603ZciIVhyeH0j3cQ5zATbDESFmwiIsjcWGRPAo0QJ+LVf9GnTJnCxIkTSU9PZ+TIkbz55ptkZWUxefJkQA0pZWdnM2vWLABuvPFG/vKXv3D77bfz1FNPUVhYyCOPPMKkSZNOOKFYdHKuelWUzzMMlaqqDUf2Ul/Bkd5uoehE3G6Ng6U1zN2Yw3dbctmYXYbrqEATH2plWHIY/eIdxDksBFmMRASZCAuWGjRCtIRXw831119PUVERTz/9NDk5OaSlpTF37lySkpIAyMnJISsry3N/cHAwCxcu5P777yc9PZ3w8HCuu+46/vrXv3rrEURHVpIFn90Ch9ar4x7joP91KuBEdAdToHfbJzoFt1sjq6TaE2g2Z5fjOqoCR2JYIOlJoaqHJkQNOUUGm1VRPasBs0ECjRAt5dU6N94gdW46ia1fw9f3HRmGGnonpJwN4d3UMJTsDSXaUIPLza68ShZszeV/2/LZcqiMozpoSA4PJD2psYcmxEKQyUCkzeypEixF9YQ4lk/UuRGiTbjq4bvHYc2beFZDDb8botPUiqigcG+3UPipKqfax+n7bXms3F3E/uKmO213jQgiPTmUtDgHsQ4rwWYDkXYToYEm7FYjRimqJ0SrkXAj/MeJhqHCu0NEN9WDI0Qr0TSN3PJavt+Wzw/b8/hpXwkVtUe2PQjQQY9oGwPiHfSLdxBjtxJsOWrISaoEC9FmJNwI/7D1K/j6AagtPTIM1fUcVbvGHg8B8ktEnDmXW2NzdikLt+azZGc+Ww9VNJk/E2jSMyA+hLQudnrG2AgNMhFkMhAt2x4I0a4k3AjfVlkAcx+BrbPV8eFhqJj+aguFwNPbg0yIwyqd9SzbWcj32/NYsbuInLLaJte7hFgZEO+gT5ydrpHBBJn1hFhVlWCbxYjNLNseCNHeJNwI36Rp8PMs+N+TUFOizvW8FPpdCxE9ITwVjBbvtlH4JE3TyC6pYeHWPH7Yns+6rBKq645sSqkP0NEn1k5anJ1esXa6hFgJNOmJCDYTEmjEJkX1hPA6CTfC9xTuhm8ehP3L1bEjAdJvh9hBaom3vYsMQ4kWaXC5ycgqZcG2PJbuLGBHbgVHLyO1WwwMTAihT5ydXjE2zxBTlM2CzWIg2CzDTUJ0JBJuhO9wNcDyl2HZi9BQAwEGtYt3z0shNEkNSVkcp34fIYCaugYW7Shg/uZcVu4ppLCyrsn15PBA+seH0DvGRtfIIIIsRsKCjIQFmrFZDLKHkxAdmIQb4RsOrlXbJ+RvVcdRfWDwrep/w1PBFiu9NeKUqp0NfL89n7mbcli2q5BK55HVTSa9jr5xDtK62Okd6yDGYVbLtYPVdgc2qT8jhM+QcCM6NmeVmlez9l3QXGAMhIE3Qur5qqcmJEkqDYuTqnY2sHBbHnM35bB8dyFVziPzZ+wWA0OSQukbZ6dnjJ2QQCMOq5HwYNU7E2ySycBC+CIJN6Lj2jEfvp0C5dnqOHEkDLjhyIThoAiQYQFxHFW19SzYls/cjTms2FPYZEKww2okPSmUAQkOekbbcViNRNhMOKxqHo3s3ySE75NwIzqeygKY+3vYOkcdB4bD4Fsg+SwI7QqOeDCYvNpE0fFU1tbz3RbVQ7NyTxE19UcCTWigkSGHA02UHXugkWibGUegFNMTwh9JuBEdx+Hl3QufUMX40EGPsdD3aojsDqEpYA3xciNFR1JRU8/8LbnM3ZTDqr1F1Na7PdfCgkykJ4YyICGE7tHB2K1GYuxmHFa13YFehpuE8FsSbkTHULRHTRjev0IdH17e3SX9qAnDMlwgoLymjnmbVQ/N6r1FOBuOBJrwIBPpyaEMiA+hW3QwIVYjUZ7qwBJohOgsJNwI73K71NLuZS9Ag1Mt7+57FfS6HMK7QliKTBgWlFXXMXdTLnM35/Dj3mLqXEcCTWSwiSFJYQxIcNA9OhiH1aQCTeMcGpkQLETnI+FGeM/BtfD1fZC/TR0fXt4dO6BxwnCkTBjuxCpq6/nvhhz+u/EQa/YVU+86UlYvymZWk4ITHXSLVIEm2m5RS7ZluwMhOj0JN6L91VXBwidh7TugucEYBANvgO4XQ3g3NSQlE4Y7pWpnA/M25/DfjTms2F3UpIcmxm5RgSY+hNSoQByBJqJsFhyBKtBIQT0hxGESbkT72jEfvn0Yyg+p48SRqm5NVF81DGUN9W77RLurrXOxcFseX284xPJdhU1WOUXbzQxNDmNgQgipEUGEBJmItJlxWI0ES6ARQpyAhBvRPqoKVc2arV+p48PLu1POVUNQ9jiZMNyJ1De4WLSjgK8yDrFkZz6VRxXWCw8yMTQ5jEGJIfSICiYkyESU3YLDaiRItjwQQjSDhBvR9rb9V62EqinGs7y737UQ2atxwnCQt1so2oHL5WbZ7kK+yjjE99vzKK85svWBw2pkaHKo2pwy1k5oYw9NSKBJAo0QosUk3Ii2U1cN3/4ONvxHHTviIf0OSBihemuCo2TCsJ/TNI3Ve4uYs/4Q/9uWR1HVkc0pg80G0pNCGZQUQlqsnZAgNSlYhpyEEGdKwo1oGwfWwBe/gdL96rjHOBh0s9o6ITQRDGbvtk+0GU3TWJ9Vyuz12Xy3JZf8CqfnmtWoZ0hSKIMSHfSLdxAWaFaBRiYFCyFakYQb0bpcDbB4Gix/WW10aQ2FYXdB1/MhojsEhXu7haKNbM4uY/b6bOZvziW7tMZz3mwIYFBiCIMSQhiQGEJEkAQaIUTbknAjWk/RXvj8dsjJUMcJwyH9Tojtp+bWSG+NX9E0jZ+zSliwJY/vtuSyr6jac82o1zEgPoRBiaEMSnIQGWwhRurQCCHaiYQbceY0Dda+Cwseh/oaMFjVSqhev4LInjK3xo+U1dTzw/Z8vt+Wx8o9RRQfNYdGH6CjXxcHgxJDGJIUSpRN9dBIpWAhRHuTcCPOTFUhzLkbdi1Qx5G9YPhkiB+qJg0brd5tnzgjmqaxPbecBVvzWLKjgA0Hy3C5j1QKNhkC6BNrp18XO+lJYcSGWIiymQkNNEugEUJ4jYQbcfp2zIOv7oXqIlWjpu/V0P/XENVL1a2R3hqfVFvXwJJdhfxvax7LdxeSU1bb5HqUzUy/Lg76xtlJi3MQGmwiMtgkm1MKIToMCTei5eprYN4f4OdZ6tjeBYbfDSlnqe0TzDbvtk+02P6iKhZsyWPRjnzW7S9pstO2PkBHr2gbfeJs9E8IITk8iLBAE2HBKsxIHRohREcj4Ua0TPbP8PkdULJXHXe7GNJvh+i+qo6NVBn2CQ0uN6v2FLFwWx7LdhWQWVjd5HpIoJF+cQ7SutjpF+8g0mYhsjHM2CxGTIYAL7VcCCFOTcKNaB63C5Y+B0tfAHcDWEJg2J3Qfaxa4m0N8XYLxSkUlNfy3dY8Fm3PZ3VmEVVHbXmg00G3yGD6xNkZEO+ge7TN0zsTbDZIUT0hhE+RcCNOrWQffD4Jstep4/ihMGwydBkEIYmgN3q1eeLEduaWMyfjED9sz2dHbgXaUdeCzYbGeTN2BiaEEBNiJSLIpJZrS++MEMKHSbgRJ6ZpsP4DNb+mvhoMFhg0EfpepZZ4S0G+DmlnboWnOvDewqom1xLDAkmLs9M/wUGfWAfhQdI7I4TwPxJuxPFVF8Oce2DnPHUc3h1G3geJI6QgXwe0I7eCOesPMn9LHplHBRq9TkfvWJsqppfoICEsSHpnhBB+z+vhZvr06Tz//PPk5OTQt29fXnnlFcaMGXPK161YsYJzzjmHtLQ0MjIy2r6hncmu/8GcyVBVADo99L1S9dhE9ZaCfB3Ijhw15DRvc06T6sCHA83gpFCGp4QRHxpIpE3VnQkySe0ZIYT/82q4+eSTT3jooYeYPn06o0eP5o033mDcuHFs3bqVxMTEE76urKyMW265hQsuuIC8vLx2bLGfq6+F7x6Dte+oY1sMjLgXup6nCvKZAr3bPsH2nHLmZKj9m5oEmgAVaIYkqkDTpTHQOKxGgsxe/28YIYRoVzpN07RT39Y2hg8fzuDBg5kxY4bnXO/evZkwYQLTpk074et+/etf0717d/R6PXPmzGlRz015eTkOh4OysjLsdvuZNN+/HNoAX0yCot3qOPV8GHoXxPYHWywEyPCFN2iaxo7GOTTzt+Sy/xeBpk+snSGJIQyTQCOE8HMt+f3ttX8B6+rqWLduHY8++miT8xdffDErV6484etmzpzJnj17+OCDD/jrX/96yu/jdDpxOp2e4/Ly8tNvtD9yu2DZS7Dk72qJt9kOQ++EPuOlIJ+XHN7yYM76Q8zfnMv+4iOBxhCgo3esnSFJIQxLlkAjhBDH47V/DQsLC3G5XERHRzc5Hx0dTW5u7nFfs2vXLh599FGWLVuGwdC8pk+bNo2nnnrqjNvrl0r2wxd3wMGf1HHcIBh1P3QZAo4EKcjXjjRNY1vjHJr5m3PJ+kWg6XM40KSEERcSSJRdBZpAkwQaIYT4Ja//y/jLpaeaph13OarL5eLGG2/kqaeeokePHs1+/6lTpzJlyhTPcXl5OQkJCaffYH+gabD+Q5j/B6irAr0ZBt2s9oWK7A7WUG+3sFM4eshp3vECTdyRIScJNEII0Xxe+1cyIiICvV5/TC9Nfn7+Mb05ABUVFaxdu5b169dz3333AeB2u9E0DYPBwIIFCzj//POPeZ3ZbMZslmXLHtXF8NV9sONbdRyWCqMfhKTREJokBfnawe78Cr78OZu5m5qucvIEmqRQhieHERtilUAjhBCnwWv/YppMJoYMGcLChQu58sorPecXLlzIFVdcccz9drudTZs2NTk3ffp0fvjhBz7//HNSUlLavM0+b/f3MHsyVOWDLgD6TID0O9Qu3kER3m6dX9tbUMmc9dl8uymHPQVH6tB4hpySJdAIIURr8eq/nlOmTGHixImkp6czcuRI3nzzTbKyspg8eTKghpSys7OZNWsWAQEBpKWlNXl9VFQUFovlmPPiF+prYMH/wU9vq+PgaBh5P3S/EMK6SkG+NrK/qMoTaHbmVXrO6wN09IqxMTQ5lOFdw+gScmRSsAQaIYQ4c179l/T666+nqKiIp59+mpycHNLS0pg7dy5JSUkA5OTkkJWV5c0m+r6cDWpfqMNLvLuep2rXxPZTIUcK8rWqA8XVfL3hEN9sOMT23ArP+QAd9Iy2MTQljBFdjxTWk0AjhBCtz6t1bryh09S5cbtg+cuweNqRJd7Dfgt9rpCCfK3sUGkNX2Vk8+3GHDYfOlJqQKeDHlE20pNDGZkaRlJ4EJHBFhxWI1aTrEQTQoiW8Ik6N6INHW+J9+iHID4dbHFSkK8V5JXX8vWGbL7ZkMPGg2We8zogNSqYocmhjE6NIDkiiIhgswQaIYRoRxJu/ImmQcZ/YO4jUF+l5tIMnAgDboDIHmDx456qdlBQ4eSbDYf4ZuMhMrJKOdzlqQO6RgaR3hhoukYGS6ARQggvknDjL6qL4at7YcdcdRyWCmOmqCXeIYlSkO807Sus4rstuSzcmsfPWSW4jxrETQ4PZGhyGKO7RdA9KpiIxjk0FqP8rIUQwpsk3PiDX+7i3WcCDPsNRPaCwDBvt86n1Lvc/JRZzPwtuSzeUdCksB5AYlggQ5NDOat7BD2ibBJohBCiA5Jw48uOWeIdowrydbsIwpKlIF8zFVU6+X57Pgu35LFyTyFVdS7PtQAdpEYGMyDewchuEfSOsREeLIFGCCE6Mgk3vupQhpo07Fnifb7aFyqmHwRHerVpHZ3ax6mC77bk8v32PLZkl3P0ksFgs4E+sTYGJ4UyLDmMhLBAHIFG7BYJNEII4Qsk3Pia4+3iPeJu6N24xNto8XYLO6SaOhfLdxfw3ZY8lu4sIL/C2eR6lxAr/ePtDE0OY0BCCFE2CzaLgWCzAYNeVpcJIYQvkXDjS0r2wRd3wsE16jhuMJw1pXGJd4wU5PuF7NIaFm7JZeG2PH7KLKHO5fZcM+p19Ii2MTghlKFdQ+kWFUxYoBmbxUCgSX/czVuFEEL4Bgk3viJzKXz0a7WLt8ECg26BgTepXbxNQd5uXYfgcmv8vL+YBVvz+GF7AXsKKptcDw00ktbFQXpSKEOSQ4kPsWK3mgg2GzAZpHdGCCH8hYQbX7BvBXx4HTTUQHg3GPMIJI8Ge5dOX5DvYEk1y3YWsnRXASv3FFFWU++5ptNBSngQ/eNDGJYSSloXOxHBargpyGQgIEB6Z4QQwh9JuOnosn6ED69RwSY6DS59AaL7dtqCfMVVdSzfVciSnQWs3ltEdmlNk+tWo54+sTYGJYUyPCWMlIggHFYTNotBJgMLIUQnIeGmIzu4Fj64CuqrIaqPCjZdBneqXbyrnA2s3lvE0p2qZ2ZXftOhpgAdJIQF0ifWzsCEEIYkhRJtt2C3GAm2GNBL74wQQnQ6Em46quyf4d8ToK5SFePrJMGmrsHNz1klLN1ZwIrdhWw+VI7L3XRv11iHhV4xNvrHhzAo0UFCaBA2q1rZJDtsCyGEkN8EHVHOBhVsnBUQ0R0ufRG6DPHLYON2a2zNKWfJzgKW7ypk/YESauvdTe4JCzKpMNPFwcDEEFIjg3FYjQSZZWWTEEKIY0m46WjytsCsK6C2TE0evvQltdTbT+rXaJpGZmEVS3epMLMms5jy2oYm9wSbDfSMCSati4PBCaH0irXhsJoIMutlIrAQQohTknDTkeRvh/fHQ00JhKbAZS9BwjCfDzY5ZTWs2K3mzazeW3RMAT2zIYDuUcH07eJgUEII/eLthAaaCW5c1STzZoQQQrSEhJuOomAnvP8rqC6CkCSfDjaFlU5W7S5i6W4VZg4UN13RpA/QkRIRRFqcnQEJIQxODCHCZiHYZCDIrJeKwEIIIc6IhJuOoGgPvH+Z2tXbkQC/egmSRoLR6u2WNUtZTT2r9xaxfFcBq/YWs/sXK5p0OkgMDaR3rI0BCSEMSQwlNsRKsNlAkBTQE0II0cok3Hhb8V5471KozFdF+S57CRJHdehgU13XwE/7SljWuDx7e245v1jQRFyIhV4xdgbEOxiSFEpiWJAaZjLrMRuk3owQQoi2I+HGm0r2w3u/gopcsMWpYJN8FpgCvd2yJmrrXazPKmXZrhMvz46ymekVq1Y0DUoMpWtEEDarkWCzFM8TQgjRviTceEvpAXjvMijPhuAYuOwFSBnTIYJNg8vNxuwylu8qZPnuQjIOlFLX0HR5dmigkV4xNrWiKTGU7tHB2BvDjNUoy7OFEEJ4j4Qbbyg/pHpsyg5AUBRc9iJ0PddrG2BW1zWw9VA5a/eXsGJXIeuySqiuczW5x2Yx0DPaRloXO4MTQ+kVY8cR2FhrxqiX5dlCCCE6DAk37a0iV/XYlO6DwAhVebgdg01tvYutOeVsOFBKxoFSNmeXkVlYdcycmUCTnh7RwfSJVcuz+3SxyfJsIYQQPkHCTXuqzFfBpngvBIbDpc9DtwvAHNwm387Z4GJ7TgUbDpSyvjHI7C2owqVpx9xrtxhIDAukd6ydgQkO0uIdhAeZsZmNsjxbCCGET5Fw016qClUdm6LdYA2Fcc9B94taLdjUNbjZmdc0yOzOr6Thl10yqArAieGBdI0IoltkMD1ibKREBGFr7JWR5dlCCCF8mYSb9lBdrCoPF+wAS4gKNj3Ggtl2Wm9X73KzK6+SDQfV0NKmg2Xsyq+g3nVskAky6UkMCyQlIohuUcH0agwy9kATVqMeq1GPxRggE4CFEEL4DQk3ba2mBN6/HPK3gsUB4/4OPS5pUbDJr6hlTWYxq/YUseFgKTtzK6lzuY+5L9CkJyFU9cikRgfRK9pOt6ggbFYJMkIIIToPCTdtqbYM/n0l5G1SYeaSadDzMrDYT/qynLIaVu8pYuWeItbsK2Z/UfUx91iMAapHJjyI1Khg+sTZ6R4ZjM1qVEHGpMdskCAjhBCi85Fw01Zqy1WwObQeTMEwdhr0+tVxg82B4mp+3FvEij1FrMksJru06V5MOlTF357RNnrG2Okda6NnjA2bRYKMEEII8UsSbtqCsxI+uBqy14ExCMY+A30uB4sDTdPYV1TN6j1FrNhTyNp9JeSW1zZ5uU4H8SFWesXYSetiZ0hSKEnhQQSa9ASZDRJkhBBCiJOQcNPa6qrgw2vh4BowWtEu/gt7Ii9i1foSVu7ZzU/7iimsrGvykgAdJIYF0ivGTr8udgYnhRIfGkiQWfZiEkIIIVpKwk1rqq9B+8/16LJWUhdg5Xnb//H53HhKatY3uU0foCOpsabM4Yq/cY27ZAdKmBFCCCHOiISbVrI/r4jK966lb806KjULt9T8kZ+rU4AGjHodyeFBjWHGwaBEBzF2FWakpowQQgjRurwebqZPn87zzz9PTk4Offv25ZVXXmHMmDHHvffLL79kxowZZGRk4HQ66du3L3/+858ZO3ZsO7f6WKHFG+lSvZ5qzNzleoTayP5MiAujX3wIgxIdRNksqmfGJGFGCCGEaEteDTeffPIJDz30ENOnT2f06NG88cYbjBs3jq1bt5KYmHjM/UuXLuWiiy7imWeeISQkhJkzZzJ+/Hh+/PFHBg0a5IUnOMLe+zwWD/g7AQ01TB34K0Ij4zw9M0bZukAIIYRoNzpNO85GQ+1k+PDhDB48mBkzZnjO9e7dmwkTJjBt2rRmvUffvn25/vrreeKJJ4573el04nQ6Pcfl5eUkJCRQVlaG3X7yejOnQ3O70AXInBkhhBCiNZWXl+NwOJr1+9trXQp1dXWsW7eOiy++uMn5iy++mJUrVzbrPdxuNxUVFYSFhZ3wnmnTpuFwODxfCQkJZ9TuU5FgI4QQQniX18JNYWEhLpeL6OjoJuejo6PJzc1t1nu8+OKLVFVVcd11153wnqlTp1JWVub5OnDgwBm1WwghhBAdm9cnFP+yGJ2mac0qUPfRRx/x5z//ma+++oqoqKgT3mc2mzGbzWfcTiGEEEL4Bq+Fm4iICPR6/TG9NPn5+cf05vzSJ598wh133MFnn33GhRde2JbNFEIIIYSP8dqwlMlkYsiQISxcuLDJ+YULFzJq1KgTvu6jjz7itttu4z//+Q+XXXZZWzdTCCGEED7Gq8NSU6ZMYeLEiaSnpzNy5EjefPNNsrKymDx5MqDmy2RnZzNr1ixABZtbbrmFV199lREjRnh6faxWKw6Hw2vPIYQQQoiOw6vh5vrrr6eoqIinn36anJwc0tLSmDt3LklJSQDk5OSQlZXluf+NN96goaGBe++9l3vvvddz/tZbb+W9995r7+YLIYQQogPyap0bb2jJOnkhhBBCdAw+UedGCCGEEKItSLgRQgghhF+RcCOEEEIIvyLhRgghhBB+RcKNEEIIIfyKhBshhBBC+BWv7y3V3g6vfC8vL/dyS4QQQgjRXId/bzengk2nCzcVFRUAJCQkeLklQgghhGipioqKU+5K0OmK+Lndbg4dOoTNZmvW7uO+rLy8nISEBA4cOOD3BQvlWf1XZ3peeVb/1Zmet62eVdM0KioqiIuLIyDg5LNqOl3PTUBAAPHx8d5uRruy2+1+/5fpMHlW/9WZnlee1X91pudti2dt7j6SMqFYCCGEEH5Fwo0QQggh/IqEGz9mNpt58sknMZvN3m5Km5Nn9V+d6XnlWf1XZ3rejvCsnW5CsRBCCCH8m/TcCCGEEMKvSLgRQgghhF+RcCOEEEIIvyLhRgghhBB+RcKND5s+fTopKSlYLBaGDBnCsmXLTnjv4sWL0el0x3xt3769HVt8epYuXcr48eOJi4tDp9MxZ86cU75myZIlDBkyBIvFQteuXfnXv/7V9g1tJS19Xl/9bKdNm8bQoUOx2WxERUUxYcIEduzYccrX+epnezrP66uf7YwZM+jfv7+niNvIkSOZN2/eSV/jq58rtPx5ffVz/aVp06ah0+l46KGHTnqfNz5bCTc+6pNPPuGhhx7i8ccfZ/369YwZM4Zx48aRlZV10tft2LGDnJwcz1f37t3bqcWnr6qqigEDBvDaa6816/7MzEwuvfRSxowZw/r163nsscd44IEH+OKLL9q4pa2jpc97mK99tkuWLOHee+9l9erVLFy4kIaGBi6++GKqqqpO+Bpf/mxP53kP87XPNj4+nr///e+sXbuWtWvXcv7553PFFVewZcuW497vy58rtPx5D/O1z/VoP/30E2+++Sb9+/c/6X1e+2w14ZOGDRumTZ48ucm5Xr16aY8++uhx71+0aJEGaCUlJe3QurYDaLNnzz7pPX/4wx+0Xr16NTn329/+VhsxYkQbtqxtNOd5/eWzzc/P1wBtyZIlJ7zHnz7b5jyvv3y2mqZpoaGh2ttvv33ca/70uR52suf19c+1oqJC6969u7Zw4ULtnHPO0R588MET3uutz1Z6bnxQXV0d69at4+KLL25y/uKLL2blypUnfe2gQYOIjY3lggsuYNGiRW3ZTK9ZtWrVMT+bsWPHsnbtWurr673Uqrbn659tWVkZAGFhYSe8x58+2+Y872G+/Nm6XC4+/vhjqqqqGDly5HHv8afPtTnPe5ivfq733nsvl112GRdeeOEp7/XWZ9vpNs70B4WFhbhcLqKjo5ucj46OJjc397iviY2N5c0332TIkCE4nU7+/e9/c8EFF7B48WLOPvvs9mh2u8nNzT3uz6ahoYHCwkJiY2O91LK24Q+fraZpTJkyhbPOOou0tLQT3ucvn21zn9eXP9tNmzYxcuRIamtrCQ4OZvbs2fTp0+e49/rD59qS5/Xlz/Xjjz/m559/5qeffmrW/d76bCXc+DCdTtfkWNO0Y84d1rNnT3r27Ok5HjlyJAcOHOCFF17o8H+ZTsfxfjbHO+8P/OGzve+++9i4cSPLly8/5b3+8Nk293l9+bPt2bMnGRkZlJaW8sUXX3DrrbeyZMmSE/7C9/XPtSXP66uf64EDB3jwwQdZsGABFoul2a/zxmcrw1I+KCIiAr1ef0wvTX5+/jEJ+WRGjBjBrl27Wrt5XhcTE3Pcn43BYCA8PNxLrWpfvvTZ3n///Xz99dcsWrSI+Pj4k97rD59tS573eHzlszWZTHTr1o309HSmTZvGgAEDePXVV497rz98ri153uPxhc913bp15OfnM2TIEAwGAwaDgSVLlvCPf/wDg8GAy+U65jXe+mwl3Pggk8nEkCFDWLhwYZPzCxcuZNSoUc1+n/Xr1/tEd29LjRw58pifzYIFC0hPT8doNHqpVe3LFz5bTdO47777+PLLL/nhhx9ISUk55Wt8+bM9nec9Hl/4bI9H0zScTudxr/ny53oiJ3ve4/GFz/WCCy5g06ZNZGRkeL7S09O56aabyMjIQK/XH/Mar322bTpdWbSZjz/+WDMajdo777yjbd26VXvooYe0oKAgbd++fZqmadqjjz6qTZw40XP/yy+/rM2ePVvbuXOntnnzZu3RRx/VAO2LL77w1iM0W0VFhbZ+/Xpt/fr1GqC99NJL2vr167X9+/drmnbss+7du1cLDAzUHn74YW3r1q3aO++8oxmNRu3zzz/31iO0SEuf11c/27vvvltzOBza4sWLtZycHM9XdXW15x5/+mxP53l99bOdOnWqtnTpUi0zM1PbuHGj9thjj2kBAQHaggULNE3zr89V01r+vL76uR7PL1dLdZTPVsKND3v99de1pKQkzWQyaYMHD26ypPTWW2/VzjnnHM/xs88+q6WmpmoWi0ULDQ3VzjrrLO3bb7/1Qqtb7vCyyV9+3XrrrZqmHfusmqZpixcv1gYNGqSZTCYtOTlZmzFjRvs3/DS19Hl99bM93jMC2syZMz33+NNnezrP66uf7aRJkzz/NkVGRmoXXHCB5xe9pvnX56ppLX9eX/1cj+eX4aajfLY6TWuc2SOEEEII4Qdkzo0QQggh/IqEGyGEEEL4FQk3QgghhPArEm6EEEII4Vck3AghhBDCr0i4EUIIIYRfkXAjhBBCCL8i4UYIIYQQfkXCjRCiU7vtttuYMGHCKe+bOHEizzzzTLPe85prruGll146w5YJIU6XhBshxBnLz8/nt7/9LYmJiZjNZmJiYhg7diyrVq3ydtNaxcaNG/n222+5//77m3X/E088wd/+9jfKy8vbuGVCiOORcCOEOGNXX301GzZs4P3332fnzp18/fXXnHvuuRQXF3u7aa3itdde49prr8VmszXr/v79+5OcnMyHH37Yxi0TQhyPhBshxBkpLS1l+fLlPPvss5x33nkkJSUxbNgwpk6dymWXXea5r6ysjLvuuouoqCjsdjvnn38+GzZsaPJeX3/9Nenp6VgsFiIiIrjqqqs810pKSrjlllsIDQ0lMDCQcePGsWvXLs/19957j5CQEL777jt69+5NcHAwl1xyCTk5OZ57XC4XU6ZMISQkhPDwcP7whz9wqu313G43n332GZdffnmT89OnT6d79+5YLBaio6O55pprmly//PLL+eijj5r/gxRCtBoJN0KIMxIcHExwcDBz5szB6XQe9x5N07jsssvIzc1l7ty5rFu3jsGDB3PBBRd4ene+/fZbrrrqKi677DLWr1/P999/T3p6uuc9brvtNtauXcvXX3/NqlWr0DSNSy+9lPr6es891dXVvPDCC/z73/9m6dKlZGVl8fvf/95z/cUXX+Tdd9/lnXfeYfny5RQXFzN79uyTPt/GjRspLS1t0pa1a9fywAMP8PTTT7Njxw7mz5/P2Wef3eR1w4YNY82aNSf8mQgh2lCb7zsuhPB7n3/+uRYaGqpZLBZt1KhR2tSpU7UNGzZ4rn///fea3W7Xamtrm7wuNTVVe+ONNzRN07SRI0dqN91003Hff+fOnRqgrVixwnOusLBQs1qt2qeffqppmqbNnDlTA7Tdu3d77nn99de16Ohoz3FsbKz297//3XNcX1+vxcfHa1dcccUJn2327NmaXq/X3G6359wXX3yh2e12rby8/ISv27BhgwZo+/btO+E9Qoi2IT03QogzdvXVV3Po0CG+/vprxo4dy+LFixk8eDDvvfceAOvWraOyspLw8HBPT09wcDCZmZns2bMHgIyMDC644ILjvv+2bdswGAwMHz7ccy48PJyePXuybds2z7nAwEBSU1M9x7GxseTn5wNqWCwnJ4eRI0d6rhsMhiY9MsdTU1OD2WxGp9N5zl100UUkJSXRtWtXJk6cyIcffkh1dXWT11mtVoBjzgsh2p6EGyFEq7BYLFx00UU88cQTrFy5kttuu40nn3wSUPNWYmNjycjIaPK1Y8cOHnnkEeBIGDge7QTzYjRNaxI6jEZjk+s6ne6Uc2pOJSIigurqaurq6jznbDYbP//8Mx999BGxsbE88cQTDBgwgNLSUs89h4fbIiMjz+j7CyFaTsKNEKJN9OnTh6qqKgAGDx5Mbm4uBoOBbt26NfmKiIgA1Aqj77///oTv1dDQwI8//ug5V1RUxM6dO+ndu3ez2uNwOIiNjWX16tWecw0NDaxbt+6krxs4cCAAW7dubXLeYDBw4YUX8txzz7Fx40b27dvHDz/84Lm+efNm4uPjPc8nhGg/Bm83QAjh24qKirj22muZNGkS/fv3x2azsXbtWp577jmuuOIKAC688EJGjhzJhAkTePbZZ+nZsyeHDh1i7ty5TJgwgfT0dJ588kkuuOACUlNT+fWvf01DQwPz5s3jD3/4A927d+eKK67gzjvv5I033sBms/Hoo4/SpUsXz/dojgcffJC///3vdO/end69e/PSSy816W05nsjISAYPHszy5cs9Qee///0ve/fu5eyzzyY0NJS5c+fidrvp2bOn53XLli3j4osvbvHPUwjRCrw850cI4eNqa2u1Rx99VBs8eLDmcDi0wMBArWfPntr//d//adXV1Z77ysvLtfvvv1+Li4vTjEajlpCQoN10001aVlaW554vvvhCGzhwoGYymbSIiAjtqquu8lwrLi7WJk6cqDkcDs1qtWpjx47Vdu7c6bk+c+ZMzeFwNGnb7NmztaP/mauvr9cefPBBzW63ayEhIdqUKVO0W2655aQTijVN0/71r39pI0aM8BwvW7ZMO+ecc7TQ0FDNarVq/fv31z755BPP9ZqaGs1ut2urVq1q9s9RCNF6dJp2hgPSQgjh52pra+nZsycff/xxkwnJJ/L666/z1VdfsWDBgnZonRDil2TOjRBCnILFYmHWrFkUFhY2636j0cg///nPNm6VEOJEpOdGCCGEEH5Fem6EEEII4Vck3AghhBDCr0i4EUIIIYRfkXAjhBBCCL8i4UYIIYQQfkXCjRBCCCH8ioQbIYQQQvgVCTdCCCGE8CsSboQQQgjhV/4f+Na7HUpx9R8AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "steps = []\n",
    "loss = []\n",
    "max_loss = []\n",
    "for step in range(1, predictions.size(1) + 1):\n",
    "    raw_rmse_loss = criterion(predictions[:, :step, :], truths[:, :step, :])\n",
    "    raw_rmse_loss = torch.sqrt(torch.sum(raw_rmse_loss, dim=-1))\n",
    "    mean_rmse_loss = raw_rmse_loss.mean(dim=-1)\n",
    "    max_rmse_loss = raw_rmse_loss.max(dim=-1).values\n",
    "    loss.append(mean_rmse_loss)\n",
    "    max_loss.append(max_rmse_loss)\n",
    "    steps.extend([step] * len(mean_rmse_loss))\n",
    "    \n",
    "max_loss = torch.cat(max_loss).cpu().numpy()\n",
    "loss = torch.cat(loss).cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame({'Second (s)': steps, 'loss': loss})\n",
    "df1 = pd.DataFrame({'Second (s)': steps, 'loss': max_loss})\n",
    "df['type'] = 'mean'\n",
    "df1['type'] = 'max'\n",
    "df = pd.concat([df, df1])\n",
    "\n",
    "\n",
    "df['RMSE Error (m)'] = df['loss'] / 100 # to meters\n",
    "df['Second (s)'] = df['Second (s)'] / 5 # to seconds\n",
    "sns.lineplot(data = df, x='Second (s)', y='RMSE Error (m)', hue='type',) #  errorbar=('sd', 1),\n",
    "plt.savefig(f'../model/{model_name}/{folder_name}/res.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize\n",
    "\n",
    "time_stamp = 2899\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "pred = predictions[time_stamp, :, :].cpu().numpy()\n",
    "truth = truths[time_stamp, :, :].cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# equal axis\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.plot(pred[:, 0], pred[:, 1], color='blue', label='Predicted Trajectory')\n",
    "ax.plot(truth[:, 0], truth[:, 1], color='red', label='Ground Truth Trajectory')\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_title('Predicted vs Ground Truth Trajectory')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second (s)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.213196</td>\n",
       "      <td>0.213196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.325087</td>\n",
       "      <td>0.240143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.401820</td>\n",
       "      <td>0.262324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.478753</td>\n",
       "      <td>0.290556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.548466</td>\n",
       "      <td>0.319244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.630744</td>\n",
       "      <td>0.351674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.722682</td>\n",
       "      <td>0.388734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>0.805256</td>\n",
       "      <td>0.425171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.8</th>\n",
       "      <td>0.869738</td>\n",
       "      <td>0.457087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.961358</td>\n",
       "      <td>0.494607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2</th>\n",
       "      <td>1.035280</td>\n",
       "      <td>0.530799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>1.100478</td>\n",
       "      <td>0.563363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6</th>\n",
       "      <td>1.182403</td>\n",
       "      <td>0.599558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8</th>\n",
       "      <td>1.254538</td>\n",
       "      <td>0.634955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1.336145</td>\n",
       "      <td>0.670869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>1.419983</td>\n",
       "      <td>0.707562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.4</th>\n",
       "      <td>1.497616</td>\n",
       "      <td>0.743652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.6</th>\n",
       "      <td>1.587365</td>\n",
       "      <td>0.781477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.8</th>\n",
       "      <td>1.663460</td>\n",
       "      <td>0.818394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1.745875</td>\n",
       "      <td>0.855828</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type             max      mean\n",
       "Second (s)                    \n",
       "0.2         0.213196  0.213196\n",
       "0.4         0.325087  0.240143\n",
       "0.6         0.401820  0.262324\n",
       "0.8         0.478753  0.290556\n",
       "1.0         0.548466  0.319244\n",
       "1.2         0.630744  0.351674\n",
       "1.4         0.722682  0.388734\n",
       "1.6         0.805256  0.425171\n",
       "1.8         0.869738  0.457087\n",
       "2.0         0.961358  0.494607\n",
       "2.2         1.035280  0.530799\n",
       "2.4         1.100478  0.563363\n",
       "2.6         1.182403  0.599558\n",
       "2.8         1.254538  0.634955\n",
       "3.0         1.336145  0.670869\n",
       "3.2         1.419983  0.707562\n",
       "3.4         1.497616  0.743652\n",
       "3.6         1.587365  0.781477\n",
       "3.8         1.663460  0.818394\n",
       "4.0         1.745875  0.855828"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_results = df.groupby(by=['Second (s)', 'type']).mean().unstack()['RMSE Error (m)']\n",
    "exp_results.to_csv(f'../model/{model_name}/{folder_name}/result.csv')\n",
    "exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export JIT Model\n",
    "\n",
    "Integrate partial of data processing into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXPORT_MODEL = True\n",
    "\n",
    "# # # model.load_state_dict(torch.load(\"/home/shaoze/Documents/Boeing/Boeing-Trajectory-Prediction/model/Jul09_20-37-37/model_40000.pt\"))\n",
    "# # if EXPORT_MODEL:\n",
    "# #     model.eval()\n",
    "# #     model.to('cpu')\n",
    "# #     script_module = torch.jit.script(model)\n",
    "# #     os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# #     script_module.save(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# stats = {}\n",
    "# '''\n",
    "# mean: tensor[]\n",
    "# '''\n",
    "\n",
    "# for keys, values in stats_dict.items():\n",
    "#     stats[keys] = torch.tensor(values.to_list()).view(1,1,-1)\n",
    "    \n",
    "# class TFT_EXP(nn.Module):\n",
    "#     def __init__(self, model:EnhancedTFT, stats:dict):\n",
    "#         super(TFT_EXP, self).__init__()\n",
    "#         self.stats = stats\n",
    "#         self.register_buffer('mean', self.stats['mean'])\n",
    "#         self.register_buffer('std', self.stats['std'])\n",
    "#         self.register_buffer('min', self.stats['min'])\n",
    "#         self.register_buffer('max', self.stats['max'])\n",
    "#         self.TFT = model\n",
    "#         self.num_steps = model.num_steps\n",
    "#         self.num_outputs = model.num_outputs # =2\n",
    "\n",
    "#     def forward(self, x, mask: Optional[torch.Tensor]=None):\n",
    "#         single = False\n",
    "#         if len(x.shape) == 2:\n",
    "#             x = x.unsqueeze(0)\n",
    "#             single = True\n",
    "        \n",
    "#         # normalize\n",
    "#         x = (x - self.mean) / self.std\n",
    "#         x = (x - self.min) / (self.max - self.min)\n",
    "#         # residual\n",
    "#         current_pos_input = x[:, -1, :2].clone().unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "#         current_pos_output = x[:, -1, :2].clone().unsqueeze(1).repeat(1, self.num_steps, 1)\n",
    "#         x[:, :, :2] = x[:, :, :2] - current_pos_input\n",
    "        \n",
    "#         # pass through TFT\n",
    "#         outputs, vq_loss, perplexity = self.TFT(x, mask)\n",
    "#         outputs = outputs.detach()\n",
    "        \n",
    "#         # de-residual\n",
    "#         outputs[:, :, :2] = outputs[:, :, :2] + current_pos_output\n",
    "        \n",
    "#         # denormalize\n",
    "#         outputs = outputs * (self.max[:,:,:self.num_outputs] - self.min[:,:,:self.num_outputs]) + self.min[:,:,:self.num_outputs]\n",
    "#         outputs = outputs * self.std[:,:,:self.num_outputs] + self.mean[:,:,:self.num_outputs]\n",
    "        \n",
    "#         if single:\n",
    "#             outputs = outputs.squeeze(0)\n",
    "#         return outputs\n",
    "\n",
    "# tft_exp = TFT_EXP(model, stats)\n",
    "# tft_exp.to('cpu')\n",
    "# tft_exp.eval()\n",
    "# # script_module = torch.jit.script(tft_exp)\n",
    "# # os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# # script_module.save(\"../exported/model_tft_vqvae_cpu_preproc.pt\")\n",
    "\n",
    "# # export to onnx\n",
    "\n",
    "# dummy_input = torch.randn(1, lookback, feature_dim)\n",
    "# print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "# # Export the wrapped model to ONNX format\n",
    "# torch.onnx.export(\n",
    "#     tft_exp,                   # Wrapped model to export\n",
    "#     dummy_input,                     # Model input\n",
    "#     \"../exported/tft_1111.onnx\",              # Output file name\n",
    "#     export_params=True,              # Store the trained parameter weights inside the model file\n",
    "#     opset_version=13,                # Set the ONNX opset version (adjust as needed)\n",
    "#     do_constant_folding=True,        # Whether to execute constant folding for optimization\n",
    "#     input_names=['input'],           # The model's input names\n",
    "#     output_names=['output'],         # The model's output names\n",
    "#     # dynamic_axes={\n",
    "#     #     'input': {0: 'batch_size'},  # Dynamic batch_size and sequence_length\n",
    "#     #     'output': {0: 'batch_size'}  # Dynamic batch_size for the output\n",
    "#     # }\n",
    "# )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime as ort\n",
    "# import numpy as np\n",
    "\n",
    "# # Path to your ONNX model\n",
    "# model_path = \"../exported/tft_1111.onnx\"\n",
    "\n",
    "# # Create an inference session\n",
    "# session = ort.InferenceSession(model_path)\n",
    "\n",
    "# # Get the name of the input node\n",
    "# input_name = session.get_inputs()[0].name\n",
    "\n",
    "# for file in os.listdir(dir):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         df = process_data(dir+file)\n",
    "#     break\n",
    "\n",
    "# df = df[['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "#        'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "#        'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "#        'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "#        'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "#        'closest_station', 'distance_to_closest_station',\n",
    "#        'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "#        'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "#        'GazeDirection_Z', 'AGV_X', 'AGV_Y',\n",
    "#        'looking_at_closest_station']]\n",
    "\n",
    "# start_idx = 100\n",
    "# input = df.iloc[200:200+lookback].astype(np.float32).values\n",
    "\n",
    "# # add batch\n",
    "# input = input[np.newaxis, :, :]\n",
    "# # Run the model\n",
    "# output = session.run(None, {input_name: input.astype(np.float32)})[0]\n",
    "\n",
    "# output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data (for interactive visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# test_ds = MyDataset(lookback=lookback)\n",
    "# all_ds = ds.dataset\n",
    "# test_ds.dataset = all_ds[len(all_ds)//10 :] # load the last 10% of the data\n",
    "# X_list, y_list = test_ds.generate_data(return_list=True, future_steps=future_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# normalize_dict = stats_dict\n",
    "# pred_data = []\n",
    "# truth_data = []\n",
    "# input_data = []\n",
    "# model.eval()\n",
    "# device = 'cpu'\n",
    "# for i, (X, y) in enumerate(zip(X_list, y_list)):\n",
    "#     current_pos_input = X[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "#     current_pos_output = X[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1).to(device)\n",
    "#     X[:, :, :2] = X[:, :, :2] - current_pos_input\n",
    "\n",
    "#     predictions = model(X.float().to(device))[0][:, :future_steps, :2]\n",
    "#     predictions = predictions + current_pos_output\n",
    "#     predictions = predictions.to('cpu')\n",
    "    \n",
    "#     truths = y[:, :future_steps, :2]\n",
    "#     X[:, :, :2] = X[:, :, :2] + current_pos_input\n",
    "#     model_input = X.float().to(device)[:, :lookback, :2]\n",
    "#     trajectory_id = i\n",
    "    \n",
    "#     # reverse normalization\n",
    "#     for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    \n",
    "#     for group_id in range(predictions.shape[0]):\n",
    "#         for time_step in range(predictions.shape[1]):\n",
    "#             pred_x, pred_y = predictions[group_id, time_step]\n",
    "#             pred_data.append([trajectory_id, group_id, time_step, pred_x.item(), pred_y.item()])\n",
    "\n",
    "#             truth_x, truth_y = truths[group_id, time_step]\n",
    "#             truth_data.append([trajectory_id, group_id, time_step, truth_x.item(), truth_y.item()])\n",
    "        \n",
    "#         for time_step in range(lookback):\n",
    "#             input_x, input_y = model_input[group_id, time_step]\n",
    "#             input_data.append([trajectory_id, group_id, time_step, input_x.item(), input_y.item()])\n",
    "            \n",
    "\n",
    "# pred_df = pd.DataFrame(pred_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# truth_df = pd.DataFrame(truth_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# input_df = pd.DataFrame(input_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_remove = [\n",
    "#     \"../data/pred_tra_all.pkl\",\n",
    "#     \"../data/truth_tra_all.pkl\", \n",
    "#     \"../data/input_tra_all.pkl\"\n",
    "# ]\n",
    "\n",
    "# for file_path in files_to_remove:\n",
    "#     if os.path.exists(file_path):\n",
    "#         os.remove(file_path)\n",
    "\n",
    "# truth_df.to_pickle(\"../data/truth_tra_all.pkl\")\n",
    "# pred_df.to_pickle(\"../data/pred_tra_all.pkl\")\n",
    "# input_df.to_pickle(\"../data/input_tra_all.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
