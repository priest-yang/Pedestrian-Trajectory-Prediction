{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cur_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # Gets the current notebook directory\n",
    "src_dir = os.path.join(cur_dir, '../')  # Constructs the path to the 'src' directory\n",
    "# Add the 'src' directory to sys.path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.constant import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.MyDataset import MyDataset, save_dataset, load_dataset\n",
    "# from src.TFT_Flowmatching import TemporalFusionTransformerDiffusion\n",
    "\n",
    "from src.VQVAE import VQVAE\n",
    "from typing import Optional\n",
    "import pickle\n",
    "\n",
    "import torch.utils\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: direct load data from Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = load_dataset('../data/.cache/train.pkl')\n",
    "# test = load_dataset('../data/.cache/test.pkl')\n",
    "# stats_dict = pickle.load(open('../data/.cache/stats_dict.pkl', 'rb'))\n",
    "# feature_dim = stats_dict['feature_dim']\n",
    "# features = stats_dict['features']\n",
    "\n",
    "lookback = 30\n",
    "future_steps = 40\n",
    "resample = False\n",
    "dir = '../data/Phase3/Modified/'\n",
    "ds = MyDataset(lookback=lookback)\n",
    "train_batch_size = 16\n",
    "test_batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_data(df_dir : str, target_freq : int = 10):\n",
    "    states = ['At Station', 'Error', 'Wait', 'Cross', 'Approach Sidewalk',\n",
    "       'Approach Target Station', 'Move Along Sidewalk']\n",
    "\n",
    "    states_ohe = pd.get_dummies(df['state'], prefix='state')\n",
    "    cur_states = df['state'].unique()\n",
    "    for state in states:\n",
    "        if state not in cur_states:\n",
    "            states_ohe['state_'+state] = 0\n",
    "\n",
    "    df = pd.concat([df, states_ohe], axis=1)\n",
    "    df.drop(columns=['state'], inplace=True)\n",
    "    \n",
    "    df.dropna(inplace=True, how='any')\n",
    "    if resample:\n",
    "        f_per_sec = df.groupby('TimestampID').count().mean().mean()\n",
    "        if f_per_sec < target_freq:\n",
    "            raise ValueError('The frequency of the data is lower than the target frequency')\n",
    "        elif int(f_per_sec) == target_freq:\n",
    "            pass\n",
    "        else:\n",
    "            resample_ratio = int(f_per_sec/target_freq)\n",
    "            df = df.iloc[::resample_ratio, :]\n",
    "    # # for origin\n",
    "    for drop_column in ['Confidence', 'Timestamp', 'TimestampID', \n",
    "                          'DatapointID', 'PID', 'SCN', 'U_X', 'U_Y', 'U_Z', \n",
    "                          'AGV_Z', 'User_Z', 'GazeOrigin_Z', 'User_Pitch', 'User_Yaw', 'User_Roll', \n",
    "                          'EyeTarget', \n",
    "                          'start_station_X', 'start_station_Y', 'end_station_X', 'end_station_Y',\n",
    "                          'distance_from_start_station_X',\n",
    "                            'distance_from_start_station_Y', 'distance_from_end_station_X',\n",
    "                            'distance_from_end_station_Y', 'facing_start_station',\n",
    "                            'facing_end_station', \n",
    "                            'rolling_avg', \n",
    "                            'User', 'Type', \n",
    "                            'possible_interaction'\n",
    "                          ]:\n",
    "        df = df.drop(columns=[drop_column], errors='ignore')\n",
    "\n",
    "    target_columns = ['User_X', 'User_Y']\n",
    "    # Reorder columns\n",
    "    new_columns = target_columns + [col for col in df.columns if col not in target_columns]\n",
    "    df = df[new_columns]\n",
    "    \n",
    "    # keep numeric columns\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith('.pkl'):\n",
    "        df = process_data(dir+file)\n",
    "        ds.read_data(df, agv_col_name=\"scenario\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(ds.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns : Index(['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
      "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
      "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
      "       'intent_to_cross', 'Gazing_station', 'facing_along_sidewalk',\n",
      "       'facing_to_road', 'On_sidewalks', 'On_road', 'closest_station',\n",
      "       'distance_to_closest_station', 'distance_to_closest_station_X',\n",
      "       'distance_to_closest_station_Y', 'looking_at_AGV', 'GazeDirection_X',\n",
      "       'GazeDirection_Y', 'GazeDirection_Z', 'AGV_X', 'AGV_Y',\n",
      "       'looking_at_closest_station', 'data_active', 'scenario',\n",
      "       'state_Approach Sidewalk', 'state_Approach Target Station',\n",
      "       'state_At Station', 'state_Cross', 'state_Error',\n",
      "       'state_Move Along Sidewalk', 'state_Wait'],\n",
      "      dtype='object') \n",
      "feature_dim : 38\n"
     ]
    }
   ],
   "source": [
    "stats_dict = {'mean': 0, 'std': 0, 'min': 0, 'max': 0}\n",
    "stats_dict = ds.normalize_dataset()\n",
    "ds.generate_data(future_steps=future_steps)\n",
    "\n",
    "train:torch.utils.data.DataLoader\n",
    "test:torch.utils.data.DataLoader\n",
    "\n",
    "train, test = ds.split_data(frac=0.9, shuffle=True, train_batch_size=train_batch_size, test_batch_size=test_batch_size)\n",
    "\n",
    "feature_dim = ds.feature_dim\n",
    "stats_dict['feature_dim'] = feature_dim\n",
    "stats_dict['features'] = ds.dataset[0].columns\n",
    "columns = [_ for _ in ds.dataset[0].columns if _ not in ['AGV_name']]\n",
    "print(f\"columns : {df.columns} \\nfeature_dim : {feature_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "       'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "       'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "       'closest_station', 'distance_to_closest_station',\n",
    "       'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "       'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "       'GazeDirection_Z', 'AGV_X', 'AGV_Y', 'looking_at_closest_station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 30, 38]) torch.Size([16, 40, 38])\n",
      "317840 35328\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train):\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "\n",
    "print(len(train) * train_batch_size, len(test) * test_batch_size)\n",
    "\n",
    "# save it to cache to speed up\n",
    "# save_dataset(train, type='train', file_path='../data/.cache/train.pkl')\n",
    "# save_dataset(test, type='test', file_path='../data/.cache/test.pkl')\n",
    "# pickle.dump(stats_dict, open('../data/.cache/stats_dict.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from src.VQVAE import VQVAE\n",
    "import math\n",
    "\n",
    "###############################################\n",
    "# Original Blocks (with minor efficiency tweaks)\n",
    "###############################################\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=3, dropout_rate=0.1):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)]\n",
    "        )\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "        self.gate = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_input = x\n",
    "        for layer, norm in zip(self.layers, self.norms):\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "            x = norm(x)\n",
    "        gate = torch.sigmoid(self.gate(x))\n",
    "        x2 = self.fc2(x)\n",
    "        return self.fc3(x_input) + gate * x2\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout_rate)\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size * 4, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask: Optional[torch.Tensor] = None):\n",
    "        # x: (seq_len, batch, hidden_size)\n",
    "        x2 = x\n",
    "        x = self.norm1(x)\n",
    "        x, _ = self.attention(x, x, x, key_padding_mask=mask)\n",
    "        x = x + x2\n",
    "        x2 = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = x + x2\n",
    "        return x\n",
    "\n",
    "###############################################\n",
    "# Diffusion–based Decoder\n",
    "###############################################\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Computes a sinusoidal embedding for a scalar timestep.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SinusoidalTimeEmbedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        # t: Tensor of shape (batch,) or (batch, 1)\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.unsqueeze(1)  # (batch, 1)\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        # Compute constant\n",
    "        emb_factor = math.log(10000) / (half_dim - 1)\n",
    "        # Create a tensor of shape (half_dim,)\n",
    "        dims = torch.arange(half_dim, device=t.device, dtype=t.dtype)\n",
    "        # (batch, half_dim)\n",
    "        emb = t * torch.exp(-dims * emb_factor)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        # If embedding_dim is odd, pad an extra zero.\n",
    "        if self.embedding_dim % 2 == 1:\n",
    "            emb = F.pad(emb, (0, 1))\n",
    "        return emb  # (batch, embedding_dim)\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "class DiffusionDecoder(nn.Module):\n",
    "    def __init__(self, action_dim, conditioning_dim, num_diffusion_steps=10,\n",
    "                 num_action_steps=20, num_heads=4, hidden_dim=128, num_layers=2):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dim\n",
    "        self.num_diffusion_steps = num_diffusion_steps\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_action_steps = num_action_steps\n",
    "\n",
    "        # Improved beta schedule\n",
    "        betas = cosine_beta_schedule(num_diffusion_steps)\n",
    "        self.register_buffer('betas', betas)\n",
    "        alphas = 1.0 - betas\n",
    "        self.register_buffer('alpha_bars', torch.cumprod(alphas, dim=0))\n",
    "\n",
    "        # Enhanced time embedding\n",
    "        self.time_embed = SinusoidalTimeEmbedding(hidden_dim)\n",
    "        \n",
    "        # Input projection with time conditioning\n",
    "        self.input_proj = nn.Linear(action_dim + hidden_dim, hidden_dim)\n",
    "\n",
    "        # Transformer blocks with cross-attention\n",
    "        self.blocks = nn.ModuleList([\n",
    "            nn.ModuleDict({\n",
    "                'cross_attn': nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True),\n",
    "                'mlp': nn.Sequential(\n",
    "                    nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "                    nn.GELU(),\n",
    "                    nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "                ),\n",
    "                'norm1': nn.LayerNorm(hidden_dim),\n",
    "                'norm2': nn.LayerNorm(hidden_dim),\n",
    "            }) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "        # Final output projection\n",
    "        self.out = nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "    def forward(self, conditioning, x_t, t):\n",
    "        # Time embedding\n",
    "        t_emb = self.time_embed(t)  # [batch, h_dim]\n",
    "        \n",
    "        # Combine input with time embeddings\n",
    "        x_proj = self.input_proj(torch.cat([x_t, t_emb.unsqueeze(1).expand(-1, x_t.size(1), -1)], -1))\n",
    "        \n",
    "        # Process through transformer blocks\n",
    "        h = x_proj\n",
    "        for block in self.blocks:\n",
    "            # Cross-attention\n",
    "            attn_out, _ = block['cross_attn'](\n",
    "                h, conditioning, conditioning,\n",
    "            )\n",
    "            h = h + attn_out\n",
    "            h = block['norm1'](h)\n",
    "            \n",
    "            # MLP\n",
    "            h = h + block['mlp'](h)\n",
    "            h = block['norm2'](h)\n",
    "        \n",
    "        return self.out(h)\n",
    "    \n",
    "    def influence(self, conditioning, device):\n",
    "        \"\"\"\n",
    "        Runs the reverse diffusion process and returns a list of intermediate denoised trajectories.\n",
    "        \n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "            device: torch.device.\n",
    "            \n",
    "        Returns:\n",
    "            intermediates: A list of tensors, each of shape (batch, num_action_steps, action_dim),\n",
    "                           representing the denoised trajectory at each diffusion step.\n",
    "        \"\"\"\n",
    "        batch_size = conditioning.size(0)\n",
    "        x = torch.randn(batch_size, self.num_action_steps, self.action_dim, device=device)\n",
    "        intermediates = []\n",
    "        # Reverse diffusion: record intermediate results at each step.\n",
    "        for t in reversed(range(self.num_diffusion_steps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            epsilon_pred = self.forward(conditioning, x, t_tensor)\n",
    "            beta_t = self.betas[t]\n",
    "            alpha_t = 1.0 - beta_t\n",
    "            alpha_bar_t = self.alpha_bars[t]\n",
    "            noise = torch.randn_like(x) if t > 0 else 0.0\n",
    "            x = (1.0 / torch.sqrt(alpha_t)) * (x - (beta_t / torch.sqrt(1 - alpha_bar_t)) * epsilon_pred) \\\n",
    "                + torch.sqrt(beta_t) * noise\n",
    "            # Save a clone of the current state.\n",
    "            intermediates.append(x.clone())\n",
    "        return intermediates\n",
    "    \n",
    "\n",
    "    def sample(self, conditioning, device):\n",
    "        \"\"\"\n",
    "        Generate a trajectory by running the reverse diffusion process.\n",
    "        \n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "            device: torch.device to run the sampling on.\n",
    "            \n",
    "        Returns:\n",
    "            x: Generated trajectory of shape (batch, num_action_steps, action_dim)\n",
    "        \"\"\"\n",
    "        batch_size = conditioning.size(0)\n",
    "        # Start from standard Gaussian noise.\n",
    "        x = torch.randn(batch_size, self.num_action_steps, self.action_dim, device=device)\n",
    "        # Reverse diffusion process (using the DDPM update)\n",
    "        for t in reversed(range(self.num_diffusion_steps)):\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "            epsilon_pred = self.forward(conditioning, x, t_tensor)\n",
    "            beta_t = self.betas[t]\n",
    "            alpha_t = 1.0 - beta_t\n",
    "            alpha_bar_t = self.alpha_bars[t]\n",
    "            if t > 0:\n",
    "                noise = torch.randn_like(x)\n",
    "            else:\n",
    "                noise = 0.0\n",
    "            # DDPM reverse update:\n",
    "            x = (1.0 / torch.sqrt(alpha_t)) * (x - (beta_t / torch.sqrt(1 - alpha_bar_t)) * epsilon_pred) \\\n",
    "                + torch.sqrt(beta_t) * noise\n",
    "        return x\n",
    "    \n",
    "###############################################\n",
    "# Modified Temporal Fusion Transformer with Diffusion Decoder\n",
    "###############################################\n",
    "\n",
    "class TemporalFusionTransformerDiffusion(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_outputs, num_steps,\n",
    "                 num_attention_heads=8, diffusion_steps=10, vqvae: VQVAE = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_features (int): Number of input features.\n",
    "            num_hidden (int): Hidden dimension size.\n",
    "            num_outputs (int): Dimensionality of each output (e.g. action dimension).\n",
    "            num_steps (int): Desired output sequence length (e.g. number of action steps).\n",
    "            num_attention_heads (int): Number of heads for the transformer blocks.\n",
    "            diffusion_steps (int): Number of diffusion (denoising) steps.\n",
    "        \"\"\"\n",
    "        super(TemporalFusionTransformerDiffusion, self).__init__()\n",
    "        if vqvae is None:\n",
    "            self.vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "        else:\n",
    "            self.vqvae = vqvae\n",
    "        num_features = num_features + self.vqvae.encoder.fc2.out_features\n",
    "        self.encoder_grn = GatedResidualNetwork(num_features, num_hidden, num_hidden)\n",
    "        self.transformer_block = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        self.transformer_block2 = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        \n",
    "        # To condition the diffusion process we project the transformer output.\n",
    "        self.condition_proj = nn.Linear(num_hidden, num_hidden)\n",
    "        # Diffusion decoder: we set action_dim=num_outputs and produce a sequence of length num_steps.\n",
    "        self.diffusion_decoder = DiffusionDecoder(\n",
    "            action_dim=num_outputs,\n",
    "            conditioning_dim=num_hidden,\n",
    "            num_diffusion_steps=diffusion_steps,\n",
    "            num_action_steps=num_steps,\n",
    "            num_heads=4,  # you can adjust as needed\n",
    "            hidden_dim=num_hidden\n",
    "        )\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "    def forward(self, x, y_batch=None , mask: Optional[torch.Tensor] = None, influence=False, return_all=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, seq_len, num_features).\n",
    "            mask: Optional attention mask for the transformer blocks.\n",
    "            \n",
    "        Returns:\n",
    "            actions: Tensor of shape (batch, num_steps, num_outputs)\n",
    "        \"\"\"\n",
    "        # If given a 2D input, add a batch dimension.\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # VQ-VAE\n",
    "        x_recon, vq_loss, perplexity, embedding = self.vqvae(x)\n",
    "        x = torch.cat((x, embedding), dim=-1)\n",
    "        \n",
    "        # Encoder GRN.\n",
    "        x = self.encoder_grn(x)  # (batch, seq_len, num_hidden)\n",
    "        \n",
    "        # Transformer expects (seq_len, batch, hidden_size).\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer_block(x, mask=mask)\n",
    "        x = self.transformer_block2(x, mask=mask)\n",
    "        x = x.permute(1, 0, 2)  # back to (batch, seq_len, num_hidden)\n",
    "        \n",
    "        # Use a summary of the encoder output as conditioning.\n",
    "        # Here we use the last time–step (you might also try an average or more complex pooling).\n",
    "        conditioning = self.condition_proj(x[:, -1:, :])  # (batch, 1, num_hidden)\n",
    "        # conditioning = self.condition_proj(x[:, :, :])  # (batch, 1, num_hidden)\n",
    "\n",
    "\n",
    "\n",
    "        # flow matching during training\n",
    "        self.device = next(self.parameters()).device\n",
    "        flow_loss = torch.tensor(0.0, device=self.device)\n",
    "\n",
    "        \n",
    "        if influence:\n",
    "            if return_all:\n",
    "                return self.diffusion_decoder.influence(conditioning, self.device)\n",
    "            return self.diffusion_decoder.influence(conditioning, self.device)[-1]\n",
    "        else:\n",
    "            if self.training:\n",
    "                diff_loss = self.decoder_train_step(conditioning, y_batch, self.device)\n",
    "                return diff_loss, vq_loss, perplexity, flow_loss\n",
    "            \n",
    "            return User_trajectory, vq_loss, perplexity, flow_loss\n",
    "\n",
    "\n",
    "    def influence(self, x):\n",
    "        User_trajectory = self.forward(x, influence=True)\n",
    "        return User_trajectory\n",
    "    \n",
    "    def decoder_train_step(self, conditioning, y_batch, device):\n",
    "        \"\"\"\n",
    "        Performs one training step for the diffusion self.diffusion_decoder.\n",
    "        \n",
    "        Args:\n",
    "            self.diffusion_decoder: Instance of DiffusionDecoder.\n",
    "            conditioning: Conditioning tensor (batch, cond_len, conditioning_dim)\n",
    "                        (e.g., output from an encoder that has been projected to hidden_dim).\n",
    "            y_batch: Ground truth trajectory (batch, num_action_steps, action_dim).\n",
    "            device: torch.device.\n",
    "            \n",
    "        Returns:\n",
    "            loss: The MSE loss between predicted and true noise.\n",
    "        \"\"\"\n",
    "        batch_size = y_batch.size(0)\n",
    "        # Sample random timesteps for each example in the batch.\n",
    "        t = torch.randint(0, self.diffusion_decoder.num_diffusion_steps, (batch_size,), device=device)\n",
    "        # Gather the corresponding alpha_bar for each timestep.\n",
    "        alpha_bar_t = self.diffusion_decoder.alpha_bars[t].view(batch_size, 1, 1)  # (batch, 1, 1)\n",
    "        # Sample noise to add.\n",
    "        noise = torch.randn_like(y_batch)\n",
    "        # Create the noisy trajectory: x_t = sqrt(alpha_bar) * x0 + sqrt(1 - alpha_bar) * noise\n",
    "        x_t = torch.sqrt(alpha_bar_t) * y_batch + torch.sqrt(1.0 - alpha_bar_t) * noise\n",
    "        # The network predicts the noise given x_t and the conditioning.\n",
    "        noise_pred = self.diffusion_decoder(conditioning, x_t, t)\n",
    "        # MSE loss between the predicted noise and the actual noise.\n",
    "        loss = F.mse_loss(noise_pred, noise)\n",
    "        return loss\n",
    "\n",
    "def compute_flow_target(noise, target, t, schedule_fn=lambda t: t):\n",
    "    \"\"\"\n",
    "    Computes an intermediate sample x_t and its target flow v_target.\n",
    "    \n",
    "    Args:\n",
    "        noise: Tensor of shape (batch, num_action_steps, action_dim)\n",
    "        target: Ground truth output tensor of shape (batch, num_action_steps, action_dim)\n",
    "        t: Tensor of shape (batch, 1, 1) with time values in [0,1]\n",
    "        schedule_fn: A function φ(t) that maps time to interpolation weight.\n",
    "                     For a linear schedule, schedule_fn(t)=t.\n",
    "                     \n",
    "    Returns:\n",
    "        x_t: The intermediate sample at time t.\n",
    "        v_target: The target flow, i.e., d x_t / dt.\n",
    "    \"\"\"\n",
    "    # Compute interpolation weight and its derivative.\n",
    "    phi = schedule_fn(t)              # shape: (batch, 1, 1)\n",
    "    # For linear schedule, dphi/dt = 1. Otherwise, adjust accordingly.\n",
    "    dphi_dt = torch.ones_like(phi)    # Modify if using a non-linear schedule.\n",
    "    \n",
    "    # Interpolate: x(t) = (1 - φ(t)) * noise + φ(t) * target\n",
    "    x_t = (1 - phi) * noise + phi * target\n",
    "    \n",
    "    # The target flow is: v_target = dφ/dt * (target - noise)\n",
    "    v_target = dphi_dt * (target - noise)\n",
    "    \n",
    "    return x_t, v_target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalFusionTransformerDiffusion(\n",
       "  (vqvae): VQVAE(\n",
       "    (encoder): VQVAEEncoder(\n",
       "      (fc1): Linear(in_features=38, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "    (quantizer): VectorQuantizer(\n",
       "      (embedding): Embedding(128, 128)\n",
       "    )\n",
       "    (decoder): VQVAEDecoder(\n",
       "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=38, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_grn): GatedResidualNetwork(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=166, out_features=128, bias=True)\n",
       "      (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-2): 3 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=166, out_features=128, bias=True)\n",
       "    (gate): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (transformer_block): TransformerBlock(\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer_block2): TransformerBlock(\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (condition_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (diffusion_decoder): DiffusionDecoder(\n",
       "    (time_embed): SinusoidalTimeEmbedding()\n",
       "    (input_proj): Linear(in_features=130, out_features=128, bias=True)\n",
       "    (blocks): ModuleList(\n",
       "      (0-1): 2 x ModuleDict(\n",
       "        (cross_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (mlp): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "    (out): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecayLoss(nn.Module):\n",
    "    def __init__(self, num_steps, baseline_loss_fn=nn.L1Loss()):\n",
    "        super(DecayLoss, self).__init__()\n",
    "        # Weight decreases as we move further into the future\n",
    "        self.weights = torch.linspace(1.0, 1.0, num_steps)\n",
    "        self.baseline_loss_fn = baseline_loss_fn\n",
    "        \n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        loss = 0\n",
    "        for i in range(predictions.shape[1]):\n",
    "            loss += self.weights[i] * self.baseline_loss_fn(predictions[:, i], targets[:, i])\n",
    "        return loss\n",
    "    \n",
    "    \n",
    "baseline_loss_fn = nn.L1Loss() #nn.MSELoss()\n",
    "loss_fn = DecayLoss(future_steps, baseline_loss_fn=baseline_loss_fn)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps, diffusion_steps=10, vqvae=vqvae)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer with early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at ../model/TFT_Flowmatching/Feb16_15-19-00\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efdfeeff34ea40d6a2307aedfd67aa23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps 2000: test RMSE 10.0616, moving average RMSE 10.0616\n",
      "Steps 4000: test RMSE 2.1145, moving average RMSE 5.2933\n",
      "Steps 6000: test RMSE 2.1794, moving average RMSE 3.4250\n",
      "Steps 8000: test RMSE 1.4525, moving average RMSE 2.2415\n",
      "Model saved at ../model/TFT_Flowmatching/Feb16_15-19-00/model_10000.pt\n",
      "Steps 10000: test RMSE 1.3606, moving average RMSE 1.7129\n",
      "Steps 12000: test RMSE 1.5652, moving average RMSE 1.6243\n",
      "Steps 14000: test RMSE 1.1753, moving average RMSE 1.3549\n",
      "Steps 16000: test RMSE 1.1375, moving average RMSE 1.2244\n",
      "Steps 18000: test RMSE 1.0671, moving average RMSE 1.1300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5357956f0cb46b6b8f4e16de045ac9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19865 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved at ../model/TFT_Flowmatching/Feb16_15-19-00/model_20000.pt\n",
      "Steps 20000: test RMSE 1.0263, moving average RMSE 1.0678\n",
      "Steps 22000: test RMSE 0.9568, moving average RMSE 1.0012\n",
      "Steps 24000: test RMSE 1.0979, moving average RMSE 1.0592\n",
      "Steps 26000: test RMSE 1.2340, moving average RMSE 1.1641\n",
      "Steps 28000: test RMSE 0.9873, moving average RMSE 1.0580\n",
      "Model saved at ../model/TFT_Flowmatching/Feb16_15-19-00/model_30000.pt\n",
      "Steps 30000: test RMSE 0.9858, moving average RMSE 1.0147\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_epochs = 50\n",
    "eval_step = 2000\n",
    "save_every = 10000\n",
    "patience = 8  # Number of evaluations to wait for improvement\n",
    "cooldown = 4  # Evaluations to wait after an improvement before counting non-improvements\n",
    "smooth_factor = 0.6  # Smoothing factor for moving average\n",
    "lambda_flow = 1e-3  # Weight for flow matching loss\n",
    "\n",
    "# Setup\n",
    "train_all = len(train)\n",
    "model_name = \"TFT_Flowmatching\"\n",
    "from collections import defaultdict\n",
    "loss_all = defaultdict(list)\n",
    "best_test_rmse = float('inf')\n",
    "early_stopping_counter = 0\n",
    "cooldown_counter = cooldown\n",
    "\n",
    "now = datetime.now()\n",
    "folder_name = now.strftime(\"%b%d_%H-%M-%S\")\n",
    "print(f\"Saving model at ../model/{model_name}/{folder_name}\")\n",
    "\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=max(len(train) * n_epochs, 50000), eta_min=1e-6)\n",
    "\n",
    "# Initialize moving average\n",
    "moving_avg_test_rmse = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, (X_batch, y_batch) in tqdm(enumerate(train), total=train_all):\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        y_batch = y_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_batch[:, :, :2] = X_batch[:, :, :2] - current_pos_input\n",
    "        y_batch[:, :, :2] = y_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "\n",
    "        # residual\n",
    "        # X_batch[:, 1:, :2] = X_batch[:, 1:, :2] - X_batch[:, :-1, :2].clone()\n",
    "        # X_batch[:, 0, :2] = 0\n",
    "        # y_batch[:, 1:, :2] = y_batch[:, 1:, :2] - y_batch[:, :-1, :2].clone()\n",
    "        # y_batch[:, 0, :2] = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # y_pred, vq_loss, perplexity, flow_loss = model(X_batch, y_batch=y_batch)\n",
    "        # loss = loss_fn(y_pred[:, :future_steps, :2], y_batch[:, :future_steps, :2])\n",
    "        diff_loss, vq_loss, perplexity, flow_loss = model(X_batch, y_batch[:, :future_steps, :2])\n",
    "\n",
    "\n",
    "        loss_all['diff_loss'].append(diff_loss.item())\n",
    "        loss_all['vq_loss'].append(vq_loss.item() * 10)\n",
    "        # add vq_loss\n",
    "        loss = 10 * vq_loss + diff_loss\n",
    "        # add flow_loss\n",
    "        loss += lambda_flow * flow_loss\n",
    "        loss_all['flow_loss'].append(flow_loss.item())\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # Save model\n",
    "        if (epoch * train_all + step + 1) % save_every == 0:\n",
    "            os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "            save_path = f\"../model/{model_name}/{folder_name}/model_{epoch * train_all + step + 1}.pt\"\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at {save_path}\")\n",
    "\n",
    "        # Validation and early stopping\n",
    "        if (epoch * train_all + step + 1) % eval_step == 0:\n",
    "            model.eval()\n",
    "            test_rmse_all = []\n",
    "            with torch.no_grad():\n",
    "                for X_test_batch, y_test_batch in test:\n",
    "                    X_test_batch = X_test_batch.float().to(device)\n",
    "                    y_test_batch = y_test_batch.float().to(device)\n",
    "                    \n",
    "                    current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "                    current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "                    X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "                    y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "                    \n",
    "                    \n",
    "                    # # residual\n",
    "                    # X_test_batch[:, 1:, :2] = X_test_batch[:, 1:, :2] - X_test_batch[:, :-1, :2].clone()\n",
    "                    # X_test_batch[:, 0, :2] = 0\n",
    "                    # y_test_batch[:, 1:, :2] = y_test_batch[:, 1:, :2] - y_test_batch[:, :-1, :2].clone()\n",
    "                    # y_test_batch[:, 0, :2] = 0\n",
    "                    \n",
    "                    y_pred_test = model(X_test_batch, influence=True)\n",
    "                    loss_test = loss_fn(y_pred_test[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "                    test_rmse = torch.sqrt(loss_test)\n",
    "                    if not torch.isnan(test_rmse):\n",
    "                        test_rmse_all.append(test_rmse.item())\n",
    "            \n",
    "            current_rmse = sum(test_rmse_all) / len(test_rmse_all)\n",
    "            if moving_avg_test_rmse is None:\n",
    "                moving_avg_test_rmse = current_rmse\n",
    "            else:\n",
    "                moving_avg_test_rmse = smooth_factor * current_rmse + (1 - smooth_factor) * moving_avg_test_rmse\n",
    "\n",
    "            print(f\"Steps {epoch * train_all + step + 1}: test RMSE {current_rmse:.4f}, moving average RMSE {moving_avg_test_rmse:.4f}\")\n",
    "\n",
    "            # Check if the moving average RMSE is better; if not, increment counter\n",
    "            if moving_avg_test_rmse < best_test_rmse:\n",
    "                best_test_rmse = moving_avg_test_rmse\n",
    "                early_stopping_counter = 0  # Reset counter\n",
    "                cooldown_counter = cooldown  # Reset cooldown\n",
    "                # Optionally save the best model\n",
    "                os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "                best_model_path = f\"../model/{model_name}/{folder_name}/best_model.pt\"\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                if cooldown_counter > 0:\n",
    "                    cooldown_counter -= 1\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Stopping early at epoch {epoch+1}, step {step+1}\")\n",
    "                break\n",
    "\n",
    "            model.train()\n",
    "        \n",
    "    if early_stopping_counter >= patience:\n",
    "        break\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1408a9573b6541b39346e74672c5e476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.37827416709151823\n"
     ]
    }
   ],
   "source": [
    "validation_step = future_steps\n",
    "\n",
    "predictions = []\n",
    "truths = []\n",
    "\n",
    "test_loss_all = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    all_test = len(test)\n",
    "    test_rmse_all = []\n",
    "    for X_test_batch, y_test_batch in tqdm(test):\n",
    "        X_test_batch = X_test_batch.float().to(device)\n",
    "        y_test_batch = y_test_batch.float().to(device)\n",
    "        \n",
    "        # current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        # current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        # X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "        # y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "        \n",
    "        # residual\n",
    "        current_pos = y_test_batch[:, 0, :2].clone().unsqueeze(1).repeat(1, validation_step, 1)\n",
    "        X_test_batch[:, 1:, :2] = X_test_batch[:, 1:, :2] - X_test_batch[:, :-1, :2].clone()\n",
    "        X_test_batch[:, 0, :2] = 0\n",
    "        y_test_batch[:, 1:, :2] = y_test_batch[:, 1:, :2] - y_test_batch[:, :-1, :2].clone()\n",
    "        y_test_batch[:, 0, :2] = 0\n",
    "        \n",
    "        y_preds = model(X_test_batch, influence=True, return_all=True)\n",
    "        # slect the one with minimum loss\n",
    "\n",
    "        min_loss = float('inf')\n",
    "        best_pred = None\n",
    "        for y_pred in y_preds:\n",
    "            loss_test = loss_fn(y_pred[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "            test_rmse = torch.sqrt(loss_test)\n",
    "            if test_rmse < min_loss:\n",
    "                min_loss = test_rmse\n",
    "                best_pred = y_pred\n",
    "        \n",
    "        test_loss_all.append(min_loss.item())\n",
    "        # revert to global coordinate\n",
    "        # predictions.append(y_pred[:, :validation_step, :2] + current_pos_output)\n",
    "        # truths.append(y_test_batch[:, :validation_step, :2] + current_pos_output)\n",
    "\n",
    "        # predictions.append(best_pred[:, :validation_step, :2].cumsum(dim=1) + current_pos)\n",
    "        # truths.append(y_test_batch[:, :validation_step, :2].cumsum(dim=1) + current_pos)\n",
    "\n",
    "        # predictions.append(y_pred[:, :validation_step, :2])\n",
    "        # truths.append(y_test_batch[:, :validation_step, :2])\n",
    "\n",
    "\n",
    "        y_test_batch[:, 0, :2] = current_pos[:, 0, :2]\n",
    "        y_test_batch = torch.cumsum(y_test_batch, dim=1)\n",
    "        y_test_batch = y_test_batch[:, :validation_step, :2]\n",
    "        prediction = best_pred[:, :validation_step, :2]\n",
    "        prediction[:, 0, :2] = current_pos[:, 0, :2]\n",
    "        prediction = torch.cumsum(prediction, dim=1)\n",
    "        prediction = prediction[:, :validation_step, :2]\n",
    "        predictions.append(prediction)\n",
    "        truths.append(y_test_batch)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Test RMSE: {sum(test_loss_all) / len(test_loss_all)}\")       \n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "truths = torch.cat(truths, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse normalization\n",
    "normalize_dict = stats_dict\n",
    "\n",
    "for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "steps = []\n",
    "loss = []\n",
    "max_loss = []\n",
    "for step in range(1, future_steps+1):\n",
    "    raw_rmse_loss = criterion(predictions[:, :step, :], truths[:, :step, :])\n",
    "    raw_rmse_loss = torch.sqrt(torch.sum(raw_rmse_loss, dim=-1))\n",
    "    mean_rmse_loss = raw_rmse_loss.mean(dim=-1)\n",
    "    max_rmse_loss = raw_rmse_loss.max(dim=-1).values\n",
    "    loss.append(mean_rmse_loss)\n",
    "    max_loss.append(max_rmse_loss)\n",
    "    steps.extend([step] * len(mean_rmse_loss))\n",
    "    \n",
    "max_loss = torch.cat(max_loss).cpu().numpy()\n",
    "loss = torch.cat(loss).cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame({'Second (s)': steps, 'loss': loss})\n",
    "df1 = pd.DataFrame({'Second (s)': steps, 'loss': max_loss})\n",
    "df['type'] = 'mean'\n",
    "df1['type'] = 'max'\n",
    "df = pd.concat([df, df1])\n",
    "\n",
    "\n",
    "df['RMSE Error (m)'] = df['loss'] / 100 # to meters\n",
    "df['Second (s)'] = df['Second (s)'] / 10 # to seconds\n",
    "sns.lineplot(data = df, x='Second (s)', y='RMSE Error (m)', hue='type',) #  errorbar=('sd', 1),\n",
    "plt.savefig(f'../model/{model_name}/{folder_name}/res.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second (s)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.548230</td>\n",
       "      <td>0.548230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.934171</td>\n",
       "      <td>0.536876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>1.392358</td>\n",
       "      <td>0.567279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>1.604216</td>\n",
       "      <td>0.523036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>1.815371</td>\n",
       "      <td>0.497163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>2.024293</td>\n",
       "      <td>0.480105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>2.219446</td>\n",
       "      <td>0.466605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>2.614821</td>\n",
       "      <td>0.482249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>2.831122</td>\n",
       "      <td>0.474742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>3.022951</td>\n",
       "      <td>0.466633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1</th>\n",
       "      <td>3.203134</td>\n",
       "      <td>0.459255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>3.587172</td>\n",
       "      <td>0.470598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3</th>\n",
       "      <td>3.760483</td>\n",
       "      <td>0.463891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>3.934080</td>\n",
       "      <td>0.458614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>4.075286</td>\n",
       "      <td>0.452031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>4.235872</td>\n",
       "      <td>0.447609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7</th>\n",
       "      <td>4.403636</td>\n",
       "      <td>0.444038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.8</th>\n",
       "      <td>4.869186</td>\n",
       "      <td>0.457889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9</th>\n",
       "      <td>5.139966</td>\n",
       "      <td>0.460024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>5.397569</td>\n",
       "      <td>0.461220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1</th>\n",
       "      <td>5.539302</td>\n",
       "      <td>0.457214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2</th>\n",
       "      <td>6.431083</td>\n",
       "      <td>0.487557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3</th>\n",
       "      <td>7.016776</td>\n",
       "      <td>0.501879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>7.170322</td>\n",
       "      <td>0.497449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>7.317200</td>\n",
       "      <td>0.492999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6</th>\n",
       "      <td>7.495565</td>\n",
       "      <td>0.490351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7</th>\n",
       "      <td>7.952060</td>\n",
       "      <td>0.498239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8</th>\n",
       "      <td>8.100080</td>\n",
       "      <td>0.494561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.9</th>\n",
       "      <td>8.240574</td>\n",
       "      <td>0.490882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>8.448173</td>\n",
       "      <td>0.489820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1</th>\n",
       "      <td>8.819397</td>\n",
       "      <td>0.494324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>9.214183</td>\n",
       "      <td>0.499310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.3</th>\n",
       "      <td>9.591898</td>\n",
       "      <td>0.503448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.4</th>\n",
       "      <td>9.722022</td>\n",
       "      <td>0.499957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.5</th>\n",
       "      <td>10.110901</td>\n",
       "      <td>0.504116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.6</th>\n",
       "      <td>10.497478</td>\n",
       "      <td>0.508032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.7</th>\n",
       "      <td>10.631241</td>\n",
       "      <td>0.504841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.8</th>\n",
       "      <td>10.772753</td>\n",
       "      <td>0.502284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.9</th>\n",
       "      <td>11.168420</td>\n",
       "      <td>0.506357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>11.300062</td>\n",
       "      <td>0.503635</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type              max      mean\n",
       "Second (s)                     \n",
       "0.1          0.548230  0.548230\n",
       "0.2          0.934171  0.536876\n",
       "0.3          1.392358  0.567279\n",
       "0.4          1.604216  0.523036\n",
       "0.5          1.815371  0.497163\n",
       "0.6          2.024293  0.480105\n",
       "0.7          2.219446  0.466605\n",
       "0.8          2.614821  0.482249\n",
       "0.9          2.831122  0.474742\n",
       "1.0          3.022951  0.466633\n",
       "1.1          3.203134  0.459255\n",
       "1.2          3.587172  0.470598\n",
       "1.3          3.760483  0.463891\n",
       "1.4          3.934080  0.458614\n",
       "1.5          4.075286  0.452031\n",
       "1.6          4.235872  0.447609\n",
       "1.7          4.403636  0.444038\n",
       "1.8          4.869186  0.457889\n",
       "1.9          5.139966  0.460024\n",
       "2.0          5.397569  0.461220\n",
       "2.1          5.539302  0.457214\n",
       "2.2          6.431083  0.487557\n",
       "2.3          7.016776  0.501879\n",
       "2.4          7.170322  0.497449\n",
       "2.5          7.317200  0.492999\n",
       "2.6          7.495565  0.490351\n",
       "2.7          7.952060  0.498239\n",
       "2.8          8.100080  0.494561\n",
       "2.9          8.240574  0.490882\n",
       "3.0          8.448173  0.489820\n",
       "3.1          8.819397  0.494324\n",
       "3.2          9.214183  0.499310\n",
       "3.3          9.591898  0.503448\n",
       "3.4          9.722022  0.499957\n",
       "3.5         10.110901  0.504116\n",
       "3.6         10.497478  0.508032\n",
       "3.7         10.631241  0.504841\n",
       "3.8         10.772753  0.502284\n",
       "3.9         11.168420  0.506357\n",
       "4.0         11.300062  0.503635"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_results = df.groupby(by=['Second (s)', 'type']).mean().unstack()['RMSE Error (m)']\n",
    "exp_results.to_csv(f'../model/{model_name}/{folder_name}/result.csv')\n",
    "exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export JIT Model\n",
    "\n",
    "Integrate partial of data processing into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXPORT_MODEL = True\n",
    "\n",
    "# # # model.load_state_dict(torch.load(\"/home/shaoze/Documents/Boeing/Boeing-Trajectory-Prediction/model/Jul09_20-37-37/model_40000.pt\"))\n",
    "# # if EXPORT_MODEL:\n",
    "# #     model.eval()\n",
    "# #     model.to('cpu')\n",
    "# #     script_module = torch.jit.script(model)\n",
    "# #     os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# #     script_module.save(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# stats = {}\n",
    "# '''\n",
    "# mean: tensor[]\n",
    "# '''\n",
    "\n",
    "# for keys, values in stats_dict.items():\n",
    "#     stats[keys] = torch.tensor(values.to_list()).view(1,1,-1)\n",
    "    \n",
    "# class TFT_EXP(nn.Module):\n",
    "#     def __init__(self, model:EnhancedTFT, stats:dict):\n",
    "#         super(TFT_EXP, self).__init__()\n",
    "#         self.stats = stats\n",
    "#         self.register_buffer('mean', self.stats['mean'])\n",
    "#         self.register_buffer('std', self.stats['std'])\n",
    "#         self.register_buffer('min', self.stats['min'])\n",
    "#         self.register_buffer('max', self.stats['max'])\n",
    "#         self.TFT = model\n",
    "#         self.num_steps = model.num_steps\n",
    "#         self.num_outputs = model.num_outputs # =2\n",
    "\n",
    "#     def forward(self, x, mask: Optional[torch.Tensor]=None):\n",
    "#         single = False\n",
    "#         if len(x.shape) == 2:\n",
    "#             x = x.unsqueeze(0)\n",
    "#             single = True\n",
    "        \n",
    "#         # normalize\n",
    "#         x = (x - self.mean) / self.std\n",
    "#         x = (x - self.min) / (self.max - self.min)\n",
    "#         # residual\n",
    "#         current_pos_input = x[:, -1, :2].clone().unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "#         current_pos_output = x[:, -1, :2].clone().unsqueeze(1).repeat(1, self.num_steps, 1)\n",
    "#         x[:, :, :2] = x[:, :, :2] - current_pos_input\n",
    "        \n",
    "#         # pass through TFT\n",
    "#         outputs, vq_loss, perplexity = self.TFT(x, mask)\n",
    "#         outputs = outputs.detach()\n",
    "        \n",
    "#         # de-residual\n",
    "#         outputs[:, :, :2] = outputs[:, :, :2] + current_pos_output\n",
    "        \n",
    "#         # denormalize\n",
    "#         outputs = outputs * (self.max[:,:,:self.num_outputs] - self.min[:,:,:self.num_outputs]) + self.min[:,:,:self.num_outputs]\n",
    "#         outputs = outputs * self.std[:,:,:self.num_outputs] + self.mean[:,:,:self.num_outputs]\n",
    "        \n",
    "#         if single:\n",
    "#             outputs = outputs.squeeze(0)\n",
    "#         return outputs\n",
    "\n",
    "# tft_exp = TFT_EXP(model, stats)\n",
    "# tft_exp.to('cpu')\n",
    "# tft_exp.eval()\n",
    "# # script_module = torch.jit.script(tft_exp)\n",
    "# # os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# # script_module.save(\"../exported/model_tft_vqvae_cpu_preproc.pt\")\n",
    "\n",
    "# # export to onnx\n",
    "\n",
    "# dummy_input = torch.randn(1, lookback, feature_dim)\n",
    "# print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "# # Export the wrapped model to ONNX format\n",
    "# torch.onnx.export(\n",
    "#     tft_exp,                   # Wrapped model to export\n",
    "#     dummy_input,                     # Model input\n",
    "#     \"../exported/tft_1111.onnx\",              # Output file name\n",
    "#     export_params=True,              # Store the trained parameter weights inside the model file\n",
    "#     opset_version=13,                # Set the ONNX opset version (adjust as needed)\n",
    "#     do_constant_folding=True,        # Whether to execute constant folding for optimization\n",
    "#     input_names=['input'],           # The model's input names\n",
    "#     output_names=['output'],         # The model's output names\n",
    "#     # dynamic_axes={\n",
    "#     #     'input': {0: 'batch_size'},  # Dynamic batch_size and sequence_length\n",
    "#     #     'output': {0: 'batch_size'}  # Dynamic batch_size for the output\n",
    "#     # }\n",
    "# )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime as ort\n",
    "# import numpy as np\n",
    "\n",
    "# # Path to your ONNX model\n",
    "# model_path = \"../exported/tft_1111.onnx\"\n",
    "\n",
    "# # Create an inference session\n",
    "# session = ort.InferenceSession(model_path)\n",
    "\n",
    "# # Get the name of the input node\n",
    "# input_name = session.get_inputs()[0].name\n",
    "\n",
    "# for file in os.listdir(dir):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         df = process_data(dir+file)\n",
    "#     break\n",
    "\n",
    "# df = df[['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "#        'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "#        'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "#        'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "#        'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "#        'closest_station', 'distance_to_closest_station',\n",
    "#        'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "#        'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "#        'GazeDirection_Z', 'AGV_X', 'AGV_Y',\n",
    "#        'looking_at_closest_station']]\n",
    "\n",
    "# start_idx = 100\n",
    "# input = df.iloc[200:200+lookback].astype(np.float32).values\n",
    "\n",
    "# # add batch\n",
    "# input = input[np.newaxis, :, :]\n",
    "# # Run the model\n",
    "# output = session.run(None, {input_name: input.astype(np.float32)})[0]\n",
    "\n",
    "# output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data (for interactive visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# test_ds = MyDataset(lookback=lookback)\n",
    "# all_ds = ds.dataset\n",
    "# test_ds.dataset = all_ds[len(all_ds)//10 :] # load the last 10% of the data\n",
    "# X_list, y_list = test_ds.generate_data(return_list=True, future_steps=future_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# normalize_dict = stats_dict\n",
    "# pred_data = []\n",
    "# truth_data = []\n",
    "# input_data = []\n",
    "# model.eval()\n",
    "# device = 'cpu'\n",
    "# for i, (X, y) in enumerate(zip(X_list, y_list)):\n",
    "#     current_pos_input = X[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "#     current_pos_output = X[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1).to(device)\n",
    "#     X[:, :, :2] = X[:, :, :2] - current_pos_input\n",
    "\n",
    "#     predictions = model(X.float().to(device))[0][:, :future_steps, :2]\n",
    "#     predictions = predictions + current_pos_output\n",
    "#     predictions = predictions.to('cpu')\n",
    "    \n",
    "#     truths = y[:, :future_steps, :2]\n",
    "#     X[:, :, :2] = X[:, :, :2] + current_pos_input\n",
    "#     model_input = X.float().to(device)[:, :lookback, :2]\n",
    "#     trajectory_id = i\n",
    "    \n",
    "#     # reverse normalization\n",
    "#     for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    \n",
    "#     for group_id in range(predictions.shape[0]):\n",
    "#         for time_step in range(predictions.shape[1]):\n",
    "#             pred_x, pred_y = predictions[group_id, time_step]\n",
    "#             pred_data.append([trajectory_id, group_id, time_step, pred_x.item(), pred_y.item()])\n",
    "\n",
    "#             truth_x, truth_y = truths[group_id, time_step]\n",
    "#             truth_data.append([trajectory_id, group_id, time_step, truth_x.item(), truth_y.item()])\n",
    "        \n",
    "#         for time_step in range(lookback):\n",
    "#             input_x, input_y = model_input[group_id, time_step]\n",
    "#             input_data.append([trajectory_id, group_id, time_step, input_x.item(), input_y.item()])\n",
    "            \n",
    "\n",
    "# pred_df = pd.DataFrame(pred_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# truth_df = pd.DataFrame(truth_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# input_df = pd.DataFrame(input_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_remove = [\n",
    "#     \"../data/pred_tra_all.pkl\",\n",
    "#     \"../data/truth_tra_all.pkl\", \n",
    "#     \"../data/input_tra_all.pkl\"\n",
    "# ]\n",
    "\n",
    "# for file_path in files_to_remove:\n",
    "#     if os.path.exists(file_path):\n",
    "#         os.remove(file_path)\n",
    "\n",
    "# truth_df.to_pickle(\"../data/truth_tra_all.pkl\")\n",
    "# pred_df.to_pickle(\"../data/pred_tra_all.pkl\")\n",
    "# input_df.to_pickle(\"../data/input_tra_all.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
