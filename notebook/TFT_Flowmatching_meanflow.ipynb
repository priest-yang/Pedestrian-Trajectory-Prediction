{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cur_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # Gets the current notebook directory\n",
    "src_dir = os.path.join(cur_dir, '../')  # Constructs the path to the 'src' directory\n",
    "# Add the 'src' directory to sys.path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.constant import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.MyDataset import MyDataset, save_dataset, load_dataset\n",
    "# from src.TFT_Flowmatching import TemporalFusionTransformerDiffusion\n",
    "\n",
    "from src.VQVAE import VQVAE\n",
    "from typing import Optional\n",
    "import pickle\n",
    "\n",
    "import torch.utils\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: direct load data from Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 30\n",
    "future_steps = 40\n",
    "resample = False\n",
    "dir = '../data/Phase3/Modified/'\n",
    "ds = MyDataset(lookback=lookback)\n",
    "train_batch_size = 128\n",
    "test_batch_size = 256\n",
    "\n",
    "train = load_dataset('../data/.cache/train.pkl', batch_size=train_batch_size)\n",
    "test = load_dataset('../data/.cache/test.pkl', batch_size=test_batch_size)\n",
    "stats_dict = pickle.load(open('../data/.cache/stats_dict.pkl', 'rb'))\n",
    "\n",
    "# train = load_dataset('../data/.cache/opentraj_train.pkl', batch_size=train_batch_size)\n",
    "# test = load_dataset('../data/.cache/opentraj_test.pkl', batch_size=test_batch_size)\n",
    "# stats_dict = pickle.load(open('../data/.cache/opentraj_stats_dict.pkl', 'rb'))\n",
    "\n",
    "feature_dim = stats_dict['feature_dim']\n",
    "features = stats_dict['features']\n",
    "\n",
    "\n",
    "feature_dim = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def process_data(df_dir : str, target_freq : int = 10):\n",
    "#     df: pd.DataFrame = pd.read_pickle(df_dir)\n",
    "#     df.columns = df.columns.str.strip() \n",
    "    \n",
    "#     df = df.rename(columns={'State': 'state'})\n",
    "\n",
    "#     states = ['At Station', 'Error', 'Wait', 'Cross', 'Approach Sidewalk',\n",
    "#        'Approach Target Station', 'Move Along Sidewalk']\n",
    "\n",
    "#     states_ohe = pd.get_dummies(df['state'], prefix='state')\n",
    "#     cur_states = df['state'].unique()\n",
    "#     for state in states:\n",
    "#         if state not in cur_states:\n",
    "#             states_ohe['state_'+state] = 0\n",
    "\n",
    "#     df = pd.concat([df, states_ohe], axis=1)\n",
    "#     df.drop(columns=['state'], inplace=True)\n",
    "    \n",
    "#     df.dropna(inplace=True, how='any')\n",
    "#     if resample:\n",
    "#         f_per_sec = df.groupby('TimestampID').count().mean().mean()\n",
    "#         if f_per_sec < target_freq:\n",
    "#             raise ValueError('The frequency of the data is lower than the target frequency')\n",
    "#         elif int(f_per_sec) == target_freq:\n",
    "#             pass\n",
    "#         else:\n",
    "#             resample_ratio = int(f_per_sec/target_freq)\n",
    "#             df = df.iloc[::resample_ratio, :]\n",
    "#     # # for origin\n",
    "#     for drop_column in ['Confidence', 'Timestamp', 'TimestampID', \n",
    "#                           'DatapointID', 'PID', 'SCN', 'U_X', 'U_Y', 'U_Z', \n",
    "#                           'AGV_Z', 'User_Z', 'GazeOrigin_Z', 'User_Pitch', 'User_Yaw', 'User_Roll', \n",
    "#                           'EyeTarget', \n",
    "#                           'start_station_X', 'start_station_Y', 'end_station_X', 'end_station_Y',\n",
    "#                           'distance_from_start_station_X',\n",
    "#                             'distance_from_start_station_Y', 'distance_from_end_station_X',\n",
    "#                             'distance_from_end_station_Y', 'facing_start_station',\n",
    "#                             'facing_end_station', \n",
    "#                             'rolling_avg', \n",
    "#                             'User', 'Type', \n",
    "#                             'possible_interaction'\n",
    "#                           ]:\n",
    "#         df = df.drop(columns=[drop_column], errors='ignore')\n",
    "\n",
    "#     target_columns = ['User_X', 'User_Y']\n",
    "#     # Reorder columns\n",
    "#     new_columns = target_columns + [col for col in df.columns if col not in target_columns]\n",
    "#     df = df[new_columns]\n",
    "    \n",
    "#     # keep numeric columns\n",
    "#     df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "#     return df\n",
    "\n",
    "# for file in os.listdir(dir):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         df = process_data(dir+file)\n",
    "#         ds.read_data(df, agv_col_name=\"scenario\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = process_data(dir+file)\n",
    "# df = df[df['scenario'] == 7]\n",
    "\n",
    "# uer_x, uer_y = df['User_X'].values[10:40], df['User_Y'].values[10:40]\n",
    "\n",
    "# plt.plot(uer_x, uer_y)\n",
    "# # same\n",
    "# plt.title('User Position')\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# # equal aspect ratio\n",
    "# plt.gca().set_aspect('equal', adjustable='box')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(ds.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# stats_dict = {'mean': 0, 'std': 0, 'min': 0, 'max': 0}\n",
    "# stats_dict = ds.normalize_dataset()\n",
    "# ds.generate_data(future_steps=future_steps)\n",
    "\n",
    "# train:torch.utils.data.DataLoader\n",
    "# test:torch.utils.data.DataLoader\n",
    "\n",
    "# train, test = ds.split_data(frac=0.9, shuffle=True, train_batch_size=train_batch_size, test_batch_size=test_batch_size)\n",
    "\n",
    "# feature_dim = ds.feature_dim\n",
    "# stats_dict['feature_dim'] = feature_dim\n",
    "# stats_dict['features'] = ds.dataset[0].columns\n",
    "# columns = [_ for _ in ds.dataset[0].columns if _ not in ['AGV_name']]\n",
    "# print(f\"columns : {df.columns} \\nfeature_dim : {feature_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "       'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "       'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "       'closest_station', 'distance_to_closest_station',\n",
    "       'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "       'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "       'GazeDirection_Z', 'AGV_X', 'AGV_Y', 'looking_at_closest_station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30, 38]) torch.Size([128, 40, 38])\n",
      "317952 35328\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train):\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "\n",
    "print(len(train) * train_batch_size, len(test) * test_batch_size)\n",
    "\n",
    "# # save it to cache to speed up\n",
    "# save_dataset(train, type='train', file_path='../data/.cache/train.pkl')\n",
    "# save_dataset(test, type='test', file_path='../data/.cache/test.pkl')\n",
    "# pickle.dump(stats_dict, open('../data/.cache/stats_dict.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of DiT parameters:  561024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.9995, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from src.DiT import DiT\n",
    "from diffusers.models.attention_processor import AttnProcessor\n",
    "\n",
    "def stopgrad(x):\n",
    "    return x.detach()\n",
    "\n",
    "\n",
    "def append_dims(x, target_dims):\n",
    "    \"\"\"Appends dimensions to the end of a tensor until it has target_dims dimensions.\"\"\"\n",
    "    dims_to_append = target_dims - x.ndim\n",
    "    if dims_to_append < 0:\n",
    "        raise ValueError(f\"input has {x.ndim} dims but target_dims is {target_dims}, which is less\")\n",
    "    return x[(...,) + (None,) * dims_to_append]\n",
    "\n",
    "\n",
    "def adaptive_l2_loss(error, gamma=0, c=1e-3, action_mask=None):\n",
    "    \"\"\"\n",
    "    Adaptive L2 loss: sg(w) * ||Δ||_2^2, where w = 1 / (||Δ||^2 + c)^p, p = 1 - γ\n",
    "    Args:\n",
    "        error: Tensor of shape (B, C, W, H)\n",
    "        gamma: Power used in original ||Δ||^{2γ} loss\n",
    "        c: Small constant for stability\n",
    "    Returns:\n",
    "        Scalar loss\n",
    "    \"\"\"\n",
    "    loss_original = error**2\n",
    "    dims = tuple(range(1, error.ndim))  # all dims except dim 0\n",
    "    if action_mask is not None:\n",
    "        loss_masked = loss_original * action_mask\n",
    "        # Compute mean over dims for each sample, then sum over batch weighted by mask\n",
    "        delta_sq = loss_masked.sum(dim=dims) / (action_mask.sum(dim=dims) + 1e-8)\n",
    "    else:\n",
    "        delta_sq = torch.mean(loss_original, dim=dims, keepdim=False)\n",
    "\n",
    "    p = 1.0 - gamma\n",
    "    w = 1.0 / (delta_sq + c).pow(p)\n",
    "    loss = delta_sq  # ||Δ||^2\n",
    "    return (stopgrad(w) * loss).mean()\n",
    "\n",
    "\n",
    "# class SinusoidalTimeEmbedding(nn.Module):\n",
    "#     def __init__(self, embedding_dim):\n",
    "#         super(SinusoidalTimeEmbedding, self).__init__()\n",
    "#         self.embedding_dim = embedding_dim\n",
    "\n",
    "#     def forward(self, t):\n",
    "#         if len(t.shape) == 1:\n",
    "#             t = t.unsqueeze(1)\n",
    "#         half_dim = self.embedding_dim // 2\n",
    "#         emb_factor = math.log(10000) / (half_dim - 1)\n",
    "#         dims = torch.arange(half_dim, device=t.device, dtype=t.dtype)\n",
    "#         emb = t * torch.exp(-dims * emb_factor)\n",
    "#         emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "#         if self.embedding_dim % 2 == 1:\n",
    "#             emb = F.pad(emb, (0, 1))\n",
    "#         return emb\n",
    "    \n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SinusoidalTimeEmbedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        # Handle both single timestep (N,) and batched timesteps (B, N)\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "            n = 1\n",
    "        elif len(t.shape) == 2:\n",
    "            # For batched input (B, N), reshape to (B*N, 1) for processing\n",
    "            batch_size, n = t.shape\n",
    "            t = t.reshape(-1, 1)\n",
    "        \n",
    "        half_dim = self.embedding_dim // 2\n",
    "        emb_factor = math.log(10000) / (half_dim - 1)\n",
    "        dims = torch.arange(half_dim, device=t.device, dtype=t.dtype)\n",
    "        emb = t * torch.exp(-dims * emb_factor)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        if self.embedding_dim % 2 == 1:\n",
    "            emb = F.pad(emb, (0, 1))\n",
    "            \n",
    "        # Reshape back to (B, N, D) if input was batched\n",
    "        if n > 1:\n",
    "            emb = emb.reshape(batch_size, n, -1)\n",
    "        else:\n",
    "            emb = emb.unsqueeze(1)          \n",
    "        return emb\n",
    "\n",
    "\n",
    "class MeanFlowDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        action_dim,\n",
    "        conditioning_dim,\n",
    "        num_action_steps=20,\n",
    "        hidden_dim=128,\n",
    "        num_layers=2,\n",
    "        num_heads=4,\n",
    "        dropout_rate=0.1,\n",
    "        flow_ratio=0.75,\n",
    "        time_dist=[\"lognorm\", -0.4, 1.0]\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_action_steps = num_action_steps\n",
    "        self.flow_ratio = flow_ratio\n",
    "        self.time_dist = time_dist\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_embed = SinusoidalTimeEmbedding(hidden_dim)\n",
    "        self.time_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Input encoders\n",
    "        self.x_encoder = nn.Linear(action_dim, hidden_dim)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_action_steps, hidden_dim))\n",
    "        self.conditioning_align = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "        # DiT model\n",
    "        self.dit = DiT(\n",
    "            num_attention_heads=num_heads,\n",
    "            attention_head_dim=hidden_dim // num_heads,\n",
    "            output_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_rate,\n",
    "            norm_elementwise_affine=True,\n",
    "            processor=AttnProcessor() # for jvp, need to roll back to the original attn processor\n",
    "        )\n",
    "        \n",
    "        # Final projection layers\n",
    "        self.final_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.proj_1 = nn.Linear(hidden_dim, hidden_dim * 2)\n",
    "        self.proj_2 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, action_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def sample_t_r(self, x_0):\n",
    "        batch_size = x_0.shape[0]\n",
    "        dtype = x_0.dtype\n",
    "        device = x_0.device\n",
    "\n",
    "        if self.time_dist[0] == \"uniform\":\n",
    "            samples = torch.rand(batch_size, 2, dtype=dtype, device=device)\n",
    "        elif self.time_dist[0] == \"lognorm\":\n",
    "            mean, std = self.time_dist[-2], self.time_dist[-1]\n",
    "            normal_samples = torch.randn(batch_size, 2, dtype=dtype, device=device) * std + mean\n",
    "            samples = torch.sigmoid(normal_samples)\n",
    "\n",
    "        t = torch.maximum(samples[:, 0], samples[:, 1])\n",
    "        r = torch.minimum(samples[:, 0], samples[:, 1])\n",
    "\n",
    "        num_selected = int(self.flow_ratio * batch_size)\n",
    "        indices = torch.randperm(batch_size, device=x_0.device)[:num_selected]\n",
    "        r[indices] = t[indices]\n",
    "\n",
    "        return t, r\n",
    "\n",
    "\n",
    "    def forward(self, conditioning, x_t, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, hidden_dim)\n",
    "            x_t: Tensor of shape (batch, num_action_steps, action_dim)\n",
    "            t: Tensor of shape (batch,) with time values in [0,1]\n",
    "        \"\"\"\n",
    "        batch_size = x_t.size(0)\n",
    "        \n",
    "        # Encode input trajectory\n",
    "        x_encoded = self.x_encoder(x_t)\n",
    "        \n",
    "        # Combine encoded trajectory with time embedding\n",
    "        x = x_encoded + self.pos_embed\n",
    "        \n",
    "        # Process conditioning - average pooling as a simple approach\n",
    "        if conditioning.size(1) > 1:\n",
    "            cond_pooled = torch.mean(conditioning, dim=1, keepdim=True)  # [batch, 1, hidden_dim]\n",
    "        else:\n",
    "            cond_pooled = conditioning\n",
    "        \n",
    "        # Time embedding\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        t_emb = self.time_embed(t)  # [batch, hidden_dim]\n",
    "        t_emb = self.time_proj(t_emb)  # Project time embedding\n",
    "\n",
    "        # concat with x_encoded\n",
    "        x = torch.concat([t_emb, x],dim=1)\n",
    "        \n",
    "        # Broadcast time embedding to match sequence length\n",
    "        # use mean time_embed for following process\n",
    "        # t_emb = t_emb.mean(dim=1, keepdim=True).repeat(1, x_t.size(1), 1)\n",
    "        \n",
    "        # # Repeat conditioning for each timestep in the sequence\n",
    "        # cond_expanded = cond_pooled.repeat(1, x_t.size(1), 1)\n",
    "        # cond_expanded = torch.cat([cond_expanded, t_emb], dim=-1)\n",
    "        # cond_expanded = self.conditioning_align(cond_expanded)\n",
    "\n",
    "        cond_expanded = cond_pooled\n",
    "\n",
    "        # Process through DiT model (instead of iterating through DiTBlocks)\n",
    "        # Convert timestep to the format DiT expects\n",
    "        timesteps = (t.mean(dim=1) * 1000).long()  # Scale to typical timestep range\n",
    "        # Pass through the DiT model\n",
    "        x = self.dit(\n",
    "            hidden_states=x,\n",
    "            encoder_hidden_states=cond_expanded,\n",
    "            timestep=timesteps\n",
    "        )\n",
    "        \n",
    "        # Final processing\n",
    "        x = self.final_norm(x)\n",
    "        x = F.gelu(self.proj_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.gelu(self.proj_2(x))\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        output = self.output(x)\n",
    "        output = output[:, -self.num_action_steps:, :]\n",
    "        \n",
    "        return output  # [batch, num_action_steps, action_dim]\n",
    "    \n",
    "    def denoise(self, conditioning, z, r, t):\n",
    "        combine_t = torch.stack([t, t - r], dim=1)\n",
    "        model_output = self.forward(conditioning, z, combine_t)\n",
    "        return model_output\n",
    "\n",
    "    def decoder_train_step(self, conditioning, y_batch, device):\n",
    "        \"\"\"\n",
    "        Performs one training step for the mean flow decoder.\n",
    "        \n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "            y_batch: Ground truth trajectory (batch, num_action_steps, action_dim)\n",
    "            device: torch.device\n",
    "        \n",
    "        Returns:\n",
    "            loss: The adaptive L2 loss\n",
    "        \"\"\"\n",
    "        t, r = self.sample_t_r(y_batch)\n",
    "        \n",
    "        # Add dimensions to match y_batch shape\n",
    "        t_ = append_dims(t, y_batch.ndim)\n",
    "        r_ = append_dims(r, y_batch.ndim)\n",
    "        \n",
    "        # Sample noise\n",
    "        e = torch.randn_like(y_batch)\n",
    "        \n",
    "        # Compute noisy sample\n",
    "        z = (1 - t_) * y_batch + t_ * e\n",
    "        v = e - y_batch\n",
    "\n",
    "        # Compute model output and its derivative\n",
    "        \n",
    "        u, dudt = torch.autograd.functional.jvp(\n",
    "            lambda z, r, t: self.denoise(conditioning, z, r, t),\n",
    "            (z, r, t),\n",
    "            (v, torch.zeros_like(r), torch.ones_like(t)),\n",
    "            create_graph=True,\n",
    "        )\n",
    "\n",
    "        # Compute target\n",
    "        u_tgt = v - (t_ - r_) * dudt\n",
    "\n",
    "        # Compute error and loss\n",
    "        error = u - stopgrad(u_tgt)\n",
    "        loss = adaptive_l2_loss(error)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def influence(self, conditioning, device):\n",
    "        \"\"\"\n",
    "        Runs the mean flow sampling process.\n",
    "        \n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "            device: torch.device\n",
    "        \n",
    "        Returns:\n",
    "            x: The final generated trajectory\n",
    "        \"\"\"\n",
    "        batch_size = conditioning.size(0)\n",
    "        e = torch.randn(batch_size, self.num_action_steps, self.action_dim, device=device)\n",
    "        \n",
    "        t = torch.ones((batch_size,), device=device)\n",
    "        r = torch.zeros((batch_size,), device=device)\n",
    "        \n",
    "        out = e - self.denoise(conditioning, e, r, t)\n",
    "        return out\n",
    "    \n",
    "lookback = 30\n",
    "future_steps = 40\n",
    "resample = False\n",
    "dir = '../data/Phase3/Modified/'\n",
    "ds = MyDataset(lookback=lookback)\n",
    "train_batch_size = 128\n",
    "test_batch_size = 256\n",
    "feature_dim =38\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "decoder = MeanFlowDecoder(action_dim=2, conditioning_dim=feature_dim, num_action_steps=future_steps, hidden_dim=128, num_layers=2, num_heads=4)\n",
    "y_batch = torch.randn(16, 40, 2).to(device)\n",
    "condition = torch.randn(16, 1, 128).to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "decoder.decoder_train_step(condition, y_batch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from src.VQVAE import VQVAE\n",
    "from src.DiT import SelfAttentionTransformer\n",
    "import math\n",
    "\n",
    "###############################################\n",
    "# Original Blocks (with minor efficiency tweaks)\n",
    "###############################################\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=3, dropout_rate=0.1):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)]\n",
    "        )\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "        self.gate = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_input = x\n",
    "        for layer, norm in zip(self.layers, self.norms):\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "            x = norm(x)\n",
    "        gate = torch.sigmoid(self.gate(x))\n",
    "        x2 = self.fc2(x)\n",
    "        return self.fc3(x_input) + gate * x2\n",
    "    \n",
    "    \n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int):\n",
    "        super(GRUEncoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # update gate parameters\n",
    "        self.x2z = nn.Linear(input_dim,  hidden_dim)\n",
    "        self.h2z = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        # reset  gate parameters\n",
    "        self.x2r = nn.Linear(input_dim,  hidden_dim)\n",
    "        self.h2r = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        # candidate hidden state parameters\n",
    "        self.x2h = nn.Linear(input_dim,  hidden_dim)\n",
    "        self.h2h = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, h0: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x:  Tensor of shape (batch, seq_len, input_dim)\n",
    "          h0: Optional initial hidden state, shape (batch, hidden_dim)\n",
    "        Returns:\n",
    "          outputs: Tensor of shape (batch, seq_len, hidden_dim)\n",
    "          h_t:      Tensor of shape (batch, hidden_dim), the final hidden state\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # initialize hidden state if not provided\n",
    "        if h0 is None:\n",
    "            h_t = x.new_zeros(batch_size, self.hidden_dim)\n",
    "        else:\n",
    "            h_t = h0\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            \n",
    "            # compute gates\n",
    "            z_t = torch.sigmoid(self.x2z(x_t) + self.h2z(h_t))      # update gate\n",
    "            r_t = torch.sigmoid(self.x2r(x_t) + self.h2r(h_t))      # reset  gate\n",
    "            \n",
    "            # candidate hidden state\n",
    "            h_tilde = torch.tanh(self.x2h(x_t) + self.h2h(r_t * h_t))\n",
    "            \n",
    "            # new hidden state\n",
    "            h_t = (1 - z_t) * h_t + z_t * h_tilde\n",
    "\n",
    "            outputs.append(h_t.unsqueeze(1))\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, hidden_dim)\n",
    "        return outputs, h_t\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout_rate)\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size * 4, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask: Optional[torch.Tensor] = None):\n",
    "        # x: (seq_len, batch, hidden_size)\n",
    "        x2 = x\n",
    "        x = self.norm1(x)\n",
    "        x, _ = self.attention(x, x, x, key_padding_mask=mask)\n",
    "        x = x + x2\n",
    "        x2 = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = x + x2\n",
    "        return x\n",
    "\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "\n",
    "class TemporalFusionTransformerDiffusion(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_outputs, num_steps, his_steps = 30, \n",
    "                 num_attention_heads=8, vqvae: VQVAE = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_features (int): Number of input features.\n",
    "            num_hidden (int): Hidden dimension size.\n",
    "            num_outputs (int): Dimensionality of each output (e.g. action dimension).\n",
    "            num_steps (int): Desired output sequence length (e.g. number of action steps).\n",
    "            num_attention_heads (int): Number of heads for the transformer blocks.\n",
    "            diffusion_steps (int): Number of diffusion (denoising) steps.\n",
    "        \"\"\"\n",
    "        super(TemporalFusionTransformerDiffusion, self).__init__()\n",
    "        if vqvae is None:\n",
    "            self.vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "        else:\n",
    "            self.vqvae = vqvae\n",
    "\n",
    "        self.num_hidden = num_hidden\n",
    "        num_features = num_features + self.vqvae.encoder.fc2.out_features\n",
    "        self.encoder_grn = GatedResidualNetwork(num_features, num_hidden, num_hidden)\n",
    "        \n",
    "        # self.transformer_block = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        # self.transformer_block2 = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        \n",
    "        self.transformer_encoder = SelfAttentionTransformer(num_attention_heads=num_attention_heads, \n",
    "                                                            attention_head_dim=num_hidden // num_attention_heads, \n",
    "                                                            output_dim=num_hidden, \n",
    "                                                            num_layers=2, \n",
    "                                                            dropout=0.1, attention_bias=True, \n",
    "                                                            activation_fn=\"gelu-approximate\", \n",
    "                                                            max_num_positional_embeddings=512, \n",
    "                                                            compute_dtype=torch.float32, \n",
    "                                                            final_dropout=True, \n",
    "                                                            positional_embeddings=\"sinusoidal\", \n",
    "                                                            interleave_self_attention=False)\n",
    "        self.encoder_gru = GRUEncoder(num_hidden, num_hidden)\n",
    "        self.his_steps = his_steps\n",
    "\n",
    "        # Diffusion decoder: we set action_dim=num_outputs and produce a sequence of length num_steps.\n",
    "        self.diffusion_decoder = MeanFlowDecoder(\n",
    "            action_dim=num_outputs,\n",
    "            conditioning_dim=num_hidden,\n",
    "            num_action_steps=num_steps,\n",
    "            num_heads=num_attention_heads,  \n",
    "            hidden_dim=num_hidden, \n",
    "            num_layers=2,  # you can adjust as needed\n",
    "            # noise_weight=0.5  # you can adjust as needed\n",
    "        )\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "\n",
    "    def forward(self, x, y_batch=None , mask: Optional[torch.Tensor] = None, influence=False, return_all=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, seq_len, num_features).\n",
    "            mask: Optional attention mask for the transformer blocks.\n",
    "            \n",
    "        Returns:\n",
    "            actions: Tensor of shape (batch, num_steps, num_outputs)\n",
    "        \"\"\"\n",
    "        # If given a 2D input, add a batch dimension.\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # VQ-VAE\n",
    "        x_recon, vq_loss, perplexity, embedding = self.vqvae(x)\n",
    "        x = torch.cat((x, embedding), dim=-1)\n",
    "        \n",
    "        # Encoder GRN.\n",
    "        x = self.encoder_grn(x)  # (batch, seq_len, num_hidden)\n",
    "        \n",
    "        # Transformer expects (seq_len, batch, hidden_size).\n",
    "        # x = x.permute(1, 0, 2)\n",
    "        # x = self.transformer_block(x, mask=mask)\n",
    "        # x = self.transformer_block2(x, mask=mask)\n",
    "        # x = x.permute(1, 0, 2)  # back to (batch, seq_len, num_hidden)\n",
    "        \n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "\n",
    "        # Use a summary of the encoder output as conditioning.\n",
    "        # Here we use the last time–step (you might also try an average or more complex pooling).\n",
    "        x, conditioning = self.encoder_gru(x)  # (batch, seq_len, num_hidden)\n",
    "        conditioning = conditioning.unsqueeze(1)\n",
    "        # conditioning = x[:, -1:, :] #self.condition_proj()  # (batch, 1, num_hidden)\n",
    "\n",
    "        # flow matching during training\n",
    "        self.device = next(self.parameters()).device\n",
    "        \n",
    "        if influence:\n",
    "            return [self.diffusion_decoder.influence(conditioning, self.device)] if return_all else self.diffusion_decoder.influence(conditioning, self.device)\n",
    "        else:\n",
    "            if self.training:\n",
    "                max_displace = torch.max(y_batch, dim=1).values - torch.min(y_batch, dim=1).values\n",
    "                max_displace = torch.linalg.norm(max_displace, dim=1)\n",
    "                diff_loss = self.diffusion_decoder.decoder_train_step(conditioning, y_batch, self.device)\n",
    "                diff_loss = diff_loss.mean()\n",
    "                return diff_loss, vq_loss\n",
    "            \n",
    "\n",
    "    def influence(self, x):\n",
    "        User_trajectory = self.forward(x, influence=True)\n",
    "        return User_trajectory\n",
    "\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using {device}\")\n",
    "\n",
    "# vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "# model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps, diffusion_steps=10, vqvae=vqvae)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# model.to(device)\n",
    "\n",
    "# X_batch, y_batch = next(iter(train))\n",
    "# X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "# model(X_batch, y_batch[:, :future_steps, :2], influence=True).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Total number of SelfAttentionTransformer parameters:  396544\n",
      "Total number of DiT parameters:  561024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalFusionTransformerDiffusion(\n",
       "  (vqvae): VQVAE(\n",
       "    (encoder): VQVAEEncoder(\n",
       "      (fc1): Linear(in_features=38, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "    (quantizer): VectorQuantizer(\n",
       "      (embedding): Embedding(128, 128)\n",
       "    )\n",
       "    (decoder): VQVAEDecoder(\n",
       "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=38, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_grn): GatedResidualNetwork(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=166, out_features=128, bias=True)\n",
       "      (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-2): 3 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=166, out_features=128, bias=True)\n",
       "    (gate): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (transformer_encoder): SelfAttentionTransformer(\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0-1): 2 x BasicTransformerBlock(\n",
       "        (pos_embed): SinusoidalPositionalEmbedding()\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn1): Attention(\n",
       "          (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (net): ModuleList(\n",
       "            (0): GELU(\n",
       "              (proj): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (final_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder_gru): GRUEncoder(\n",
       "    (x2z): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (h2z): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (x2r): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (h2r): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (x2h): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (h2h): Linear(in_features=128, out_features=128, bias=False)\n",
       "  )\n",
       "  (diffusion_decoder): MeanFlowDecoder(\n",
       "    (time_embed): SinusoidalTimeEmbedding()\n",
       "    (time_proj): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (x_encoder): Linear(in_features=2, out_features=128, bias=True)\n",
       "    (conditioning_align): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dit): DiT(\n",
       "      (timestep_encoder): TimestepEncoder(\n",
       "        (time_proj): Timesteps()\n",
       "        (timestep_embedder): TimestepEmbedding(\n",
       "          (linear_1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (act): SiLU()\n",
       "          (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0-1): 2 x BasicTransformerBlock(\n",
       "          (pos_embed): SinusoidalPositionalEmbedding()\n",
       "          (norm1): AdaLayerNorm(\n",
       "            (silu): SiLU()\n",
       "            (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          )\n",
       "          (attn1): Attention(\n",
       "            (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (to_out): ModuleList(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): FeedForward(\n",
       "            (net): ModuleList(\n",
       "              (0): GELU(\n",
       "                (proj): Linear(in_features=128, out_features=512, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.1, inplace=False)\n",
       "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm((128,), eps=1e-06, elementwise_affine=False)\n",
       "      (proj_out_1): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (proj_out_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (final_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (proj_1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (proj_2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (output): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecayLoss(nn.Module):\n",
    "    def __init__(self, num_steps, baseline_loss_fn=nn.L1Loss()):\n",
    "        super(DecayLoss, self).__init__()\n",
    "        # Weight decreases as we move further into the future\n",
    "        self.weights = torch.linspace(1.0, 1.0, num_steps)\n",
    "        self.baseline_loss_fn = baseline_loss_fn\n",
    "        \n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        loss = 0\n",
    "        for i in range(predictions.shape[1]):\n",
    "            loss += self.weights[i] * self.baseline_loss_fn(predictions[:, i], targets[:, i])\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "baseline_loss_fn = nn.L1Loss() #nn.MSELoss()\n",
    "loss_fn = DecayLoss(future_steps, baseline_loss_fn=baseline_loss_fn)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps, vqvae=vqvae)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/home/shaoze/Documents/Prediction/Pedestrian-Trajectory-Prediction/model/TFT_Flowmatching/Jun07_07-05-43/best_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer with early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at ../model/TFT_MeanFlow/Jun08_15-34-36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b99e96fd59f45bd9e85e23468c99d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 500, Loss: 0.934783, VQ Loss: 0.013466, Diff Loss: 0.921317, learning rate: 5.00e-04\n",
      "Epoch 1, Step 1000, Loss: 0.902776, VQ Loss: 0.014427, Diff Loss: 0.888349, learning rate: 5.00e-04\n",
      "Epoch 1, Step 1500, Loss: 0.881735, VQ Loss: 0.010348, Diff Loss: 0.871386, learning rate: 5.00e-04\n",
      "Epoch 1, Step 2000, Loss: 0.878532, VQ Loss: 0.010470, Diff Loss: 0.868063, learning rate: 5.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "595efdbda8bc42aeb29eaba199014ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 16, Loss: 0.873264, VQ Loss: 0.009563, Diff Loss: 0.863701, learning rate: 5.00e-04\n",
      "Epoch 2, Step 516, Loss: 0.866975, VQ Loss: 0.009030, Diff Loss: 0.857944, learning rate: 5.00e-04\n",
      "Epoch 2, Step 1016, Loss: 0.865404, VQ Loss: 0.009016, Diff Loss: 0.856388, learning rate: 5.00e-04\n",
      "Epoch 2, Step 1516, Loss: 0.860666, VQ Loss: 0.008926, Diff Loss: 0.851741, learning rate: 5.00e-04\n",
      "Epoch 2, Step 2016, Loss: 0.858210, VQ Loss: 0.008827, Diff Loss: 0.849383, learning rate: 5.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb647636dbea4bb4a05c71eaa92e04bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 32, Loss: 0.851300, VQ Loss: 0.008990, Diff Loss: 0.842311, learning rate: 5.00e-04\n",
      "Steps 5000: test RMSE 1.7395, moving average RMSE 1.7395, learning rate 5.00e-04\n",
      "Epoch 3, Step 532, Loss: 0.849499, VQ Loss: 0.009046, Diff Loss: 0.840453, learning rate: 5.00e-04\n",
      "Epoch 3, Step 1032, Loss: 0.850591, VQ Loss: 0.009093, Diff Loss: 0.841498, learning rate: 5.00e-04\n",
      "Epoch 3, Step 1532, Loss: 0.850213, VQ Loss: 0.009653, Diff Loss: 0.840559, learning rate: 5.00e-04\n",
      "Epoch 3, Step 2032, Loss: 0.855396, VQ Loss: 0.009305, Diff Loss: 0.846091, learning rate: 5.00e-04\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90af625acf5b41f6963796bb26c1bb81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 48, Loss: 0.845237, VQ Loss: 0.009936, Diff Loss: 0.835301, learning rate: 5.00e-04\n",
      "Epoch 4, Step 548, Loss: 0.844493, VQ Loss: 0.009386, Diff Loss: 0.835106, learning rate: 5.00e-04\n",
      "Epoch 4, Step 1048, Loss: 0.840440, VQ Loss: 0.010168, Diff Loss: 0.830273, learning rate: 5.00e-04\n",
      "Epoch 4, Step 1548, Loss: 0.839358, VQ Loss: 0.009918, Diff Loss: 0.829440, learning rate: 5.00e-04\n",
      "Epoch 4, Step 2048, Loss: 0.840549, VQ Loss: 0.010308, Diff Loss: 0.830241, learning rate: 5.00e-04\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_epochs = 4\n",
    "eval_step = 5000\n",
    "save_every = 10000\n",
    "patience = 8  # Number of evaluations to wait for improvement\n",
    "cooldown = 4  # Evaluations to wait after an improvement before counting non-improvements\n",
    "smooth_factor = 0.6  # Smoothing factor for moving average\n",
    "lambda_flow = 1e-3  # Weight for flow matching loss\n",
    "print_every = 500\n",
    "\n",
    "# Setup\n",
    "train_all = len(train)\n",
    "model_name = \"TFT_MeanFlow\"\n",
    "from collections import defaultdict\n",
    "loss_all = defaultdict(list)\n",
    "best_test_rmse = float('inf')\n",
    "early_stopping_counter = 0\n",
    "cooldown_counter = cooldown\n",
    "\n",
    "now = datetime.now()\n",
    "folder_name = now.strftime(\"%b%d_%H-%M-%S\")\n",
    "print(f\"Saving model at ../model/{model_name}/{folder_name}\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-4)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=min(len(train) * n_epochs, 100000), eta_min=1e-8)\n",
    "# Define scheduler: ReduceLROnPlateau\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',        # 'min' because we want to minimize loss\n",
    "    factor=0.2,        # Reduce LR by factor of 0.2 (i.e., lr / 5)\n",
    "    patience=3000,     # Number of steps with no significant improvement before reducing LR\n",
    "    threshold=5e-4,    # Minimum change in loss to qualify as \"significant\"\n",
    "    min_lr=1e-8,       # Minimum LR to stop at\n",
    "    verbose=True       # Prints a message when LR is reduced\n",
    ")\n",
    "\n",
    "os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "\n",
    "\n",
    "# Initialize moving average\n",
    "moving_avg_test_rmse = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, (X_batch, y_batch) in tqdm(enumerate(train), total=train_all):\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        y_batch = y_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_batch[:, :, :2] = X_batch[:, :, :2] - current_pos_input\n",
    "        y_batch[:, :, :2] = y_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "        # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "        # y_batch = y_batch[:, ::2, :2]\n",
    "        # X_batch = X_batch[:, ::2, :]\n",
    "\n",
    "        X_batch = F.pad(X_batch, (0, feature_dim - X_batch.shape[-1]))\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # y_pred, vq_loss, perplexity = model(X_batch, y_batch=y_batch)\n",
    "        # loss = loss_fn(y_pred[:, :future_steps, :2], y_batch[:, :future_steps, :2])\n",
    "        diff_loss, vq_loss = model(X_batch, y_batch[:, :future_steps, :2])\n",
    "\n",
    "\n",
    "        loss_all['diff_loss'].append(diff_loss.item())\n",
    "        loss_all['vq_loss'].append(vq_loss.item() * 10)\n",
    "        \n",
    "        loss_all['loss'].append(diff_loss.item() + vq_loss.item() * 10)\n",
    "        # add vq_loss\n",
    "        loss = diff_loss  + 10 * vq_loss\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss.item())\n",
    "\n",
    "        if (epoch * train_all + step + 1) % print_every == 0:\n",
    "            loss_item = sum(loss_all['loss'][-100:]) / 100\n",
    "            vq_loss_item = sum(loss_all['vq_loss'][-100:]) / 100\n",
    "            diff_loss_item = sum(loss_all['diff_loss'][-100:]) / 100\n",
    "            print(f\"Epoch {epoch+1}, Step {step+1}, Loss: {loss_item:.6f}, VQ Loss: {vq_loss_item:.6f}, Diff Loss: {diff_loss_item:.6f}, learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # Save model\n",
    "        if (epoch * train_all + step + 1) % save_every == 0:\n",
    "            os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "            save_path = f\"../model/{model_name}/{folder_name}/model_{epoch * train_all + step + 1}.pt\"\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at {save_path}\")\n",
    "\n",
    "        # Validation and early stopping\n",
    "        if (epoch * train_all + step + 1) % eval_step == 0:\n",
    "            model.eval()\n",
    "            test_rmse_all = []\n",
    "            with torch.no_grad():\n",
    "                for X_test_batch, y_test_batch in test:\n",
    "                    # handle dim mismatch\n",
    "                    if len(X_test_batch.shape) == 2:\n",
    "                        X_test_batch = X_test_batch.unsqueeze(0)\n",
    "                        y_test_batch = y_test_batch.unsqueeze(0)\n",
    "                        \n",
    "                    X_test_batch = X_test_batch.float().to(device)\n",
    "                    y_test_batch = y_test_batch.float().to(device)\n",
    "                    \n",
    "                    current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "                    current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "                    X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "                    y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "                    # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "                    # y_test_batch = y_test_batch[:, ::2, :2]\n",
    "                    # X_test_batch = X_test_batch[:, ::2, :]\n",
    "                    \n",
    "                    X_test_batch = F.pad(X_test_batch, (0, feature_dim - X_test_batch.shape[-1]))\n",
    "\n",
    "\n",
    "                    y_pred_test = model(X_test_batch, influence=True)\n",
    "                    loss_test = loss_fn(y_pred_test[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "                    test_rmse = torch.sqrt(loss_test)\n",
    "                    if not torch.isnan(test_rmse):\n",
    "                        test_rmse_all.append(test_rmse.item())\n",
    "            \n",
    "            current_rmse = sum(test_rmse_all) / len(test_rmse_all)\n",
    "            if moving_avg_test_rmse is None:\n",
    "                moving_avg_test_rmse = current_rmse\n",
    "            else:\n",
    "                moving_avg_test_rmse = smooth_factor * current_rmse + (1 - smooth_factor) * moving_avg_test_rmse\n",
    "\n",
    "            print(f\"Steps {epoch * train_all + step + 1}: test RMSE {current_rmse:.4f}, moving average RMSE {moving_avg_test_rmse:.4f}, learning rate {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            # Check if the moving average RMSE is better; if not, increment counter\n",
    "            if moving_avg_test_rmse < best_test_rmse:\n",
    "                best_test_rmse = moving_avg_test_rmse\n",
    "                early_stopping_counter = 0  # Reset counter\n",
    "                cooldown_counter = cooldown  # Reset cooldown\n",
    "                # Optionally save the best model\n",
    "                os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "                best_model_path = f\"../model/{model_name}/{folder_name}/best_model.pt\"\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                if cooldown_counter > 0:\n",
    "                    cooldown_counter -= 1\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Stopping early at epoch {epoch+1}, step {step+1}\")\n",
    "                break\n",
    "\n",
    "            model.train()\n",
    "        \n",
    "    if early_stopping_counter >= patience:\n",
    "        break\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "078ce7c4e1bb4650a31b6418c810ca37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.2167664869971897\n"
     ]
    }
   ],
   "source": [
    "validation_step = future_steps\n",
    "\n",
    "predictions = []\n",
    "truths = []\n",
    "\n",
    "max_test_batch = 200\n",
    "cur_test = 0\n",
    "\n",
    "test_loss_all = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    all_test = len(test)\n",
    "    test_rmse_all = []\n",
    "    for X_test_batch, y_test_batch in tqdm(test):\n",
    "        cur_test += 1\n",
    "        if cur_test > max_test_batch:\n",
    "            break\n",
    "\n",
    "        X_test_batch = X_test_batch.float().to(device)\n",
    "        y_test_batch = y_test_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "        y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "        X_test_batch = F.pad(X_test_batch, (0, feature_dim - X_test_batch.shape[-1]))\n",
    "\n",
    "\n",
    "        # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "        # y_test_batch = y_test_batch[:, ::2, :2]\n",
    "        # X_test_batch = X_test_batch[:, ::2, :]\n",
    "        \n",
    "        y_preds = model(X_test_batch, influence=True, return_all=True)\n",
    "        # slect the one with minimum loss\n",
    "\n",
    "        min_loss = float('inf')\n",
    "        best_pred = None\n",
    "        for y_pred in y_preds:\n",
    "            loss_test = loss_fn(y_pred[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "            test_rmse = torch.sqrt(loss_test)\n",
    "            if test_rmse < min_loss:\n",
    "                min_loss = test_rmse\n",
    "                best_pred = y_pred\n",
    "        \n",
    "        test_loss_all.append(min_loss.item())\n",
    "\n",
    "        predictions.append(y_pred[:, :validation_step, :2] + current_pos_output[:, :y_pred.shape[1], :2])\n",
    "        truths.append(y_test_batch[:, :validation_step, :2] + current_pos_output[:, :y_pred.shape[1], :2])\n",
    "\n",
    "\n",
    "print(f\"Test RMSE: {sum(test_loss_all) / len(test_loss_all)}\")       \n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "truths = torch.cat(truths, dim=0)\n",
    "\n",
    "# reverse normalization\n",
    "normalize_dict = stats_dict\n",
    "\n",
    "for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume predictions and truths are torch tensors of shape (batch_size, num_steps, num_dims)\n",
    "# # Also assume model_name and folder_name are defined strings for saving the plot.\n",
    "# criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "# steps = []\n",
    "# ade_loss = []\n",
    "# fde_loss = []\n",
    "\n",
    "# # Loop over each prediction horizon (step)\n",
    "# for step in range(1, predictions.size(1) + 1):\n",
    "#     # Compute MSE loss for the first 'step' timesteps for all samples\n",
    "#     raw_loss = criterion(predictions[:, :step, :], truths[:, :step, :])\n",
    "#     # Sum loss over the coordinate dimension and take square root to get RMSE per timestep per sample\n",
    "#     raw_rmse = torch.sqrt(torch.sum(raw_loss, dim=-1))\n",
    "    \n",
    "#     # ADE: average RMSE over all time steps for each sample\n",
    "#     current_ade = raw_rmse.mean(dim=-1)\n",
    "#     # FDE: RMSE error at the final timestep for each sample\n",
    "#     current_fde = raw_rmse[:, -1]  # Alternatively, use: raw_rmse.max(dim=-1).values\n",
    "    \n",
    "#     ade_loss.append(current_ade)\n",
    "#     fde_loss.append(current_fde)\n",
    "#     steps.extend([step] * len(current_ade))\n",
    "\n",
    "# # Concatenate results across all steps and move to CPU numpy arrays\n",
    "# ade_loss = torch.cat(ade_loss).cpu().numpy()\n",
    "# fde_loss = torch.cat(fde_loss).cpu().numpy()\n",
    "\n",
    "# # Create DataFrames for ADE and FDE\n",
    "# df_ade = pd.DataFrame({'Step': steps, 'Loss': ade_loss, 'Metric': 'ADE'})\n",
    "# df_fde = pd.DataFrame({'Step': steps, 'Loss': fde_loss, 'Metric': 'FDE'})\n",
    "\n",
    "# # Combine both DataFrames\n",
    "# df = pd.concat([df_ade, df_fde], ignore_index=True)\n",
    "\n",
    "# # Convert step count to seconds and scale the RMSE error to meters\n",
    "# df['Second (s)'] = df['Step'] / 10   # For example, if 5 steps equal 1 second\n",
    "# df['RMSE Error (m)'] = df['Loss'] / 100  # Convert error to meters\n",
    "\n",
    "# # Plot the ADE and FDE curves using seaborn\n",
    "# sns.lineplot(data=df, x='Second (s)', y='RMSE Error (m)', hue='Metric')\n",
    "# plt.title(\"Trajectory Prediction Error: ADE vs FDE\")\n",
    "# plt.xlabel(\"Time (s)\")\n",
    "# plt.ylabel(\"RMSE Error (m)\")\n",
    "# # plt.savefig(f'../model/{model_name}/{folder_name}/res.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "steps = []\n",
    "loss = []\n",
    "max_loss = []\n",
    "for step in range(1, predictions.size(1) + 1):\n",
    "    raw_rmse_loss = criterion(predictions[:, :step, :], truths[:, :step, :])\n",
    "    raw_rmse_loss = torch.sqrt(torch.sum(raw_rmse_loss, dim=-1))\n",
    "    mean_rmse_loss = raw_rmse_loss.mean(dim=-1)\n",
    "    max_rmse_loss = raw_rmse_loss.max(dim=-1).values\n",
    "    loss.append(mean_rmse_loss)\n",
    "    max_loss.append(max_rmse_loss)\n",
    "    steps.extend([step] * len(mean_rmse_loss))\n",
    "    \n",
    "max_loss = torch.cat(max_loss).cpu().numpy()\n",
    "loss = torch.cat(loss).cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame({'Second (s)': steps, 'loss': loss})\n",
    "df1 = pd.DataFrame({'Second (s)': steps, 'loss': max_loss})\n",
    "df['type'] = 'mean'\n",
    "df1['type'] = 'max'\n",
    "df = pd.concat([df, df1])\n",
    "\n",
    "\n",
    "df['RMSE Error (m)'] = df['loss'] / 100 # to meters\n",
    "df['Second (s)'] = df['Second (s)'] / 10 # to seconds\n",
    "sns.lineplot(data = df, x='Second (s)', y='RMSE Error (m)', hue='type',) #  errorbar=('sd', 1),\n",
    "plt.savefig(f'../model/{model_name}/{folder_name}/res.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize\n",
    "\n",
    "time_stamp = 21539\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "pred = predictions[time_stamp, :, :].cpu().numpy()\n",
    "truth = truths[time_stamp, :, :].cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# equal axis\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.plot(pred[:, 0], pred[:, 1], color='blue', label='Predicted Trajectory')\n",
    "ax.plot(truth[:, 0], truth[:, 1], color='red', label='Ground Truth Trajectory')\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_title('Predicted vs Ground Truth Trajectory')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second (s)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.484973</td>\n",
       "      <td>0.484973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.617330</td>\n",
       "      <td>0.493961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.691306</td>\n",
       "      <td>0.499424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.760760</td>\n",
       "      <td>0.511441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.811654</td>\n",
       "      <td>0.521896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.855982</td>\n",
       "      <td>0.533225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.892222</td>\n",
       "      <td>0.543846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.923317</td>\n",
       "      <td>0.552929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.954907</td>\n",
       "      <td>0.562222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.987372</td>\n",
       "      <td>0.571389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1</th>\n",
       "      <td>1.011652</td>\n",
       "      <td>0.580639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>1.037865</td>\n",
       "      <td>0.590949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3</th>\n",
       "      <td>1.065261</td>\n",
       "      <td>0.601041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>1.087906</td>\n",
       "      <td>0.610356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>1.115279</td>\n",
       "      <td>0.619841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>1.143024</td>\n",
       "      <td>0.629787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7</th>\n",
       "      <td>1.166811</td>\n",
       "      <td>0.639358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.8</th>\n",
       "      <td>1.193063</td>\n",
       "      <td>0.648796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9</th>\n",
       "      <td>1.214815</td>\n",
       "      <td>0.658075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1.240570</td>\n",
       "      <td>0.667777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1</th>\n",
       "      <td>1.266086</td>\n",
       "      <td>0.677748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2</th>\n",
       "      <td>1.290136</td>\n",
       "      <td>0.687428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3</th>\n",
       "      <td>1.316234</td>\n",
       "      <td>0.697613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>1.342375</td>\n",
       "      <td>0.707426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>1.367906</td>\n",
       "      <td>0.716757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6</th>\n",
       "      <td>1.391437</td>\n",
       "      <td>0.726073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7</th>\n",
       "      <td>1.417322</td>\n",
       "      <td>0.735846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8</th>\n",
       "      <td>1.439788</td>\n",
       "      <td>0.744850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.9</th>\n",
       "      <td>1.463237</td>\n",
       "      <td>0.754262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1.486849</td>\n",
       "      <td>0.763480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1</th>\n",
       "      <td>1.510508</td>\n",
       "      <td>0.772844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>1.538466</td>\n",
       "      <td>0.782387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.3</th>\n",
       "      <td>1.564122</td>\n",
       "      <td>0.791647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.4</th>\n",
       "      <td>1.591407</td>\n",
       "      <td>0.801034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.5</th>\n",
       "      <td>1.617378</td>\n",
       "      <td>0.810253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.6</th>\n",
       "      <td>1.644947</td>\n",
       "      <td>0.819422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.7</th>\n",
       "      <td>1.670064</td>\n",
       "      <td>0.828433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.8</th>\n",
       "      <td>1.696084</td>\n",
       "      <td>0.837681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.9</th>\n",
       "      <td>1.724185</td>\n",
       "      <td>0.846870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1.750998</td>\n",
       "      <td>0.856001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type             max      mean\n",
       "Second (s)                    \n",
       "0.1         0.484973  0.484973\n",
       "0.2         0.617330  0.493961\n",
       "0.3         0.691306  0.499424\n",
       "0.4         0.760760  0.511441\n",
       "0.5         0.811654  0.521896\n",
       "0.6         0.855982  0.533225\n",
       "0.7         0.892222  0.543846\n",
       "0.8         0.923317  0.552929\n",
       "0.9         0.954907  0.562222\n",
       "1.0         0.987372  0.571389\n",
       "1.1         1.011652  0.580639\n",
       "1.2         1.037865  0.590949\n",
       "1.3         1.065261  0.601041\n",
       "1.4         1.087906  0.610356\n",
       "1.5         1.115279  0.619841\n",
       "1.6         1.143024  0.629787\n",
       "1.7         1.166811  0.639358\n",
       "1.8         1.193063  0.648796\n",
       "1.9         1.214815  0.658075\n",
       "2.0         1.240570  0.667777\n",
       "2.1         1.266086  0.677748\n",
       "2.2         1.290136  0.687428\n",
       "2.3         1.316234  0.697613\n",
       "2.4         1.342375  0.707426\n",
       "2.5         1.367906  0.716757\n",
       "2.6         1.391437  0.726073\n",
       "2.7         1.417322  0.735846\n",
       "2.8         1.439788  0.744850\n",
       "2.9         1.463237  0.754262\n",
       "3.0         1.486849  0.763480\n",
       "3.1         1.510508  0.772844\n",
       "3.2         1.538466  0.782387\n",
       "3.3         1.564122  0.791647\n",
       "3.4         1.591407  0.801034\n",
       "3.5         1.617378  0.810253\n",
       "3.6         1.644947  0.819422\n",
       "3.7         1.670064  0.828433\n",
       "3.8         1.696084  0.837681\n",
       "3.9         1.724185  0.846870\n",
       "4.0         1.750998  0.856001"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_results = df.groupby(by=['Second (s)', 'type']).mean().unstack()['RMSE Error (m)']\n",
    "exp_results.to_csv(f'../model/{model_name}/{folder_name}/result.csv')\n",
    "exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export JIT Model\n",
    "\n",
    "Integrate partial of data processing into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXPORT_MODEL = True\n",
    "\n",
    "# # # model.load_state_dict(torch.load(\"/home/shaoze/Documents/Boeing/Boeing-Trajectory-Prediction/model/Jul09_20-37-37/model_40000.pt\"))\n",
    "# # if EXPORT_MODEL:\n",
    "# #     model.eval()\n",
    "# #     model.to('cpu')\n",
    "# #     script_module = torch.jit.script(model)\n",
    "# #     os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# #     script_module.save(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# stats = {}\n",
    "# '''\n",
    "# mean: tensor[]\n",
    "# '''\n",
    "\n",
    "# for keys, values in stats_dict.items():\n",
    "#     stats[keys] = torch.tensor(values.to_list()).view(1,1,-1)\n",
    "    \n",
    "# class TFT_EXP(nn.Module):\n",
    "#     def __init__(self, model:EnhancedTFT, stats:dict):\n",
    "#         super(TFT_EXP, self).__init__()\n",
    "#         self.stats = stats\n",
    "#         self.register_buffer('mean', self.stats['mean'])\n",
    "#         self.register_buffer('std', self.stats['std'])\n",
    "#         self.register_buffer('min', self.stats['min'])\n",
    "#         self.register_buffer('max', self.stats['max'])\n",
    "#         self.TFT = model\n",
    "#         self.num_steps = model.num_steps\n",
    "#         self.num_outputs = model.num_outputs # =2\n",
    "\n",
    "#     def forward(self, x, mask: Optional[torch.Tensor]=None):\n",
    "#         single = False\n",
    "#         if len(x.shape) == 2:\n",
    "#             x = x.unsqueeze(0)\n",
    "#             single = True\n",
    "        \n",
    "#         # normalize\n",
    "#         x = (x - self.mean) / self.std\n",
    "#         x = (x - self.min) / (self.max - self.min)\n",
    "#         # residual\n",
    "#         current_pos_input = x[:, -1, :2].clone().unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "#         current_pos_output = x[:, -1, :2].clone().unsqueeze(1).repeat(1, self.num_steps, 1)\n",
    "#         x[:, :, :2] = x[:, :, :2] - current_pos_input\n",
    "        \n",
    "#         # pass through TFT\n",
    "#         outputs, vq_loss, perplexity = self.TFT(x, mask)\n",
    "#         outputs = outputs.detach()\n",
    "        \n",
    "#         # de-residual\n",
    "#         outputs[:, :, :2] = outputs[:, :, :2] + current_pos_output\n",
    "        \n",
    "#         # denormalize\n",
    "#         outputs = outputs * (self.max[:,:,:self.num_outputs] - self.min[:,:,:self.num_outputs]) + self.min[:,:,:self.num_outputs]\n",
    "#         outputs = outputs * self.std[:,:,:self.num_outputs] + self.mean[:,:,:self.num_outputs]\n",
    "        \n",
    "#         if single:\n",
    "#             outputs = outputs.squeeze(0)\n",
    "#         return outputs\n",
    "\n",
    "# tft_exp = TFT_EXP(model, stats)\n",
    "# tft_exp.to('cpu')\n",
    "# tft_exp.eval()\n",
    "# # script_module = torch.jit.script(tft_exp)\n",
    "# # os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# # script_module.save(\"../exported/model_tft_vqvae_cpu_preproc.pt\")\n",
    "\n",
    "# # export to onnx\n",
    "\n",
    "# dummy_input = torch.randn(1, lookback, feature_dim)\n",
    "# print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "# # Export the wrapped model to ONNX format\n",
    "# torch.onnx.export(\n",
    "#     tft_exp,                   # Wrapped model to export\n",
    "#     dummy_input,                     # Model input\n",
    "#     \"../exported/tft_1111.onnx\",              # Output file name\n",
    "#     export_params=True,              # Store the trained parameter weights inside the model file\n",
    "#     opset_version=13,                # Set the ONNX opset version (adjust as needed)\n",
    "#     do_constant_folding=True,        # Whether to execute constant folding for optimization\n",
    "#     input_names=['input'],           # The model's input names\n",
    "#     output_names=['output'],         # The model's output names\n",
    "#     # dynamic_axes={\n",
    "#     #     'input': {0: 'batch_size'},  # Dynamic batch_size and sequence_length\n",
    "#     #     'output': {0: 'batch_size'}  # Dynamic batch_size for the output\n",
    "#     # }\n",
    "# )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime as ort\n",
    "# import numpy as np\n",
    "\n",
    "# # Path to your ONNX model\n",
    "# model_path = \"../exported/tft_1111.onnx\"\n",
    "\n",
    "# # Create an inference session\n",
    "# session = ort.InferenceSession(model_path)\n",
    "\n",
    "# # Get the name of the input node\n",
    "# input_name = session.get_inputs()[0].name\n",
    "\n",
    "# for file in os.listdir(dir):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         df = process_data(dir+file)\n",
    "#     break\n",
    "\n",
    "# df = df[['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "#        'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "#        'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "#        'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "#        'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "#        'closest_station', 'distance_to_closest_station',\n",
    "#        'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "#        'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "#        'GazeDirection_Z', 'AGV_X', 'AGV_Y',\n",
    "#        'looking_at_closest_station']]\n",
    "\n",
    "# start_idx = 100\n",
    "# input = df.iloc[200:200+lookback].astype(np.float32).values\n",
    "\n",
    "# # add batch\n",
    "# input = input[np.newaxis, :, :]\n",
    "# # Run the model\n",
    "# output = session.run(None, {input_name: input.astype(np.float32)})[0]\n",
    "\n",
    "# output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data (for interactive visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# test_ds = MyDataset(lookback=lookback)\n",
    "# all_ds = ds.dataset\n",
    "# test_ds.dataset = all_ds[len(all_ds)//10 :] # load the last 10% of the data\n",
    "# X_list, y_list = test_ds.generate_data(return_list=True, future_steps=future_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# normalize_dict = stats_dict\n",
    "# pred_data = []\n",
    "# truth_data = []\n",
    "# input_data = []\n",
    "# model.eval()\n",
    "# device = 'cpu'\n",
    "# for i, (X, y) in enumerate(zip(X_list, y_list)):\n",
    "#     current_pos_input = X[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "#     current_pos_output = X[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1).to(device)\n",
    "#     X[:, :, :2] = X[:, :, :2] - current_pos_input\n",
    "\n",
    "#     predictions = model(X.float().to(device))[0][:, :future_steps, :2]\n",
    "#     predictions = predictions + current_pos_output\n",
    "#     predictions = predictions.to('cpu')\n",
    "    \n",
    "#     truths = y[:, :future_steps, :2]\n",
    "#     X[:, :, :2] = X[:, :, :2] + current_pos_input\n",
    "#     model_input = X.float().to(device)[:, :lookback, :2]\n",
    "#     trajectory_id = i\n",
    "    \n",
    "#     # reverse normalization\n",
    "#     for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    \n",
    "#     for group_id in range(predictions.shape[0]):\n",
    "#         for time_step in range(predictions.shape[1]):\n",
    "#             pred_x, pred_y = predictions[group_id, time_step]\n",
    "#             pred_data.append([trajectory_id, group_id, time_step, pred_x.item(), pred_y.item()])\n",
    "\n",
    "#             truth_x, truth_y = truths[group_id, time_step]\n",
    "#             truth_data.append([trajectory_id, group_id, time_step, truth_x.item(), truth_y.item()])\n",
    "        \n",
    "#         for time_step in range(lookback):\n",
    "#             input_x, input_y = model_input[group_id, time_step]\n",
    "#             input_data.append([trajectory_id, group_id, time_step, input_x.item(), input_y.item()])\n",
    "            \n",
    "\n",
    "# pred_df = pd.DataFrame(pred_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# truth_df = pd.DataFrame(truth_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# input_df = pd.DataFrame(input_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_remove = [\n",
    "#     \"../data/pred_tra_all.pkl\",\n",
    "#     \"../data/truth_tra_all.pkl\", \n",
    "#     \"../data/input_tra_all.pkl\"\n",
    "# ]\n",
    "\n",
    "# for file_path in files_to_remove:\n",
    "#     if os.path.exists(file_path):\n",
    "#         os.remove(file_path)\n",
    "\n",
    "# truth_df.to_pickle(\"../data/truth_tra_all.pkl\")\n",
    "# pred_df.to_pickle(\"../data/pred_tra_all.pkl\")\n",
    "# input_df.to_pickle(\"../data/input_tra_all.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
