{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cur_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # Gets the current notebook directory\n",
    "src_dir = os.path.join(cur_dir, '../')  # Constructs the path to the 'src' directory\n",
    "# Add the 'src' directory to sys.path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.constant import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.MyDataset import MyDataset, save_dataset, load_dataset\n",
    "# from src.TFT_Flowmatching import TemporalFusionTransformerDiffusion\n",
    "\n",
    "from src.VQVAE import VQVAE\n",
    "from typing import Optional\n",
    "import pickle\n",
    "\n",
    "import torch.utils\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: direct load data from Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_dataset('../data/.cache/train.pkl')\n",
    "test = load_dataset('../data/.cache/test.pkl')\n",
    "stats_dict = pickle.load(open('../data/.cache/stats_dict.pkl', 'rb'))\n",
    "feature_dim = stats_dict['feature_dim']\n",
    "features = stats_dict['features']\n",
    "\n",
    "lookback = 30\n",
    "future_steps = 40\n",
    "resample = False\n",
    "dir = '../data/Phase3/Modified/'\n",
    "ds = MyDataset(lookback=lookback)\n",
    "train_batch_size = 32\n",
    "test_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def process_data(df_dir : str, target_freq : int = 10):\n",
    "    df: pd.DataFrame = pd.read_pickle(df_dir)\n",
    "    df.columns = df.columns.str.strip() \n",
    "    \n",
    "    df = df.rename(columns={'State': 'state'})\n",
    "\n",
    "    states = ['At Station', 'Error', 'Wait', 'Cross', 'Approach Sidewalk',\n",
    "       'Approach Target Station', 'Move Along Sidewalk']\n",
    "\n",
    "    states_ohe = pd.get_dummies(df['state'], prefix='state')\n",
    "    cur_states = df['state'].unique()\n",
    "    for state in states:\n",
    "        if state not in cur_states:\n",
    "            states_ohe['state_'+state] = 0\n",
    "\n",
    "    df = pd.concat([df, states_ohe], axis=1)\n",
    "    df.drop(columns=['state'], inplace=True)\n",
    "    \n",
    "    df.dropna(inplace=True, how='any')\n",
    "    if resample:\n",
    "        f_per_sec = df.groupby('TimestampID').count().mean().mean()\n",
    "        if f_per_sec < target_freq:\n",
    "            raise ValueError('The frequency of the data is lower than the target frequency')\n",
    "        elif int(f_per_sec) == target_freq:\n",
    "            pass\n",
    "        else:\n",
    "            resample_ratio = int(f_per_sec/target_freq)\n",
    "            df = df.iloc[::resample_ratio, :]\n",
    "    # # for origin\n",
    "    for drop_column in ['Confidence', 'Timestamp', 'TimestampID', \n",
    "                          'DatapointID', 'PID', 'SCN', 'U_X', 'U_Y', 'U_Z', \n",
    "                          'AGV_Z', 'User_Z', 'GazeOrigin_Z', 'User_Pitch', 'User_Yaw', 'User_Roll', \n",
    "                          'EyeTarget', \n",
    "                          'start_station_X', 'start_station_Y', 'end_station_X', 'end_station_Y',\n",
    "                          'distance_from_start_station_X',\n",
    "                            'distance_from_start_station_Y', 'distance_from_end_station_X',\n",
    "                            'distance_from_end_station_Y', 'facing_start_station',\n",
    "                            'facing_end_station', \n",
    "                            'rolling_avg', \n",
    "                            'User', 'Type', \n",
    "                            'possible_interaction'\n",
    "                          ]:\n",
    "        df = df.drop(columns=[drop_column], errors='ignore')\n",
    "\n",
    "    target_columns = ['User_X', 'User_Y']\n",
    "    # Reorder columns\n",
    "    new_columns = target_columns + [col for col in df.columns if col not in target_columns]\n",
    "    df = df[new_columns]\n",
    "    \n",
    "    # keep numeric columns\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "for file in os.listdir(dir):\n",
    "    if file.endswith('.pkl'):\n",
    "        df = process_data(dir+file)\n",
    "        ds.read_data(df, agv_col_name=\"scenario\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = process_data(dir+file)\n",
    "# df = df[df['scenario'] == 7]\n",
    "\n",
    "# uer_x, uer_y = df['User_X'].values[10:40], df['User_Y'].values[10:40]\n",
    "\n",
    "# plt.plot(uer_x, uer_y)\n",
    "# # same\n",
    "# plt.title('User Position')\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# # equal aspect ratio\n",
    "# plt.gca().set_aspect('equal', adjustable='box')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(ds.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "columns : Index(['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
      "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
      "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
      "       'intent_to_cross', 'Gazing_station', 'facing_along_sidewalk',\n",
      "       'facing_to_road', 'On_sidewalks', 'On_road', 'closest_station',\n",
      "       'distance_to_closest_station', 'distance_to_closest_station_X',\n",
      "       'distance_to_closest_station_Y', 'looking_at_AGV', 'GazeDirection_X',\n",
      "       'GazeDirection_Y', 'GazeDirection_Z', 'AGV_X', 'AGV_Y',\n",
      "       'looking_at_closest_station', 'data_active', 'scenario',\n",
      "       'state_Approach Sidewalk', 'state_Approach Target Station',\n",
      "       'state_At Station', 'state_Cross', 'state_Error',\n",
      "       'state_Move Along Sidewalk', 'state_Wait'],\n",
      "      dtype='object') \n",
      "feature_dim : 38\n"
     ]
    }
   ],
   "source": [
    "stats_dict = {'mean': 0, 'std': 0, 'min': 0, 'max': 0}\n",
    "stats_dict = ds.normalize_dataset()\n",
    "ds.generate_data(future_steps=future_steps)\n",
    "\n",
    "train:torch.utils.data.DataLoader\n",
    "test:torch.utils.data.DataLoader\n",
    "\n",
    "train, test = ds.split_data(frac=0.9, shuffle=True, train_batch_size=train_batch_size, test_batch_size=test_batch_size)\n",
    "\n",
    "feature_dim = ds.feature_dim\n",
    "stats_dict['feature_dim'] = feature_dim\n",
    "stats_dict['features'] = ds.dataset[0].columns\n",
    "columns = [_ for _ in ds.dataset[0].columns if _ not in ['AGV_name']]\n",
    "print(f\"columns : {df.columns} \\nfeature_dim : {feature_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "       'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "       'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "       'closest_station', 'distance_to_closest_station',\n",
    "       'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "       'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "       'GazeDirection_Z', 'AGV_X', 'AGV_Y', 'looking_at_closest_station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 30, 38]) torch.Size([32, 40, 38])\n",
      "317856 70656\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train):\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "\n",
    "print(len(train) * train_batch_size, len(test) * test_batch_size)\n",
    "\n",
    "# # save it to cache to speed up\n",
    "# save_dataset(train, type='train', file_path='../data/.cache/train.pkl')\n",
    "# save_dataset(test, type='test', file_path='../data/.cache/test.pkl')\n",
    "# pickle.dump(stats_dict, open('../data/.cache/stats_dict.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DiffusionDecoder(nn.Module):\n",
    "#     def __init__(self, action_dim, conditioning_dim, num_diffusion_steps=10,\n",
    "#                  num_action_steps=20, hidden_dim=128, num_layers=2, noise_weight=0.1, num_heads=4, ):\n",
    "#         super().__init__()\n",
    "#         self.action_dim = action_dim\n",
    "#         self.num_diffusion_steps = num_diffusion_steps  # Number of integration steps\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.num_action_steps = num_action_steps\n",
    "#         self.noise_weight = noise_weight\n",
    "\n",
    "#         self.time_embed = SinusoidalTimeEmbedding(hidden_dim)\n",
    "#         self.time_proj = nn.Sequential(\n",
    "#             nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "#             nn.SiLU(),\n",
    "#             nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "#         )\n",
    "\n",
    "#         input_dim = hidden_dim + hidden_dim + num_action_steps * action_dim\n",
    "\n",
    "#         # # Output processing\n",
    "#         # self.output_proj = nn.Sequential(\n",
    "#         #     nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "#         #     nn.LayerNorm(hidden_dim * 2),\n",
    "#         #     nn.SiLU(),\n",
    "#         #     nn.Linear(hidden_dim * 2, num_action_steps * action_dim)\n",
    "#         # )\n",
    "\n",
    "#         # x_encoder\n",
    "#         self.x_encoder = nn.Linear(action_dim, hidden_dim)\n",
    "#         self.x_align = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "\n",
    "#         # x cross attention\n",
    "#         self.cross_attention = nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True)\n",
    "#         self.cross_attention1 = nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True)\n",
    "\n",
    "#         self.ffn = nn.Sequential(\n",
    "#             nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "#         )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#         # Build a deeper network with LayerNorm and residual connections\n",
    "#         self.fc1 = nn.Linear(hidden_dim, 512)\n",
    "#         self.ln1 = nn.LayerNorm(512)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(512, 512)\n",
    "#         self.ln2 = nn.LayerNorm(512)\n",
    "        \n",
    "#         self.fc3 = nn.Linear(512, 512)\n",
    "#         self.ln3 = nn.LayerNorm(512)\n",
    "        \n",
    "#         self.fc_out = nn.Linear(512, action_dim)\n",
    "\n",
    "#         # Final output projection\n",
    "#         self.out = nn.Linear(hidden_dim, action_dim)\n",
    "\n",
    "#         # self.gate = nn.Linear(conditioning_dim, action_dim * num_action_steps)\n",
    "#         # self.fc_direct = nn.Linear(num_action_steps * action_dim, num_action_steps * action_dim)\n",
    "\n",
    "#     def forward(self, conditioning, x_t, t):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             conditioning: Tensor of shape (batch, cond_len, hidden_dim)\n",
    "#             x_t: Tensor of shape (batch, num_action_steps, action_dim)\n",
    "#             t: Tensor of shape (batch,) with time values in [0,1]\n",
    "#         \"\"\"\n",
    "#         x_t = self.x_encoder(x_t)\n",
    "\n",
    "#         # Time embedding\n",
    "#         t_emb = self.time_embed(t)  # [batch, hidden_dim]\n",
    "\n",
    "#         t_emb = t_emb.unsqueeze(1).repeat(1, x_t.size(1), 1)\n",
    "#         # x_t = x_t.view(x_t.size(0), -1)  # Flatten the last two dimensions\n",
    "#         x_with_time = torch.cat([x_t, t_emb], dim=-1)  # [batch, hidden_dim + cond_dim]\n",
    "\n",
    "#         x_with_time = self.x_align(x_with_time)\n",
    "\n",
    "#         conditioning = torch.mean(conditioning, dim=1)  # [batch, hidden_dim]\n",
    "\n",
    "\n",
    "#         conditioning = conditioning.unsqueeze(1).repeat(1, x_with_time.size(1), 1)\n",
    "#         # cross attention with conditioning\n",
    "#         x_with_time, _ = self.cross_attention(x_with_time, conditioning, conditioning)\n",
    "#         x_with_time = self.ffn(x_with_time)\n",
    "#         x_proj, _ = self.cross_attention1(x_with_time, x_with_time, x_with_time)\n",
    "\n",
    "#         # Pass through the network with normalization and residual connections\n",
    "#         x = F.relu(self.ln1(self.fc1(x_proj)))\n",
    "#         residual = x\n",
    "#         x = F.relu(self.ln2(self.fc2(x)) + residual)\n",
    "#         residual = x\n",
    "#         x = F.relu(self.ln3(self.fc3(x)) + residual)\n",
    "#         h = self.fc_out(x)\n",
    "\n",
    "#         # gate = torch.sigmoid(self.gate(conditioning))\n",
    "#         # h = h * gate + self.fc_direct(x_t)\n",
    "        \n",
    "#         h = h.view(h.size(0), self.num_action_steps, self.action_dim)  # Reshape to [batch, num_action_steps, action_dim]\n",
    "        \n",
    "        \n",
    "#         return h  # [batch, num_action_steps, action_dim]\n",
    "\n",
    "#     def decoder_train_step(self, conditioning, y_batch, device):\n",
    "#         \"\"\"\n",
    "#         Performs one training step for the flow-matching decoder.\n",
    "        \n",
    "#         Args:\n",
    "#             conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "#             y_batch: Ground truth trajectory (batch, num_action_steps, action_dim)\n",
    "#             device: torch.device\n",
    "        \n",
    "#         Returns:\n",
    "#             loss: The MSE loss between predicted and target velocity\n",
    "#         \"\"\"\n",
    "#         batch_size = y_batch.size(0)\n",
    "#         # Sample t uniformly from [0,1]\n",
    "#         t = torch.rand(batch_size, device=device)  # [batch]\n",
    "\n",
    "\n",
    "#         t = t.unsqueeze(1).unsqueeze(2)  # [batch, 1, 1]\n",
    "        \n",
    "#         # Sample noise\n",
    "#         noise = torch.randn_like(y_batch) * self.noise_weight\n",
    "        \n",
    "#         # Compute x_t and v_target\n",
    "#         x_t, v_target = compute_flow_target(noise, y_batch, t)\n",
    "        \n",
    "#         # Predict velocity\n",
    "#         v_pred = self.forward(conditioning, x_t, t.squeeze(2).squeeze(1))  # t: [batch]\n",
    "        \n",
    "#         # MSE loss\n",
    "#         loss = F.mse_loss(v_pred, v_target, reduce=False)\n",
    "#         loss = loss.mean(dim=[1, 2])  # Sum over action steps and dimensions\n",
    "#         return loss\n",
    "    \n",
    "#     def influence(self, conditioning, device):\n",
    "#         \"\"\"\n",
    "#         Runs the flow-matching integration process and returns a list of intermediate trajectories.\n",
    "        \n",
    "#         Args:\n",
    "#             conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "#             device: torch.device\n",
    "        \n",
    "#         Returns:\n",
    "#             intermediates: A list of tensors, each of shape (batch, num_action_steps, action_dim),\n",
    "#                            representing the trajectory at each integration step\n",
    "#         \"\"\"\n",
    "#         batch_size = conditioning.size(0)\n",
    "#         x = torch.randn(batch_size, self.num_action_steps, self.action_dim, device=device) * self.noise_weight\n",
    "#         intermediates = []\n",
    "#         dt = -1.0 / self.num_diffusion_steps  # Negative dt for backward integration\n",
    "#         for i in range(self.num_diffusion_steps):\n",
    "#             t = 1.0 + i * dt  # t decreases from 1.0 to almost 0\n",
    "#             t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.float)\n",
    "#             v_pred = self.forward(conditioning, x, t_tensor)\n",
    "#             x = x + v_pred * dt  # Since dt < 0, moves x towards data\n",
    "#             intermediates.append(x.clone())\n",
    "#         return intermediates\n",
    "\n",
    "\n",
    "# # decoder = DiffusionDecoder(action_dim=2, conditioning_dim=feature_dim, num_diffusion_steps=10, num_action_steps=20, hidden_dim=128, num_layers=2, noise_weight=0.1, num_heads=4)\n",
    "# # y_batch = torch.randn(16, 20, 2).to(device)\n",
    "# # condition = torch.randn(16, 1, 128).to(device)\n",
    "# # decoder.to(device)\n",
    "\n",
    "# # decoder.decoder_train_step(condition, y_batch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiTBlock(nn.Module):\n",
    "    \"\"\"Diffusion Transformer Block with self-attention and cross-attention\"\"\"\n",
    "    def __init__(self, hidden_dim, num_heads, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        # Pre-normalization layers\n",
    "        self.norm1 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm2 = nn.LayerNorm(hidden_dim)\n",
    "        self.norm3 = nn.LayerNorm(hidden_dim)\n",
    "        \n",
    "        # Self-attention\n",
    "        self.self_attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout_rate)\n",
    "        # Cross-attention\n",
    "        self.cross_attn = nn.MultiheadAttention(hidden_dim, num_heads, dropout=dropout_rate)\n",
    "        \n",
    "        # Feed-forward network\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 4),\n",
    "            nn.GELU(),  # Using GELU activation for better performance\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_dim * 4, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x, conditioning):\n",
    "        # Self-attention with residual connection\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        self_attn_out, _ = self.self_attn(x, x, x)\n",
    "        x = residual + self.dropout(self_attn_out)\n",
    "        \n",
    "        # Cross-attention with residual connection\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        cross_attn_out, _ = self.cross_attn(conditioning, x, x)\n",
    "        x = residual + self.dropout(cross_attn_out)\n",
    "        \n",
    "        # Feed-forward with residual connection\n",
    "        residual = x\n",
    "        x = self.norm3(x)\n",
    "        ffn_out = self.ffn(x)\n",
    "        x = residual + self.dropout(ffn_out)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "# SPDX-FileCopyrightText: Copyright (c) 2025 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n",
    "# SPDX-License-Identifier: Apache-2.0\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "from typing import Optional\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from diffusers import ConfigMixin, ModelMixin\n",
    "from diffusers.configuration_utils import register_to_config\n",
    "from diffusers.models.attention import Attention, FeedForward\n",
    "from diffusers.models.embeddings import (\n",
    "    SinusoidalPositionalEmbedding,\n",
    "    TimestepEmbedding,\n",
    "    Timesteps,\n",
    ")\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class TimestepEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, compute_dtype=torch.float32):\n",
    "        super().__init__()\n",
    "        self.time_proj = Timesteps(num_channels=256, flip_sin_to_cos=True, downscale_freq_shift=1)\n",
    "        self.timestep_embedder = TimestepEmbedding(in_channels=256, time_embed_dim=embedding_dim)\n",
    "\n",
    "    def forward(self, timesteps):\n",
    "        dtype = next(self.parameters()).dtype\n",
    "        timesteps_proj = self.time_proj(timesteps).to(dtype)\n",
    "        timesteps_emb = self.timestep_embedder(timesteps_proj)  # (N, D)\n",
    "        return timesteps_emb\n",
    "\n",
    "\n",
    "class AdaLayerNorm(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dim: int,\n",
    "        norm_elementwise_affine: bool = False,\n",
    "        norm_eps: float = 1e-5,\n",
    "        chunk_dim: int = 0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.chunk_dim = chunk_dim\n",
    "        output_dim = embedding_dim * 2\n",
    "        self.silu = nn.SiLU()\n",
    "        self.linear = nn.Linear(embedding_dim, output_dim)\n",
    "        self.norm = nn.LayerNorm(output_dim // 2, norm_eps, norm_elementwise_affine)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: torch.Tensor,\n",
    "        temb: Optional[torch.Tensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        temb = self.linear(self.silu(temb))\n",
    "        scale, shift = temb.chunk(2, dim=1)\n",
    "        x = self.norm(x) * (1 + scale[:, None]) + shift[:, None]\n",
    "        return x\n",
    "\n",
    "\n",
    "class BasicTransformerBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        dim: int,\n",
    "        num_attention_heads: int,\n",
    "        attention_head_dim: int,\n",
    "        dropout=0.0,\n",
    "        cross_attention_dim: Optional[int] = None,\n",
    "        activation_fn: str = \"geglu\",\n",
    "        attention_bias: bool = False,\n",
    "        upcast_attention: bool = False,\n",
    "        norm_elementwise_affine: bool = True,\n",
    "        norm_type: str = \"layer_norm\",  # 'layer_norm', 'ada_norm', 'ada_norm_zero', 'ada_norm_single', 'ada_norm_continuous', 'layer_norm_i2vgen'\n",
    "        norm_eps: float = 1e-5,\n",
    "        final_dropout: bool = False,\n",
    "        attention_type: str = \"default\",\n",
    "        positional_embeddings: Optional[str] = None,\n",
    "        num_positional_embeddings: Optional[int] = None,\n",
    "        ff_inner_dim: Optional[int] = None,\n",
    "        ff_bias: bool = True,\n",
    "        attention_out_bias: bool = True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.num_attention_heads = num_attention_heads\n",
    "        self.attention_head_dim = attention_head_dim\n",
    "        self.dropout = dropout\n",
    "        self.cross_attention_dim = cross_attention_dim\n",
    "        self.activation_fn = activation_fn\n",
    "        self.attention_bias = attention_bias\n",
    "        self.norm_elementwise_affine = norm_elementwise_affine\n",
    "        self.positional_embeddings = positional_embeddings\n",
    "        self.num_positional_embeddings = num_positional_embeddings\n",
    "        self.norm_type = norm_type\n",
    "\n",
    "        if positional_embeddings and (num_positional_embeddings is None):\n",
    "            raise ValueError(\n",
    "                \"If `positional_embedding` type is defined, `num_positition_embeddings` must also be defined.\"\n",
    "            )\n",
    "\n",
    "        if positional_embeddings == \"sinusoidal\":\n",
    "            self.pos_embed = SinusoidalPositionalEmbedding(\n",
    "                dim, max_seq_length=num_positional_embeddings\n",
    "            )\n",
    "        else:\n",
    "            self.pos_embed = None\n",
    "\n",
    "        # Define 3 blocks. Each block has its own normalization layer.\n",
    "        # 1. Self-Attn\n",
    "        if norm_type == \"ada_norm\":\n",
    "            self.norm1 = AdaLayerNorm(dim)\n",
    "        else:\n",
    "            self.norm1 = nn.LayerNorm(dim, elementwise_affine=norm_elementwise_affine, eps=norm_eps)\n",
    "\n",
    "        self.attn1 = Attention(\n",
    "            query_dim=dim,\n",
    "            heads=num_attention_heads,\n",
    "            dim_head=attention_head_dim,\n",
    "            dropout=dropout,\n",
    "            bias=attention_bias,\n",
    "            cross_attention_dim=None,\n",
    "            upcast_attention=upcast_attention,\n",
    "            out_bias=attention_out_bias,\n",
    "        )\n",
    "\n",
    "        # 3. Feed-forward\n",
    "        self.norm3 = nn.LayerNorm(dim, norm_eps, norm_elementwise_affine)\n",
    "        self.ff = FeedForward(\n",
    "            dim,\n",
    "            dropout=dropout,\n",
    "            activation_fn=activation_fn,\n",
    "            final_dropout=final_dropout,\n",
    "            inner_dim=ff_inner_dim,\n",
    "            bias=ff_bias,\n",
    "        )\n",
    "        if final_dropout:\n",
    "            self.final_dropout = nn.Dropout(dropout)\n",
    "        else:\n",
    "            self.final_dropout = None\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        encoder_hidden_states: Optional[torch.Tensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        temb: Optional[torch.LongTensor] = None,\n",
    "    ) -> torch.Tensor:\n",
    "        # 0. Self-Attention\n",
    "        if self.norm_type == \"ada_norm\":\n",
    "            norm_hidden_states = self.norm1(hidden_states, temb)\n",
    "        else:\n",
    "            norm_hidden_states = self.norm1(hidden_states)\n",
    "\n",
    "        if self.pos_embed is not None:\n",
    "            norm_hidden_states = self.pos_embed(norm_hidden_states)\n",
    "\n",
    "        attn_output = self.attn1(\n",
    "            norm_hidden_states,\n",
    "            encoder_hidden_states=encoder_hidden_states,\n",
    "            attention_mask=attention_mask,\n",
    "            # encoder_attention_mask=encoder_attention_mask,\n",
    "        )\n",
    "        if self.final_dropout:\n",
    "            attn_output = self.final_dropout(attn_output)\n",
    "\n",
    "        hidden_states = attn_output + hidden_states\n",
    "        if hidden_states.ndim == 4:\n",
    "            hidden_states = hidden_states.squeeze(1)\n",
    "\n",
    "        # 4. Feed-forward\n",
    "        norm_hidden_states = self.norm3(hidden_states)\n",
    "        ff_output = self.ff(norm_hidden_states)\n",
    "\n",
    "        hidden_states = ff_output + hidden_states\n",
    "        if hidden_states.ndim == 4:\n",
    "            hidden_states = hidden_states.squeeze(1)\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "class DiT(ModelMixin, ConfigMixin):\n",
    "    _supports_gradient_checkpointing = True\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_attention_heads: int = 8,\n",
    "        attention_head_dim: int = 64,\n",
    "        output_dim: int = 26,\n",
    "        num_layers: int = 12,\n",
    "        dropout: float = 0.1,\n",
    "        attention_bias: bool = True,\n",
    "        activation_fn: str = \"gelu-approximate\",\n",
    "        num_embeds_ada_norm: Optional[int] = 1000,\n",
    "        upcast_attention: bool = False,\n",
    "        norm_type: str = \"ada_norm\",\n",
    "        norm_elementwise_affine: bool = False,\n",
    "        norm_eps: float = 1e-5,\n",
    "        max_num_positional_embeddings: int = 512,\n",
    "        compute_dtype=torch.float32,\n",
    "        final_dropout: bool = True,\n",
    "        positional_embeddings: Optional[str] = \"sinusoidal\",\n",
    "        interleave_self_attention=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention_head_dim = attention_head_dim\n",
    "        self.inner_dim = num_attention_heads * attention_head_dim\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "        # Timestep encoder\n",
    "        self.timestep_encoder = TimestepEncoder(\n",
    "            embedding_dim=self.inner_dim, compute_dtype=compute_dtype\n",
    "        )\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                BasicTransformerBlock(\n",
    "                    self.inner_dim,\n",
    "                    num_attention_heads,\n",
    "                    attention_head_dim,\n",
    "                    dropout=dropout,\n",
    "                    activation_fn=activation_fn,\n",
    "                    attention_bias=attention_bias,\n",
    "                    upcast_attention=upcast_attention,\n",
    "                    norm_type=norm_type,\n",
    "                    norm_elementwise_affine=norm_elementwise_affine,\n",
    "                    norm_eps=norm_eps,\n",
    "                    positional_embeddings=positional_embeddings,\n",
    "                    num_positional_embeddings=max_num_positional_embeddings,\n",
    "                    final_dropout=final_dropout,\n",
    "                )\n",
    "                for _ in range(num_layers)\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        # Output blocks\n",
    "        self.norm_out = nn.LayerNorm(self.inner_dim, elementwise_affine=False, eps=1e-6)\n",
    "        self.proj_out_1 = nn.Linear(self.inner_dim, 2 * self.inner_dim)\n",
    "        self.proj_out_2 = nn.Linear(self.inner_dim, self.output_dim)\n",
    "        print(\n",
    "            \"Total number of DiT parameters: \",\n",
    "            sum(p.numel() for p in self.parameters() if p.requires_grad),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,  # Shape: (B, T, D)\n",
    "        encoder_hidden_states: torch.Tensor,  # Shape: (B, S, D)\n",
    "        timestep: Optional[torch.LongTensor] = None,\n",
    "        encoder_attention_mask: Optional[torch.Tensor] = None,\n",
    "        return_all_hidden_states: bool = False,\n",
    "    ):\n",
    "        # Encode timesteps\n",
    "        temb = self.timestep_encoder(timestep)\n",
    "\n",
    "        # Process through transformer blocks - single pass through the blocks\n",
    "        hidden_states = hidden_states.contiguous()\n",
    "        encoder_hidden_states = encoder_hidden_states.contiguous()\n",
    "\n",
    "        all_hidden_states = [hidden_states]\n",
    "\n",
    "        # Process through transformer blocks\n",
    "        for idx, block in enumerate(self.transformer_blocks):\n",
    "            if idx % 2 == 1 and self.config.interleave_self_attention:\n",
    "                hidden_states = block(\n",
    "                    hidden_states,\n",
    "                    attention_mask=None,\n",
    "                    encoder_hidden_states=None,\n",
    "                    encoder_attention_mask=None,\n",
    "                    temb=temb,\n",
    "                )\n",
    "            else:\n",
    "                hidden_states = block(\n",
    "                    hidden_states,\n",
    "                    attention_mask=None,\n",
    "                    encoder_hidden_states=encoder_hidden_states,\n",
    "                    encoder_attention_mask=None,\n",
    "                    temb=temb,\n",
    "                )\n",
    "            all_hidden_states.append(hidden_states)\n",
    "\n",
    "        # Output processing\n",
    "        conditioning = temb\n",
    "        shift, scale = self.proj_out_1(F.silu(conditioning)).chunk(2, dim=1)\n",
    "        hidden_states = self.norm_out(hidden_states) * (1 + scale[:, None]) + shift[:, None]\n",
    "        if return_all_hidden_states:\n",
    "            return self.proj_out_2(hidden_states), all_hidden_states\n",
    "        else:\n",
    "            return self.proj_out_2(hidden_states)\n",
    "\n",
    "\n",
    "class SelfAttentionTransformer(ModelMixin, ConfigMixin):\n",
    "    _supports_gradient_checkpointing = True\n",
    "\n",
    "    @register_to_config\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_attention_heads: int = 8,\n",
    "        attention_head_dim: int = 64,\n",
    "        output_dim: int = 26,\n",
    "        num_layers: int = 12,\n",
    "        dropout: float = 0.1,\n",
    "        attention_bias: bool = True,\n",
    "        activation_fn: str = \"gelu-approximate\",\n",
    "        num_embeds_ada_norm: Optional[int] = 1000,\n",
    "        upcast_attention: bool = False,\n",
    "        max_num_positional_embeddings: int = 512,\n",
    "        compute_dtype=torch.float32,\n",
    "        final_dropout: bool = True,\n",
    "        positional_embeddings: Optional[str] = \"sinusoidal\",\n",
    "        interleave_self_attention=False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.attention_head_dim = attention_head_dim\n",
    "        self.inner_dim = self.config.num_attention_heads * self.config.attention_head_dim\n",
    "        self.gradient_checkpointing = False\n",
    "\n",
    "        self.transformer_blocks = nn.ModuleList(\n",
    "            [\n",
    "                BasicTransformerBlock(\n",
    "                    self.inner_dim,\n",
    "                    self.config.num_attention_heads,\n",
    "                    self.config.attention_head_dim,\n",
    "                    dropout=self.config.dropout,\n",
    "                    activation_fn=self.config.activation_fn,\n",
    "                    attention_bias=self.config.attention_bias,\n",
    "                    upcast_attention=self.config.upcast_attention,\n",
    "                    positional_embeddings=positional_embeddings,\n",
    "                    num_positional_embeddings=self.config.max_num_positional_embeddings,\n",
    "                    final_dropout=final_dropout,\n",
    "                )\n",
    "                for _ in range(self.config.num_layers)\n",
    "            ]\n",
    "        )\n",
    "        print(\n",
    "            \"Total number of SelfAttentionTransformer parameters: \",\n",
    "            sum(p.numel() for p in self.parameters() if p.requires_grad),\n",
    "        )\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        hidden_states: torch.Tensor,  # Shape: (B, T, D)\n",
    "    ):\n",
    "        # Process through transformer blocks - single pass through the blocks\n",
    "        hidden_states = hidden_states.contiguous()\n",
    "\n",
    "        # Process through transformer blocks\n",
    "        for idx, block in enumerate(self.transformer_blocks):\n",
    "            hidden_states = block(hidden_states)\n",
    "\n",
    "        return hidden_states\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DiffusionDecoder(nn.Module):\n",
    "    def __init__(self, action_dim, conditioning_dim, num_diffusion_steps=10,\n",
    "                 num_action_steps=20, hidden_dim=128, num_layers=2, noise_weight=0.5, \n",
    "                 num_heads=4, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dim\n",
    "        self.num_diffusion_steps = num_diffusion_steps\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_action_steps = num_action_steps\n",
    "        self.noise_weight = noise_weight\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_embed = SinusoidalTimeEmbedding(hidden_dim)\n",
    "        self.time_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        )\n",
    "        \n",
    "        # Input encoders\n",
    "        self.x_encoder = nn.Linear(action_dim, hidden_dim)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_action_steps, hidden_dim))\n",
    "        self.conditioning_align = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        \n",
    "        # DiT blocks - stack of transformer blocks\n",
    "        self.dit_blocks = nn.ModuleList([\n",
    "            DiTBlock(hidden_dim, num_heads, dropout_rate) \n",
    "            for _ in range(num_layers)\n",
    "        ])\n",
    "        \n",
    "        # Final projection layers with residual connections\n",
    "        self.final_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.proj_1 = nn.Linear(hidden_dim, hidden_dim * 2)\n",
    "        self.proj_2 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, action_dim)\n",
    "        \n",
    "        # Dropout for regularization\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, conditioning, x_t, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, hidden_dim)\n",
    "            x_t: Tensor of shape (batch, num_action_steps, action_dim)\n",
    "            t: Tensor of shape (batch,) with time values in [0,1]\n",
    "        \"\"\"\n",
    "        batch_size = x_t.size(0)\n",
    "        \n",
    "        # Encode input trajectory\n",
    "        x_encoded = self.x_encoder(x_t)\n",
    "        \n",
    "        # Combine encoded trajectory with time embedding\n",
    "        x = x_encoded + self.pos_embed\n",
    "        \n",
    "        # Process conditioning - average pooling as a simple approach\n",
    "        if conditioning.size(1) > 1:\n",
    "            cond_pooled = torch.mean(conditioning, dim=1, keepdim=True)  # [batch, 1, hidden_dim]\n",
    "        else:\n",
    "            cond_pooled = conditioning\n",
    "        \n",
    "\n",
    "        # Time embedding\n",
    "        t_emb = self.time_embed(t)  # [batch, hidden_dim]\n",
    "        t_emb = self.time_proj(t_emb)  # Project time embedding\n",
    "        \n",
    "        # Broadcast time embedding to match sequence length\n",
    "        t_emb = t_emb.unsqueeze(1).repeat(1, x_t.size(1), 1)\n",
    "        \n",
    "        # Repeat conditioning for each timestep in the sequence\n",
    "        cond_expanded = cond_pooled.repeat(1, x_t.size(1), 1)\n",
    "        cond_expanded = torch.cat([cond_expanded, t_emb], dim=-1)\n",
    "        cond_expanded = self.conditioning_align(cond_expanded)\n",
    "\n",
    "        \n",
    "        # Process through DiT blocks\n",
    "        x = x.permute(1,0,2)\n",
    "        cond_expanded = cond_expanded.permute(1,0,2)\n",
    "\n",
    "        for block in self.dit_blocks:\n",
    "            x = block(x, cond_expanded)\n",
    "        \n",
    "        x = x.permute(1,0,2)\n",
    "        # Final processing\n",
    "        x = self.final_norm(x)\n",
    "        x = F.gelu(self.proj_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.gelu(self.proj_2(x))\n",
    "        x = self.dropout(x)\n",
    "        output = self.output(x)\n",
    "        \n",
    "        return output  # [batch, num_action_steps, action_dim]\n",
    "\n",
    "    def decoder_train_step(self, conditioning, y_batch, device):\n",
    "        \"\"\"\n",
    "        Performs one training step for the flow-matching decoder.\n",
    "        \n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "            y_batch: Ground truth trajectory (batch, num_action_steps, action_dim)\n",
    "            device: torch.device\n",
    "        \n",
    "        Returns:\n",
    "            loss: The MSE loss between predicted and target velocity\n",
    "        \"\"\"\n",
    "        batch_size = y_batch.size(0)\n",
    "        # Sample t uniformly from [0,1]\n",
    "        t = torch.rand(batch_size, device=device)\n",
    "        \n",
    "        # Sample noise\n",
    "        noise = torch.randn_like(y_batch) * self.noise_weight\n",
    "        \n",
    "        # Compute x_t and v_target\n",
    "        x_t, v_target = compute_flow_target(noise, y_batch, t.unsqueeze(1).unsqueeze(2))\n",
    "        \n",
    "        # Predict velocity\n",
    "        v_pred = self.forward(conditioning, x_t, t)\n",
    "        \n",
    "        # MSE loss\n",
    "        loss = F.mse_loss(v_pred, v_target, reduction='none')\n",
    "        loss = loss.mean(dim=[1, 2])  # Average over action steps and dimensions\n",
    "        return loss\n",
    "    \n",
    "    def influence(self, conditioning, device):\n",
    "        \"\"\"\n",
    "        Runs the flow-matching integration process and returns a list of intermediate trajectories.\n",
    "        \n",
    "        Args:\n",
    "            conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "            device: torch.device\n",
    "        \n",
    "        Returns:\n",
    "            intermediates: A list of tensors, each of shape (batch, num_action_steps, action_dim)\n",
    "        \"\"\"\n",
    "        batch_size = conditioning.size(0)\n",
    "        x = torch.randn(batch_size, self.num_action_steps, self.action_dim, device=device) * self.noise_weight\n",
    "        intermediates = []\n",
    "        \n",
    "        # Integration step size (negative for backward integration)\n",
    "        dt = -1.0 / self.num_diffusion_steps\n",
    "        \n",
    "        # Run the diffusion process\n",
    "        for i in range(self.num_diffusion_steps):\n",
    "            t = 1.0 + i * dt  # t decreases from 1.0 to almost 0\n",
    "            t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.float)\n",
    "            v_pred = self.forward(conditioning, x, t_tensor)\n",
    "            x = x + v_pred * dt  # Since dt < 0, moves x towards data\n",
    "            intermediates.append(x.clone())\n",
    "            \n",
    "        return intermediates\n",
    "    \n",
    "# decoder = DiffusionDecoder(action_dim=2, conditioning_dim=feature_dim, num_diffusion_steps=10, num_action_steps=20, hidden_dim=128, num_layers=2, noise_weight=0.1, num_heads=4)\n",
    "# y_batch = torch.randn(16, 20, 2).to(device)\n",
    "# condition = torch.randn(16, 1, 128).to(device)\n",
    "# x_t = torch.randn(16, 20, 2).to(device)\n",
    "# x = torch.randn(16, 20, 2).to(device)\n",
    "# decoder.to(device)\n",
    "\n",
    "# decoder.decoder_train_step(condition, y_batch, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from src.VQVAE import VQVAE\n",
    "import math\n",
    "\n",
    "###############################################\n",
    "# Original Blocks (with minor efficiency tweaks)\n",
    "###############################################\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=3, dropout_rate=0.1):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)]\n",
    "        )\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "        self.gate = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_input = x\n",
    "        for layer, norm in zip(self.layers, self.norms):\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "            x = norm(x)\n",
    "        gate = torch.sigmoid(self.gate(x))\n",
    "        x2 = self.fc2(x)\n",
    "        return self.fc3(x_input) + gate * x2\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout_rate)\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size * 4, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask: Optional[torch.Tensor] = None):\n",
    "        # x: (seq_len, batch, hidden_size)\n",
    "        x2 = x\n",
    "        x = self.norm1(x)\n",
    "        x, _ = self.attention(x, x, x, key_padding_mask=mask)\n",
    "        x = x + x2\n",
    "        x2 = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = x + x2\n",
    "        return x\n",
    "\n",
    "###############################################\n",
    "# Diffusion–based Decoder\n",
    "###############################################\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Computes a sinusoidal embedding for a scalar timestep.\n",
    "    \"\"\"\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(SinusoidalTimeEmbedding, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        # t: Tensor of shape (batch,) or (batch, 1)\n",
    "        if len(t.shape) == 1:\n",
    "            t = t.unsqueeze(1)  # (batch, 1)\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        # Compute constant\n",
    "        emb_factor = math.log(10000) / (half_dim - 1)\n",
    "        # Create a tensor of shape (half_dim,)\n",
    "        dims = torch.arange(half_dim, device=t.device, dtype=t.dtype)\n",
    "        # (batch, half_dim)\n",
    "        emb = t * torch.exp(-dims * emb_factor)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        # If embedding_dim is odd, pad an extra zero.\n",
    "        if self.embedding_dim % 2 == 1:\n",
    "            emb = F.pad(emb, (0, 1))\n",
    "        return emb  # (batch, embedding_dim)\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "\n",
    "def compute_flow_target(noise, y_batch, t):\n",
    "    \"\"\"\n",
    "    Compute the intermediate sample x_t and target velocity for flow-matching.\n",
    "    \n",
    "    Args:\n",
    "        noise: Tensor of shape (batch, num_action_steps, action_dim), noise sample\n",
    "        y_batch: Tensor of shape (batch, num_action_steps, action_dim), ground truth actions\n",
    "        t: Tensor of shape (batch, 1, 1), time steps\n",
    "    \n",
    "    Returns:\n",
    "        x_t: Intermediate sample at time t\n",
    "        v_target: Target velocity\n",
    "    \"\"\"\n",
    "    t = t.view(-1, 1, 1)  # Ensure t is [batch, 1, 1]\n",
    "    x_t = t * noise + (1 - t) * y_batch\n",
    "\n",
    "    v_target = noise - y_batch\n",
    "    return x_t, v_target\n",
    "\n",
    "# class DiffusionDecoder(nn.Module):\n",
    "#     def __init__(self, action_dim, conditioning_dim, num_diffusion_steps=10,\n",
    "#                  num_action_steps=20, hidden_dim=128, num_layers=2, noise_weight=0.1, num_heads=4, ):\n",
    "#         super().__init__()\n",
    "#         self.action_dim = action_dim\n",
    "#         self.num_diffusion_steps = num_diffusion_steps  # Number of integration steps\n",
    "#         self.hidden_dim = hidden_dim\n",
    "#         self.num_action_steps = num_action_steps\n",
    "#         self.noise_weight = noise_weight\n",
    "\n",
    "#         self.time_embed = SinusoidalTimeEmbedding(hidden_dim)\n",
    "\n",
    "#         input_dim = hidden_dim + hidden_dim + num_action_steps * action_dim\n",
    "\n",
    "#         self.DiT = DiTBlock(hidden_dim=hidden_dim, num_heads=4)\n",
    "#         self.input_proj = nn.Linear(hidden_dim + num_action_steps * action_dim, hidden_dim)\n",
    "\n",
    "\n",
    "#         # # Output processing\n",
    "#         # self.output_proj = nn.Sequential(\n",
    "#         #     nn.Linear(hidden_dim * 4, hidden_dim * 2),\n",
    "#         #     nn.LayerNorm(hidden_dim * 2),\n",
    "#         #     nn.SiLU(),\n",
    "#         #     nn.Linear(hidden_dim * 2, num_action_steps * action_dim)\n",
    "#         # )\n",
    "\n",
    "#         # x_encoder\n",
    "#         self.x_encoder = nn.Linear(action_dim, hidden_dim)\n",
    "\n",
    "#         # Build a deeper network with LayerNorm and residual connections\n",
    "#         self.fc1 = nn.Linear(hidden_dim, 512)\n",
    "#         self.ln1 = nn.LayerNorm(512)\n",
    "        \n",
    "#         self.fc2 = nn.Linear(512, 512)\n",
    "#         self.ln2 = nn.LayerNorm(512)\n",
    "        \n",
    "#         self.fc3 = nn.Linear(512, 512)\n",
    "#         self.ln3 = nn.LayerNorm(512)\n",
    "        \n",
    "#         self.fc_out = nn.Linear(512, num_action_steps * action_dim)\n",
    "\n",
    "#         # self.gate = nn.Linear(conditioning_dim, action_dim * num_action_steps)\n",
    "#         # self.fc_direct = nn.Linear(num_action_steps * action_dim, num_action_steps * action_dim)\n",
    "\n",
    "#     def forward(self, conditioning, x_t, t):\n",
    "#         \"\"\"\n",
    "#         Args:\n",
    "#             conditioning: Tensor of shape (batch, cond_len, hidden_dim)\n",
    "#             x_t: Tensor of shape (batch, num_action_steps, action_dim)\n",
    "#             t: Tensor of shape (batch,) with time values in [0,1]\n",
    "#         \"\"\"\n",
    "#         # Time embedding\n",
    "#         t_emb = self.time_embed(t)  # [batch, hidden_dim]\n",
    "\n",
    "#         x_t = x_t.view(x_t.size(0), -1)  # Flatten the last two dimensions\n",
    "#         x_with_time = torch.cat([x_t, t_emb], dim=-1)  # [batch, hidden_dim + cond_dim]\n",
    "#         x_with_time = self.input_proj(x_with_time)\n",
    "\n",
    "#         conditioning = torch.mean(conditioning, dim=1)  # [batch, hidden_dim]\n",
    "        \n",
    "#         # x_proj = torch.cat([x_with_time, conditioning], dim=-1)  # [batch, hidden_dim + cond_dim]\n",
    "        \n",
    "#         x_with_time = x_with_time.unsqueeze(1).permute(1, 0, 2)\n",
    "#         conditioning = conditioning.unsqueeze(1).permute(1, 0, 2)\n",
    "\n",
    "#         x_proj = self.DiT(x_with_time, conditioning).permute(1, 0, 2).squeeze(1)\n",
    "#         # Pass through the network with normalization and residual connections\n",
    "#         x = F.relu(self.ln1(self.fc1(x_proj)))\n",
    "#         residual = x\n",
    "#         x = F.relu(self.ln2(self.fc2(x)) + residual)\n",
    "#         residual = x\n",
    "#         x = F.relu(self.ln3(self.fc3(x)) + residual)\n",
    "#         h = self.fc_out(x)\n",
    "\n",
    "#         # gate = torch.sigmoid(self.gate(conditioning))\n",
    "#         # h = h * gate + self.fc_direct(x_t)\n",
    "        \n",
    "#         h = h.view(h.size(0), self.num_action_steps, self.action_dim)  # Reshape to [batch, num_action_steps, action_dim]\n",
    "        \n",
    "        \n",
    "#         return h  # [batch, num_action_steps, action_dim]\n",
    "\n",
    "#     def decoder_train_step(self, conditioning, y_batch, device):\n",
    "#         \"\"\"\n",
    "#         Performs one training step for the flow-matching decoder.\n",
    "        \n",
    "#         Args:\n",
    "#             conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "#             y_batch: Ground truth trajectory (batch, num_action_steps, action_dim)\n",
    "#             device: torch.device\n",
    "        \n",
    "#         Returns:\n",
    "#             loss: The MSE loss between predicted and target velocity\n",
    "#         \"\"\"\n",
    "#         batch_size = y_batch.size(0)\n",
    "#         # Sample t uniformly from [0,1]\n",
    "#         t = torch.rand(batch_size, device=device)  # [batch]\n",
    "#         t = t.unsqueeze(1).unsqueeze(2)  # [batch, 1, 1]\n",
    "        \n",
    "#         # Sample noise\n",
    "#         noise = torch.randn_like(y_batch) * self.noise_weight\n",
    "        \n",
    "#         # Compute x_t and v_target\n",
    "#         x_t, v_target = compute_flow_target(noise, y_batch, t)\n",
    "        \n",
    "#         # Predict velocity\n",
    "#         v_pred = self.forward(conditioning, x_t, t.squeeze(2).squeeze(1))  # t: [batch]\n",
    "        \n",
    "#         # MSE loss\n",
    "#         loss = F.mse_loss(v_pred, v_target, reduce=False)\n",
    "#         loss = loss.mean(dim=[1, 2])  # Sum over action steps and dimensions\n",
    "#         return loss\n",
    "    \n",
    "#     def influence(self, conditioning, device):\n",
    "#         \"\"\"\n",
    "#         Runs the flow-matching integration process and returns a list of intermediate trajectories.\n",
    "        \n",
    "#         Args:\n",
    "#             conditioning: Tensor of shape (batch, cond_len, conditioning_dim)\n",
    "#             device: torch.device\n",
    "        \n",
    "#         Returns:\n",
    "#             intermediates: A list of tensors, each of shape (batch, num_action_steps, action_dim),\n",
    "#                            representing the trajectory at each integration step\n",
    "#         \"\"\"\n",
    "#         batch_size = conditioning.size(0)\n",
    "#         x = torch.randn(batch_size, self.num_action_steps, self.action_dim, device=device) * self.noise_weight\n",
    "#         intermediates = []\n",
    "#         dt = -1.0 / self.num_diffusion_steps  # Negative dt for backward integration\n",
    "#         for i in range(self.num_diffusion_steps):\n",
    "#             t = 1.0 + i * dt  # t decreases from 1.0 to almost 0\n",
    "#             t_tensor = torch.full((batch_size,), t, device=device, dtype=torch.float)\n",
    "#             v_pred = self.forward(conditioning, x, t_tensor)\n",
    "#             x = x + v_pred * dt  # Since dt < 0, moves x towards data\n",
    "#             intermediates.append(x.clone())\n",
    "#         return intermediates\n",
    "    \n",
    "###############################################\n",
    "# Modified Temporal Fusion Transformer with Diffusion Decoder\n",
    "###############################################\n",
    "\n",
    "class TemporalFusionTransformerDiffusion(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_outputs, num_steps, his_steps = 30, \n",
    "                 num_attention_heads=8, diffusion_steps=10, vqvae: VQVAE = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_features (int): Number of input features.\n",
    "            num_hidden (int): Hidden dimension size.\n",
    "            num_outputs (int): Dimensionality of each output (e.g. action dimension).\n",
    "            num_steps (int): Desired output sequence length (e.g. number of action steps).\n",
    "            num_attention_heads (int): Number of heads for the transformer blocks.\n",
    "            diffusion_steps (int): Number of diffusion (denoising) steps.\n",
    "        \"\"\"\n",
    "        super(TemporalFusionTransformerDiffusion, self).__init__()\n",
    "        if vqvae is None:\n",
    "            self.vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "        else:\n",
    "            self.vqvae = vqvae\n",
    "\n",
    "        self.num_hidden = num_hidden\n",
    "        num_features = num_features + self.vqvae.encoder.fc2.out_features\n",
    "        self.encoder_grn = GatedResidualNetwork(num_features, num_hidden, num_hidden)\n",
    "        self.transformer_block = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        self.transformer_block2 = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        \n",
    "        self.his_steps = his_steps\n",
    "        # To condition the diffusion process we project the transformer output.\n",
    "        self.condition_proj = nn.Linear(num_hidden, num_hidden)\n",
    "        # Diffusion decoder: we set action_dim=num_outputs and produce a sequence of length num_steps.\n",
    "        self.diffusion_decoder = DiffusionDecoder(\n",
    "            action_dim=num_outputs,\n",
    "            conditioning_dim=num_hidden,\n",
    "            num_diffusion_steps=diffusion_steps,\n",
    "            num_action_steps=num_steps,\n",
    "            num_heads=num_attention_heads,  \n",
    "            hidden_dim=num_hidden, \n",
    "            num_layers=2,  # you can adjust as needed\n",
    "            noise_weight=0.5  # you can adjust as needed\n",
    "        )\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "        self.his_steps = his_steps\n",
    "\n",
    "        self.stationary_branch = nn.Sequential(\n",
    "            nn.Linear(his_steps * num_outputs, num_hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden, num_hidden // 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_hidden // 2, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, y_batch=None , mask: Optional[torch.Tensor] = None, influence=False, return_all=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, seq_len, num_features).\n",
    "            mask: Optional attention mask for the transformer blocks.\n",
    "            \n",
    "        Returns:\n",
    "            actions: Tensor of shape (batch, num_steps, num_outputs)\n",
    "        \"\"\"\n",
    "        # If given a 2D input, add a batch dimension.\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # Stationary branch\n",
    "        if self.his_steps != x.shape[1]:\n",
    "            print(f\"his_steps : {self.his_steps} != x.shape[1] : {x.shape[1]}\")\n",
    "            print(f\"Reset his_steps to x.shape[1]\")\n",
    "            self.his_steps = x.shape[1]\n",
    "            self.stationary_branch = nn.Sequential(\n",
    "                nn.Linear(self.his_steps * self.num_outputs, self.num_hidden),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.num_hidden, self.num_hidden // 2),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(self.num_hidden // 2, 1)\n",
    "            ).to(x.device)\n",
    "        # hist traj\n",
    "        hist_traj = x[:, -self.his_steps:, :self.num_outputs].reshape(batch_size, -1)\n",
    "        stationary = self.stationary_branch(hist_traj)\n",
    "        stationary = torch.sigmoid(stationary)\n",
    "\n",
    "\n",
    "\n",
    "        # VQ-VAE\n",
    "        x_recon, vq_loss, perplexity, embedding = self.vqvae(x)\n",
    "        x = torch.cat((x, embedding), dim=-1)\n",
    "        \n",
    "        # Encoder GRN.\n",
    "        x = self.encoder_grn(x)  # (batch, seq_len, num_hidden)\n",
    "        \n",
    "        # Transformer expects (seq_len, batch, hidden_size).\n",
    "        x = x.permute(1, 0, 2)\n",
    "        x = self.transformer_block(x, mask=mask)\n",
    "        x = self.transformer_block2(x, mask=mask)\n",
    "        x = x.permute(1, 0, 2)  # back to (batch, seq_len, num_hidden)\n",
    "        \n",
    "        # Use a summary of the encoder output as conditioning.\n",
    "        # Here we use the last time–step (you might also try an average or more complex pooling).\n",
    "\n",
    "        # attention\n",
    "        # attention_weights = torch.softmax(torch.mean(x, dim=-1), dim=1).unsqueeze(-1)\n",
    "        # pooled_output = torch.sum(attention_weights * x, dim=1, keepdim=True)\n",
    "\n",
    "        # conditioning = self.condition_proj(pooled_output)  # (batch, 1, num_hidden)\n",
    "        conditioning = x[:, -1:, :] #self.condition_proj()  # (batch, 1, num_hidden)\n",
    "        # conditioning = self.condition_proj(x[:, :, :])  # (batch, 1, num_hidden)\n",
    "\n",
    "        # flow matching during training\n",
    "        self.device = next(self.parameters()).device\n",
    "        \n",
    "        if influence:\n",
    "            stationary = torch.where(stationary > 0.5, 1.0, 0.0).to(self.device)\n",
    "            # match size\n",
    "            stationary = stationary.unsqueeze(1).expand(-1, self.num_steps, self.num_outputs)\n",
    "            \n",
    "            if return_all:\n",
    "                return [traj * stationary for traj in self.diffusion_decoder.influence(conditioning, self.device)]\n",
    "            return self.diffusion_decoder.influence(conditioning, self.device)[-1] * stationary\n",
    "        else:\n",
    "            if self.training:\n",
    "                max_displace = torch.max(y_batch, dim=1).values - torch.min(y_batch, dim=1).values\n",
    "                max_displace = torch.linalg.norm(max_displace, dim=1)\n",
    "                stationary_gt = torch.where(max_displace > 5e-4, 1.0, 0.0).to(self.device)\n",
    "                stationary_loss = F.binary_cross_entropy(stationary.squeeze(1), stationary_gt)\n",
    "                diff_loss = self.diffusion_decoder.decoder_train_step(conditioning, y_batch, self.device)\n",
    "                diff_loss = diff_loss * stationary_gt.detach()\n",
    "                diff_loss = diff_loss.mean()\n",
    "                return diff_loss, vq_loss, stationary_loss\n",
    "            \n",
    "\n",
    "    def influence(self, x):\n",
    "        User_trajectory = self.forward(x, influence=True)\n",
    "        return User_trajectory\n",
    "\n",
    "\n",
    "# class DecayLoss(nn.Module):\n",
    "#     def __init__(self, num_steps, baseline_loss_fn=nn.L1Loss()):\n",
    "#         super(DecayLoss, self).__init__()\n",
    "#         # Weight decreases as we move further into the future\n",
    "#         self.weights = torch.linspace(1.0, 1.0, num_steps)\n",
    "#         self.baseline_loss_fn = baseline_loss_fn\n",
    "        \n",
    "\n",
    "#     def forward(self, predictions, targets):\n",
    "#         loss = 0\n",
    "#         for i in range(predictions.shape[1]):\n",
    "#             loss += self.weights[i] * self.baseline_loss_fn(predictions[:, i], targets[:, i])\n",
    "#         return loss\n",
    "    \n",
    "    \n",
    "# baseline_loss_fn = nn.L1Loss() #nn.MSELoss()\n",
    "# loss_fn = DecayLoss(future_steps, baseline_loss_fn=baseline_loss_fn)\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using {device}\")\n",
    "\n",
    "# vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "# model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps, diffusion_steps=10, vqvae=vqvae)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# model.to(device)\n",
    "\n",
    "# X_batch, y_batch = next(iter(train))\n",
    "# X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "# model(X_batch, y_batch[:, :future_steps, :2], influence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalFusionTransformerDiffusion(\n",
       "  (vqvae): VQVAE(\n",
       "    (encoder): VQVAEEncoder(\n",
       "      (fc1): Linear(in_features=38, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "    (quantizer): VectorQuantizer(\n",
       "      (embedding): Embedding(128, 128)\n",
       "    )\n",
       "    (decoder): VQVAEDecoder(\n",
       "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=38, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_grn): GatedResidualNetwork(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=166, out_features=128, bias=True)\n",
       "      (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-2): 3 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=166, out_features=128, bias=True)\n",
       "    (gate): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (transformer_block): TransformerBlock(\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (transformer_block2): TransformerBlock(\n",
       "    (attention): MultiheadAttention(\n",
       "      (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (feed_forward): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Dropout(p=0.1, inplace=False)\n",
       "      (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (condition_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (diffusion_decoder): DiffusionDecoder(\n",
       "    (time_embed): SinusoidalTimeEmbedding()\n",
       "    (time_proj): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (x_encoder): Linear(in_features=2, out_features=128, bias=True)\n",
       "    (conditioning_align): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (dit_blocks): ModuleList(\n",
       "      (0-1): 2 x DiTBlock(\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (cross_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (ffn): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.1, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (final_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (proj_1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (proj_2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (output): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (stationary_branch): Sequential(\n",
       "    (0): Linear(in_features=60, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecayLoss(nn.Module):\n",
    "    def __init__(self, num_steps, baseline_loss_fn=nn.L1Loss()):\n",
    "        super(DecayLoss, self).__init__()\n",
    "        # Weight decreases as we move further into the future\n",
    "        self.weights = torch.linspace(1.0, 1.0, num_steps)\n",
    "        self.baseline_loss_fn = baseline_loss_fn\n",
    "        \n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        loss = 0\n",
    "        for i in range(predictions.shape[1]):\n",
    "            loss += self.weights[i] * self.baseline_loss_fn(predictions[:, i], targets[:, i])\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "baseline_loss_fn = nn.L1Loss() #nn.MSELoss()\n",
    "loss_fn = DecayLoss(future_steps, baseline_loss_fn=baseline_loss_fn)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps, diffusion_steps=10, vqvae=vqvae)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer with early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at ../model/TFT_Flowmatching/Mar27_21-39-07\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86536cc090b54d7d906be712a7a93c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 500, Loss: 0.658962, VQ Loss: 0.003620, Stationary Loss: 0.063084, Diff Loss: 0.024503, learning rate: 5.00e-05\n",
      "Epoch 1, Step 1000, Loss: 0.585122, VQ Loss: 0.001829, Stationary Loss: 0.056169, Diff Loss: 0.021601, learning rate: 5.00e-05\n",
      "Epoch 1, Step 1500, Loss: 0.533677, VQ Loss: 0.001306, Stationary Loss: 0.051326, Diff Loss: 0.019106, learning rate: 5.00e-05\n",
      "Epoch 1, Step 2000, Loss: 0.497146, VQ Loss: 0.001009, Stationary Loss: 0.047904, Diff Loss: 0.017094, learning rate: 5.00e-05\n",
      "Steps 2000: test RMSE 1.0760, moving average RMSE 1.0760, learning rate 5.00e-05\n",
      "Epoch 1, Step 2500, Loss: 0.442254, VQ Loss: 0.000908, Stationary Loss: 0.042520, Diff Loss: 0.016144, learning rate: 5.00e-05\n",
      "Epoch 1, Step 3000, Loss: 0.415090, VQ Loss: 0.000797, Stationary Loss: 0.039929, Diff Loss: 0.014999, learning rate: 5.00e-05\n",
      "Epoch 1, Step 3500, Loss: 0.385231, VQ Loss: 0.000751, Stationary Loss: 0.037188, Diff Loss: 0.012598, learning rate: 5.00e-05\n",
      "Epoch 1, Step 4000, Loss: 0.383977, VQ Loss: 0.000688, Stationary Loss: 0.037233, Diff Loss: 0.010964, learning rate: 5.00e-05\n",
      "Steps 4000: test RMSE 0.8874, moving average RMSE 0.9628, learning rate 5.00e-05\n",
      "Epoch 1, Step 4500, Loss: 0.364596, VQ Loss: 0.000611, Stationary Loss: 0.035300, Diff Loss: 0.010984, learning rate: 5.00e-05\n",
      "Epoch 1, Step 5000, Loss: 0.352619, VQ Loss: 0.000589, Stationary Loss: 0.034204, Diff Loss: 0.009995, learning rate: 5.00e-05\n",
      "Epoch 1, Step 5500, Loss: 0.358641, VQ Loss: 0.000593, Stationary Loss: 0.034812, Diff Loss: 0.009924, learning rate: 5.00e-05\n",
      "Epoch 1, Step 6000, Loss: 0.339692, VQ Loss: 0.000543, Stationary Loss: 0.032879, Diff Loss: 0.010361, learning rate: 5.00e-05\n",
      "Steps 6000: test RMSE 0.7831, moving average RMSE 0.8550, learning rate 5.00e-05\n",
      "Epoch 1, Step 6500, Loss: 0.361451, VQ Loss: 0.000537, Stationary Loss: 0.035130, Diff Loss: 0.009611, learning rate: 5.00e-05\n",
      "Epoch 1, Step 7000, Loss: 0.346850, VQ Loss: 0.000518, Stationary Loss: 0.033751, Diff Loss: 0.008820, learning rate: 5.00e-05\n",
      "Epoch 1, Step 7500, Loss: 0.341101, VQ Loss: 0.000492, Stationary Loss: 0.033192, Diff Loss: 0.008689, learning rate: 5.00e-05\n",
      "Epoch 1, Step 8000, Loss: 0.335641, VQ Loss: 0.000493, Stationary Loss: 0.032603, Diff Loss: 0.009123, learning rate: 5.00e-05\n",
      "Steps 8000: test RMSE 0.8583, moving average RMSE 0.8570, learning rate 5.00e-05\n",
      "Epoch 1, Step 8500, Loss: 0.337054, VQ Loss: 0.000490, Stationary Loss: 0.032776, Diff Loss: 0.008807, learning rate: 5.00e-05\n",
      "Epoch 1, Step 9000, Loss: 0.339962, VQ Loss: 0.000480, Stationary Loss: 0.033057, Diff Loss: 0.008908, learning rate: 5.00e-05\n",
      "Epoch 1, Step 9500, Loss: 0.377535, VQ Loss: 0.000440, Stationary Loss: 0.036897, Diff Loss: 0.008128, learning rate: 5.00e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c181537a62e43538587d749f0f4d372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 67, Loss: 0.348520, VQ Loss: 0.000503, Stationary Loss: 0.033909, Diff Loss: 0.008926, learning rate: 5.00e-05\n",
      "Model saved at ../model/TFT_Flowmatching/Mar27_21-39-07/model_10000.pt\n",
      "Steps 10000: test RMSE 0.7968, moving average RMSE 0.8209, learning rate 5.00e-05\n",
      "Epoch 2, Step 567, Loss: 0.340603, VQ Loss: 0.000425, Stationary Loss: 0.033168, Diff Loss: 0.008502, learning rate: 5.00e-05\n",
      "Epoch 2, Step 1067, Loss: 0.343496, VQ Loss: 0.000439, Stationary Loss: 0.033547, Diff Loss: 0.007590, learning rate: 5.00e-05\n",
      "Epoch 2, Step 1567, Loss: 0.323302, VQ Loss: 0.000405, Stationary Loss: 0.031561, Diff Loss: 0.007290, learning rate: 5.00e-05\n",
      "Epoch 2, Step 2067, Loss: 0.345832, VQ Loss: 0.000419, Stationary Loss: 0.033796, Diff Loss: 0.007450, learning rate: 5.00e-05\n",
      "Steps 12000: test RMSE 0.7280, moving average RMSE 0.7652, learning rate 5.00e-05\n",
      "Epoch 2, Step 2567, Loss: 0.355344, VQ Loss: 0.000397, Stationary Loss: 0.034767, Diff Loss: 0.007281, learning rate: 1.00e-05\n",
      "Epoch 2, Step 3067, Loss: 0.345467, VQ Loss: 0.000295, Stationary Loss: 0.033742, Diff Loss: 0.007757, learning rate: 1.00e-05\n",
      "Epoch 2, Step 3567, Loss: 0.321158, VQ Loss: 0.000298, Stationary Loss: 0.031414, Diff Loss: 0.006719, learning rate: 1.00e-05\n",
      "Epoch 2, Step 4067, Loss: 0.326974, VQ Loss: 0.000290, Stationary Loss: 0.032013, Diff Loss: 0.006555, learning rate: 1.00e-05\n",
      "Steps 14000: test RMSE 0.6964, moving average RMSE 0.7239, learning rate 1.00e-05\n",
      "Epoch 2, Step 4567, Loss: 0.352862, VQ Loss: 0.000291, Stationary Loss: 0.034611, Diff Loss: 0.006461, learning rate: 1.00e-05\n",
      "Epoch 2, Step 5067, Loss: 0.334154, VQ Loss: 0.000281, Stationary Loss: 0.032762, Diff Loss: 0.006255, learning rate: 1.00e-05\n",
      "Epoch 2, Step 5567, Loss: 0.336129, VQ Loss: 0.000286, Stationary Loss: 0.032990, Diff Loss: 0.005946, learning rate: 2.00e-06\n",
      "Epoch 2, Step 6067, Loss: 0.336301, VQ Loss: 0.000271, Stationary Loss: 0.032977, Diff Loss: 0.006258, learning rate: 2.00e-06\n",
      "Steps 16000: test RMSE 0.6926, moving average RMSE 0.7051, learning rate 2.00e-06\n",
      "Epoch 2, Step 6567, Loss: 0.327624, VQ Loss: 0.000273, Stationary Loss: 0.032024, Diff Loss: 0.007112, learning rate: 2.00e-06\n",
      "Epoch 2, Step 7067, Loss: 0.335703, VQ Loss: 0.000268, Stationary Loss: 0.032895, Diff Loss: 0.006483, learning rate: 2.00e-06\n",
      "Epoch 2, Step 7567, Loss: 0.328170, VQ Loss: 0.000258, Stationary Loss: 0.032094, Diff Loss: 0.006976, learning rate: 2.00e-06\n",
      "Epoch 2, Step 8067, Loss: 0.335540, VQ Loss: 0.000265, Stationary Loss: 0.032846, Diff Loss: 0.006820, learning rate: 2.00e-06\n",
      "Steps 18000: test RMSE 0.6884, moving average RMSE 0.6951, learning rate 2.00e-06\n",
      "Epoch 2, Step 8567, Loss: 0.332579, VQ Loss: 0.000267, Stationary Loss: 0.032573, Diff Loss: 0.006585, learning rate: 2.00e-06\n",
      "Epoch 2, Step 9067, Loss: 0.325582, VQ Loss: 0.000260, Stationary Loss: 0.031869, Diff Loss: 0.006632, learning rate: 2.00e-06\n",
      "Epoch 2, Step 9567, Loss: 0.334237, VQ Loss: 0.000260, Stationary Loss: 0.032754, Diff Loss: 0.006434, learning rate: 2.00e-06\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78bd74ea98804a71a38234945ee39c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 134, Loss: 0.354670, VQ Loss: 0.000264, Stationary Loss: 0.034802, Diff Loss: 0.006384, learning rate: 2.00e-06\n",
      "Model saved at ../model/TFT_Flowmatching/Mar27_21-39-07/model_20000.pt\n",
      "Steps 20000: test RMSE 0.6847, moving average RMSE 0.6888, learning rate 2.00e-06\n",
      "Epoch 3, Step 634, Loss: 0.363963, VQ Loss: 0.000262, Stationary Loss: 0.035720, Diff Loss: 0.006498, learning rate: 2.00e-06\n",
      "Epoch 3, Step 1134, Loss: 0.312098, VQ Loss: 0.000262, Stationary Loss: 0.030611, Diff Loss: 0.005729, learning rate: 2.00e-06\n",
      "Epoch 3, Step 1634, Loss: 0.332104, VQ Loss: 0.000254, Stationary Loss: 0.032472, Diff Loss: 0.007129, learning rate: 2.00e-06\n",
      "Epoch 3, Step 2134, Loss: 0.335454, VQ Loss: 0.000264, Stationary Loss: 0.032820, Diff Loss: 0.006995, learning rate: 2.00e-06\n",
      "Steps 22000: test RMSE 0.6904, moving average RMSE 0.6898, learning rate 2.00e-06\n",
      "Epoch 3, Step 2634, Loss: 0.319064, VQ Loss: 0.000256, Stationary Loss: 0.031236, Diff Loss: 0.006450, learning rate: 2.00e-06\n",
      "Epoch 3, Step 3134, Loss: 0.322384, VQ Loss: 0.000258, Stationary Loss: 0.031540, Diff Loss: 0.006727, learning rate: 4.00e-07\n",
      "Epoch 3, Step 3634, Loss: 0.321482, VQ Loss: 0.000259, Stationary Loss: 0.031448, Diff Loss: 0.006744, learning rate: 4.00e-07\n",
      "Epoch 3, Step 4134, Loss: 0.334432, VQ Loss: 0.000253, Stationary Loss: 0.032767, Diff Loss: 0.006505, learning rate: 4.00e-07\n",
      "Steps 24000: test RMSE 0.6838, moving average RMSE 0.6862, learning rate 4.00e-07\n",
      "Epoch 3, Step 4634, Loss: 0.331512, VQ Loss: 0.000259, Stationary Loss: 0.032490, Diff Loss: 0.006350, learning rate: 4.00e-07\n",
      "Epoch 3, Step 5134, Loss: 0.325742, VQ Loss: 0.000251, Stationary Loss: 0.031844, Diff Loss: 0.007048, learning rate: 4.00e-07\n",
      "Epoch 3, Step 5634, Loss: 0.327914, VQ Loss: 0.000246, Stationary Loss: 0.032063, Diff Loss: 0.007039, learning rate: 4.00e-07\n",
      "Epoch 3, Step 6134, Loss: 0.344783, VQ Loss: 0.000260, Stationary Loss: 0.033817, Diff Loss: 0.006353, learning rate: 8.00e-08\n",
      "Steps 26000: test RMSE 0.6817, moving average RMSE 0.6835, learning rate 8.00e-08\n",
      "Epoch 3, Step 6634, Loss: 0.334571, VQ Loss: 0.000252, Stationary Loss: 0.032832, Diff Loss: 0.006003, learning rate: 8.00e-08\n",
      "Epoch 3, Step 7134, Loss: 0.326189, VQ Loss: 0.000252, Stationary Loss: 0.031990, Diff Loss: 0.006037, learning rate: 8.00e-08\n",
      "Epoch 3, Step 7634, Loss: 0.317459, VQ Loss: 0.000256, Stationary Loss: 0.031086, Diff Loss: 0.006342, learning rate: 8.00e-08\n",
      "Epoch 3, Step 8134, Loss: 0.335064, VQ Loss: 0.000256, Stationary Loss: 0.032830, Diff Loss: 0.006511, learning rate: 8.00e-08\n",
      "Steps 28000: test RMSE 0.6842, moving average RMSE 0.6839, learning rate 8.00e-08\n",
      "Epoch 3, Step 8634, Loss: 0.332422, VQ Loss: 0.000248, Stationary Loss: 0.032572, Diff Loss: 0.006453, learning rate: 8.00e-08\n",
      "Epoch 3, Step 9134, Loss: 0.332541, VQ Loss: 0.000251, Stationary Loss: 0.032602, Diff Loss: 0.006273, learning rate: 1.60e-08\n",
      "Epoch 3, Step 9634, Loss: 0.329502, VQ Loss: 0.000260, Stationary Loss: 0.032286, Diff Loss: 0.006384, learning rate: 1.60e-08\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "942ae6dcf4164de5997a579568abbaa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9933 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 201, Loss: 0.326117, VQ Loss: 0.000256, Stationary Loss: 0.031933, Diff Loss: 0.006532, learning rate: 1.60e-08\n",
      "Model saved at ../model/TFT_Flowmatching/Mar27_21-39-07/model_30000.pt\n",
      "Steps 30000: test RMSE 0.6828, moving average RMSE 0.6832, learning rate 1.60e-08\n",
      "Epoch 4, Step 701, Loss: 0.326379, VQ Loss: 0.000244, Stationary Loss: 0.031906, Diff Loss: 0.007079, learning rate: 1.60e-08\n",
      "Epoch 4, Step 1201, Loss: 0.324350, VQ Loss: 0.000253, Stationary Loss: 0.031771, Diff Loss: 0.006382, learning rate: 1.60e-08\n",
      "Epoch 4, Step 1701, Loss: 0.327834, VQ Loss: 0.000252, Stationary Loss: 0.032118, Diff Loss: 0.006403, learning rate: 1.60e-08\n",
      "Epoch 4, Step 2201, Loss: 0.328117, VQ Loss: 0.000256, Stationary Loss: 0.032133, Diff Loss: 0.006535, learning rate: 1.60e-08\n",
      "Steps 32000: test RMSE 0.6830, moving average RMSE 0.6831, learning rate 1.60e-08\n",
      "Epoch 4, Step 2701, Loss: 0.332811, VQ Loss: 0.000257, Stationary Loss: 0.032613, Diff Loss: 0.006421, learning rate: 1.60e-08\n",
      "Epoch 4, Step 3201, Loss: 0.326584, VQ Loss: 0.000252, Stationary Loss: 0.031982, Diff Loss: 0.006517, learning rate: 1.60e-08\n",
      "Epoch 4, Step 3701, Loss: 0.329588, VQ Loss: 0.000259, Stationary Loss: 0.032216, Diff Loss: 0.007167, learning rate: 1.60e-08\n",
      "Epoch 4, Step 4201, Loss: 0.320336, VQ Loss: 0.000257, Stationary Loss: 0.031307, Diff Loss: 0.007010, learning rate: 1.60e-08\n",
      "Steps 34000: test RMSE 0.6806, moving average RMSE 0.6816, learning rate 1.60e-08\n",
      "Epoch 4, Step 4701, Loss: 0.326593, VQ Loss: 0.000250, Stationary Loss: 0.032007, Diff Loss: 0.006277, learning rate: 1.60e-08\n",
      "Epoch 4, Step 5201, Loss: 0.335375, VQ Loss: 0.000249, Stationary Loss: 0.032869, Diff Loss: 0.006435, learning rate: 1.60e-08\n",
      "Epoch 4, Step 5701, Loss: 0.323001, VQ Loss: 0.000259, Stationary Loss: 0.031654, Diff Loss: 0.006203, learning rate: 1.60e-08\n",
      "Epoch 4, Step 6201, Loss: 0.326605, VQ Loss: 0.000258, Stationary Loss: 0.031976, Diff Loss: 0.006590, learning rate: 1.60e-08\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[89], line 111\u001b[0m\n\u001b[1;32m    104\u001b[0m y_test_batch[:, :, :\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m y_test_batch[:, :, :\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m current_pos_output\n\u001b[1;32m    106\u001b[0m \u001b[38;5;66;03m# # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\u001b[39;00m\n\u001b[1;32m    107\u001b[0m \u001b[38;5;66;03m# y_test_batch = y_test_batch[:, ::2, :2]\u001b[39;00m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;66;03m# X_test_batch = X_test_batch[:, ::2, :]\u001b[39;00m\n\u001b[0;32m--> 111\u001b[0m y_pred_test \u001b[38;5;241m=\u001b[39m model(X_test_batch, influence\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    112\u001b[0m loss_test \u001b[38;5;241m=\u001b[39m loss_fn(y_pred_test[:, :future_steps, :\u001b[38;5;241m2\u001b[39m], y_test_batch[:, :future_steps, :\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    113\u001b[0m test_rmse \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msqrt(loss_test)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[87], line 377\u001b[0m, in \u001b[0;36mTemporalFusionTransformerDiffusion.forward\u001b[0;34m(self, x, y_batch, mask, influence, return_all)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_all:\n\u001b[1;32m    376\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m [traj \u001b[38;5;241m*\u001b[39m stationary \u001b[38;5;28;01mfor\u001b[39;00m traj \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion_decoder\u001b[38;5;241m.\u001b[39minfluence(conditioning, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)]\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdiffusion_decoder\u001b[38;5;241m.\u001b[39minfluence(conditioning, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m*\u001b[39m stationary\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n",
      "Cell \u001b[0;32mIn[86], line 191\u001b[0m, in \u001b[0;36mDiffusionDecoder.influence\u001b[0;34m(self, conditioning, device)\u001b[0m\n\u001b[1;32m    189\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m dt  \u001b[38;5;66;03m# t decreases from 1.0 to almost 0\u001b[39;00m\n\u001b[1;32m    190\u001b[0m t_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfull((batch_size,), t, device\u001b[38;5;241m=\u001b[39mdevice, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat)\n\u001b[0;32m--> 191\u001b[0m v_pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(conditioning, x, t_tensor)\n\u001b[1;32m    192\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m v_pred \u001b[38;5;241m*\u001b[39m dt  \u001b[38;5;66;03m# Since dt < 0, moves x towards data\u001b[39;00m\n\u001b[1;32m    193\u001b[0m intermediates\u001b[38;5;241m.\u001b[39mappend(x\u001b[38;5;241m.\u001b[39mclone())\n",
      "Cell \u001b[0;32mIn[86], line 126\u001b[0m, in \u001b[0;36mDiffusionDecoder.forward\u001b[0;34m(self, conditioning, x_t, t)\u001b[0m\n\u001b[1;32m    123\u001b[0m cond_expanded \u001b[38;5;241m=\u001b[39m cond_expanded\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m block \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdit_blocks:\n\u001b[0;32m--> 126\u001b[0m     x \u001b[38;5;241m=\u001b[39m block(x, cond_expanded)\n\u001b[1;32m    128\u001b[0m x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    129\u001b[0m \u001b[38;5;66;03m# Final processing\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[0;32mIn[86], line 41\u001b[0m, in \u001b[0;36mDiTBlock.forward\u001b[0;34m(self, x, conditioning)\u001b[0m\n\u001b[1;32m     39\u001b[0m residual \u001b[38;5;241m=\u001b[39m x\n\u001b[1;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm3(x)\n\u001b[0;32m---> 41\u001b[0m ffn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mffn(x)\n\u001b[1;32m     42\u001b[0m x \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(ffn_out)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_epochs = 50\n",
    "eval_step = 2000\n",
    "save_every = 10000\n",
    "patience = 8  # Number of evaluations to wait for improvement\n",
    "cooldown = 4  # Evaluations to wait after an improvement before counting non-improvements\n",
    "smooth_factor = 0.6  # Smoothing factor for moving average\n",
    "lambda_flow = 1e-3  # Weight for flow matching loss\n",
    "print_every = 500\n",
    "\n",
    "# Setup\n",
    "train_all = len(train)\n",
    "model_name = \"TFT_Flowmatching\"\n",
    "from collections import defaultdict\n",
    "loss_all = defaultdict(list)\n",
    "best_test_rmse = float('inf')\n",
    "early_stopping_counter = 0\n",
    "cooldown_counter = cooldown\n",
    "\n",
    "now = datetime.now()\n",
    "folder_name = now.strftime(\"%b%d_%H-%M-%S\")\n",
    "print(f\"Saving model at ../model/{model_name}/{folder_name}\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=min(len(train) * n_epochs, 100000), eta_min=1e-8)\n",
    "# Define scheduler: ReduceLROnPlateau\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',        # 'min' because we want to minimize loss\n",
    "    factor=0.2,        # Reduce LR by factor of 0.2 (i.e., lr / 5)\n",
    "    patience=3000,     # Number of steps with no significant improvement before reducing LR\n",
    "    threshold=5e-4,    # Minimum change in loss to qualify as \"significant\"\n",
    "    min_lr=1e-8,       # Minimum LR to stop at\n",
    "    verbose=True       # Prints a message when LR is reduced\n",
    ")\n",
    "\n",
    "\n",
    "# Initialize moving average\n",
    "moving_avg_test_rmse = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, (X_batch, y_batch) in tqdm(enumerate(train), total=train_all):\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        y_batch = y_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_batch[:, :, :2] = X_batch[:, :, :2] - current_pos_input\n",
    "        y_batch[:, :, :2] = y_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "        # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "        # y_batch = y_batch[:, ::2, :2]\n",
    "        # X_batch = X_batch[:, ::2, :]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # y_pred, vq_loss, perplexity = model(X_batch, y_batch=y_batch)\n",
    "        # loss = loss_fn(y_pred[:, :future_steps, :2], y_batch[:, :future_steps, :2])\n",
    "        diff_loss, vq_loss, stationary_loss = model(X_batch, y_batch[:, :future_steps, :2])\n",
    "\n",
    "\n",
    "        loss_all['diff_loss'].append(diff_loss.item())\n",
    "        loss_all['vq_loss'].append(vq_loss.item() * 10)\n",
    "        loss_all['stationary_loss'].append(0.1 * stationary_loss.item())\n",
    "        loss_all['loss'].append(diff_loss.item() + vq_loss.item() * 10 + stationary_loss.item())\n",
    "        # add vq_loss\n",
    "        loss = diff_loss  + 10 * vq_loss + 0.1 * stationary_loss\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss.item())\n",
    "\n",
    "        if (epoch * train_all + step + 1) % print_every == 0:\n",
    "            loss_item = sum(loss_all['loss'][-100:]) / 100\n",
    "            vq_loss_item = sum(loss_all['vq_loss'][-100:]) / 100\n",
    "            diff_loss_item = sum(loss_all['diff_loss'][-100:]) / 100\n",
    "            stationary_loss_item = sum(loss_all['stationary_loss'][-100:]) / 100\n",
    "            print(f\"Epoch {epoch+1}, Step {step+1}, Loss: {loss_item:.6f}, VQ Loss: {vq_loss_item:.6f}, Stationary Loss: {stationary_loss_item:.6f}, Diff Loss: {diff_loss_item:.6f}, learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # Save model\n",
    "        if (epoch * train_all + step + 1) % save_every == 0:\n",
    "            os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "            save_path = f\"../model/{model_name}/{folder_name}/model_{epoch * train_all + step + 1}.pt\"\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at {save_path}\")\n",
    "\n",
    "        # Validation and early stopping\n",
    "        if (epoch * train_all + step + 1) % eval_step == 0:\n",
    "            model.eval()\n",
    "            test_rmse_all = []\n",
    "            with torch.no_grad():\n",
    "                for X_test_batch, y_test_batch in test:\n",
    "                    X_test_batch = X_test_batch.float().to(device)\n",
    "                    y_test_batch = y_test_batch.float().to(device)\n",
    "                    \n",
    "                    current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "                    current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "                    X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "                    y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "                    # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "                    # y_test_batch = y_test_batch[:, ::2, :2]\n",
    "                    # X_test_batch = X_test_batch[:, ::2, :]\n",
    "                    \n",
    "\n",
    "                    y_pred_test = model(X_test_batch, influence=True)\n",
    "                    loss_test = loss_fn(y_pred_test[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "                    test_rmse = torch.sqrt(loss_test)\n",
    "                    if not torch.isnan(test_rmse):\n",
    "                        test_rmse_all.append(test_rmse.item())\n",
    "            \n",
    "            current_rmse = sum(test_rmse_all) / len(test_rmse_all)\n",
    "            if moving_avg_test_rmse is None:\n",
    "                moving_avg_test_rmse = current_rmse\n",
    "            else:\n",
    "                moving_avg_test_rmse = smooth_factor * current_rmse + (1 - smooth_factor) * moving_avg_test_rmse\n",
    "\n",
    "            print(f\"Steps {epoch * train_all + step + 1}: test RMSE {current_rmse:.4f}, moving average RMSE {moving_avg_test_rmse:.4f}, learning rate {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            # Check if the moving average RMSE is better; if not, increment counter\n",
    "            if moving_avg_test_rmse < best_test_rmse:\n",
    "                best_test_rmse = moving_avg_test_rmse\n",
    "                early_stopping_counter = 0  # Reset counter\n",
    "                cooldown_counter = cooldown  # Reset cooldown\n",
    "                # Optionally save the best model\n",
    "                os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "                best_model_path = f\"../model/{model_name}/{folder_name}/best_model.pt\"\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                if cooldown_counter > 0:\n",
    "                    cooldown_counter -= 1\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Stopping early at epoch {epoch+1}, step {step+1}\")\n",
    "                break\n",
    "\n",
    "            model.train()\n",
    "        \n",
    "    if early_stopping_counter >= patience:\n",
    "        break\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a776d47f3f04c6896cee11415b08a86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/552 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 0.705209633362466\n"
     ]
    }
   ],
   "source": [
    "validation_step = future_steps\n",
    "\n",
    "predictions = []\n",
    "truths = []\n",
    "\n",
    "test_loss_all = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    all_test = len(test)\n",
    "    test_rmse_all = []\n",
    "    for X_test_batch, y_test_batch in tqdm(test):\n",
    "        X_test_batch = X_test_batch.float().to(device)\n",
    "        y_test_batch = y_test_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "        y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "        # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "        # y_test_batch = y_test_batch[:, ::2, :2]\n",
    "        # X_test_batch = X_test_batch[:, ::2, :]\n",
    "        \n",
    "        y_preds = model(X_test_batch, influence=True, return_all=True)\n",
    "        # slect the one with minimum loss\n",
    "\n",
    "        min_loss = float('inf')\n",
    "        best_pred = None\n",
    "        for y_pred in y_preds:\n",
    "            loss_test = loss_fn(y_pred[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "            test_rmse = torch.sqrt(loss_test)\n",
    "            if test_rmse < min_loss:\n",
    "                min_loss = test_rmse\n",
    "                best_pred = y_pred\n",
    "        \n",
    "        test_loss_all.append(min_loss.item())\n",
    "\n",
    "        predictions.append(y_pred[:, :validation_step, :2] + current_pos_output[:, :y_pred.shape[1], :2])\n",
    "        truths.append(y_test_batch[:, :validation_step, :2] + current_pos_output[:, :y_pred.shape[1], :2])\n",
    "\n",
    "\n",
    "print(f\"Test RMSE: {sum(test_loss_all) / len(test_loss_all)}\")       \n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "truths = torch.cat(truths, dim=0)\n",
    "\n",
    "# reverse normalization\n",
    "normalize_dict = stats_dict\n",
    "\n",
    "for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assume predictions and truths are torch tensors of shape (batch_size, num_steps, num_dims)\n",
    "# Also assume model_name and folder_name are defined strings for saving the plot.\n",
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "steps = []\n",
    "ade_loss = []\n",
    "fde_loss = []\n",
    "\n",
    "# Loop over each prediction horizon (step)\n",
    "for step in range(1, predictions.size(1) + 1):\n",
    "    # Compute MSE loss for the first 'step' timesteps for all samples\n",
    "    raw_loss = criterion(predictions[:, :step, :], truths[:, :step, :])\n",
    "    # Sum loss over the coordinate dimension and take square root to get RMSE per timestep per sample\n",
    "    raw_rmse = torch.sqrt(torch.sum(raw_loss, dim=-1))\n",
    "    \n",
    "    # ADE: average RMSE over all time steps for each sample\n",
    "    current_ade = raw_rmse.mean(dim=-1)\n",
    "    # FDE: RMSE error at the final timestep for each sample\n",
    "    current_fde = raw_rmse[:, -1]  # Alternatively, use: raw_rmse.max(dim=-1).values\n",
    "    \n",
    "    ade_loss.append(current_ade)\n",
    "    fde_loss.append(current_fde)\n",
    "    steps.extend([step] * len(current_ade))\n",
    "\n",
    "# Concatenate results across all steps and move to CPU numpy arrays\n",
    "ade_loss = torch.cat(ade_loss).cpu().numpy()\n",
    "fde_loss = torch.cat(fde_loss).cpu().numpy()\n",
    "\n",
    "# Create DataFrames for ADE and FDE\n",
    "df_ade = pd.DataFrame({'Step': steps, 'Loss': ade_loss, 'Metric': 'ADE'})\n",
    "df_fde = pd.DataFrame({'Step': steps, 'Loss': fde_loss, 'Metric': 'FDE'})\n",
    "\n",
    "# Combine both DataFrames\n",
    "df = pd.concat([df_ade, df_fde], ignore_index=True)\n",
    "\n",
    "# Convert step count to seconds and scale the RMSE error to meters\n",
    "df['Second (s)'] = df['Step'] / 5   # For example, if 5 steps equal 1 second\n",
    "df['RMSE Error (m)'] = df['Loss'] / 100  # Convert error to meters\n",
    "\n",
    "# Plot the ADE and FDE curves using seaborn\n",
    "sns.lineplot(data=df, x='Second (s)', y='RMSE Error (m)', hue='Metric')\n",
    "plt.title(\"Trajectory Prediction Error: ADE vs FDE\")\n",
    "plt.xlabel(\"Time (s)\")\n",
    "plt.ylabel(\"RMSE Error (m)\")\n",
    "# plt.savefig(f'../model/{model_name}/{folder_name}/res.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "steps = []\n",
    "loss = []\n",
    "max_loss = []\n",
    "for step in range(1, predictions.size(1) + 1):\n",
    "    raw_rmse_loss = criterion(predictions[:, :step, :], truths[:, :step, :])\n",
    "    raw_rmse_loss = torch.sqrt(torch.sum(raw_rmse_loss, dim=-1))\n",
    "    mean_rmse_loss = raw_rmse_loss.mean(dim=-1)\n",
    "    max_rmse_loss = raw_rmse_loss.max(dim=-1).values\n",
    "    loss.append(mean_rmse_loss)\n",
    "    max_loss.append(max_rmse_loss)\n",
    "    steps.extend([step] * len(mean_rmse_loss))\n",
    "    \n",
    "max_loss = torch.cat(max_loss).cpu().numpy()\n",
    "loss = torch.cat(loss).cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame({'Second (s)': steps, 'loss': loss})\n",
    "df1 = pd.DataFrame({'Second (s)': steps, 'loss': max_loss})\n",
    "df['type'] = 'mean'\n",
    "df1['type'] = 'max'\n",
    "df = pd.concat([df, df1])\n",
    "\n",
    "\n",
    "df['RMSE Error (m)'] = df['loss'] / 100 # to meters\n",
    "df['Second (s)'] = df['Second (s)'] / 5 # to seconds\n",
    "sns.lineplot(data = df, x='Second (s)', y='RMSE Error (m)', hue='type',) #  errorbar=('sd', 1),\n",
    "plt.savefig(f'../model/{model_name}/{folder_name}/res.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize\n",
    "\n",
    "time_stamp = 24299\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "pred = predictions[time_stamp, :, :].cpu().numpy()\n",
    "truth = truths[time_stamp, :, :].cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# equal axis\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.plot(pred[:, 0], pred[:, 1], color='blue', label='Predicted Trajectory')\n",
    "ax.plot(truth[:, 0], truth[:, 1], color='red', label='Ground Truth Trajectory')\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_title('Predicted vs Ground Truth Trajectory')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second (s)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.411953</td>\n",
       "      <td>0.411953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.584402</td>\n",
       "      <td>0.429607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.672385</td>\n",
       "      <td>0.430571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.755011</td>\n",
       "      <td>0.443253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.822573</td>\n",
       "      <td>0.456573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.882477</td>\n",
       "      <td>0.469868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.931486</td>\n",
       "      <td>0.482329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>0.993323</td>\n",
       "      <td>0.499197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.8</th>\n",
       "      <td>1.035753</td>\n",
       "      <td>0.512378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1.084350</td>\n",
       "      <td>0.528315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2</th>\n",
       "      <td>1.124900</td>\n",
       "      <td>0.542816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>1.170711</td>\n",
       "      <td>0.559160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6</th>\n",
       "      <td>1.214891</td>\n",
       "      <td>0.575585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8</th>\n",
       "      <td>1.272780</td>\n",
       "      <td>0.594920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1.314860</td>\n",
       "      <td>0.611609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>1.355707</td>\n",
       "      <td>0.629180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.4</th>\n",
       "      <td>1.392041</td>\n",
       "      <td>0.645972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.6</th>\n",
       "      <td>1.438554</td>\n",
       "      <td>0.663979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.8</th>\n",
       "      <td>1.481384</td>\n",
       "      <td>0.682230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1.527172</td>\n",
       "      <td>0.701169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.2</th>\n",
       "      <td>1.575999</td>\n",
       "      <td>0.720617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.4</th>\n",
       "      <td>1.621721</td>\n",
       "      <td>0.739425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.6</th>\n",
       "      <td>1.658531</td>\n",
       "      <td>0.757366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.8</th>\n",
       "      <td>1.703168</td>\n",
       "      <td>0.776701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>1.746095</td>\n",
       "      <td>0.795835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.2</th>\n",
       "      <td>1.787002</td>\n",
       "      <td>0.815592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.4</th>\n",
       "      <td>1.832507</td>\n",
       "      <td>0.834650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.6</th>\n",
       "      <td>1.883546</td>\n",
       "      <td>0.855413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.8</th>\n",
       "      <td>1.925750</td>\n",
       "      <td>0.874835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>1.968594</td>\n",
       "      <td>0.894875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.2</th>\n",
       "      <td>2.015750</td>\n",
       "      <td>0.915555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.4</th>\n",
       "      <td>2.075885</td>\n",
       "      <td>0.936903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.6</th>\n",
       "      <td>2.121547</td>\n",
       "      <td>0.957439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.8</th>\n",
       "      <td>2.169589</td>\n",
       "      <td>0.977797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>2.220057</td>\n",
       "      <td>0.998886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.2</th>\n",
       "      <td>2.264923</td>\n",
       "      <td>1.019712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.4</th>\n",
       "      <td>2.309250</td>\n",
       "      <td>1.040092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.6</th>\n",
       "      <td>2.362869</td>\n",
       "      <td>1.061443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.8</th>\n",
       "      <td>2.408842</td>\n",
       "      <td>1.082671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>2.451247</td>\n",
       "      <td>1.103361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type             max      mean\n",
       "Second (s)                    \n",
       "0.2         0.411953  0.411953\n",
       "0.4         0.584402  0.429607\n",
       "0.6         0.672385  0.430571\n",
       "0.8         0.755011  0.443253\n",
       "1.0         0.822573  0.456573\n",
       "1.2         0.882477  0.469868\n",
       "1.4         0.931486  0.482329\n",
       "1.6         0.993323  0.499197\n",
       "1.8         1.035753  0.512378\n",
       "2.0         1.084350  0.528315\n",
       "2.2         1.124900  0.542816\n",
       "2.4         1.170711  0.559160\n",
       "2.6         1.214891  0.575585\n",
       "2.8         1.272780  0.594920\n",
       "3.0         1.314860  0.611609\n",
       "3.2         1.355707  0.629180\n",
       "3.4         1.392041  0.645972\n",
       "3.6         1.438554  0.663979\n",
       "3.8         1.481384  0.682230\n",
       "4.0         1.527172  0.701169\n",
       "4.2         1.575999  0.720617\n",
       "4.4         1.621721  0.739425\n",
       "4.6         1.658531  0.757366\n",
       "4.8         1.703168  0.776701\n",
       "5.0         1.746095  0.795835\n",
       "5.2         1.787002  0.815592\n",
       "5.4         1.832507  0.834650\n",
       "5.6         1.883546  0.855413\n",
       "5.8         1.925750  0.874835\n",
       "6.0         1.968594  0.894875\n",
       "6.2         2.015750  0.915555\n",
       "6.4         2.075885  0.936903\n",
       "6.6         2.121547  0.957439\n",
       "6.8         2.169589  0.977797\n",
       "7.0         2.220057  0.998886\n",
       "7.2         2.264923  1.019712\n",
       "7.4         2.309250  1.040092\n",
       "7.6         2.362869  1.061443\n",
       "7.8         2.408842  1.082671\n",
       "8.0         2.451247  1.103361"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_results = df.groupby(by=['Second (s)', 'type']).mean().unstack()['RMSE Error (m)']\n",
    "exp_results.to_csv(f'../model/{model_name}/{folder_name}/result.csv')\n",
    "exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export JIT Model\n",
    "\n",
    "Integrate partial of data processing into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXPORT_MODEL = True\n",
    "\n",
    "# # # model.load_state_dict(torch.load(\"/home/shaoze/Documents/Boeing/Boeing-Trajectory-Prediction/model/Jul09_20-37-37/model_40000.pt\"))\n",
    "# # if EXPORT_MODEL:\n",
    "# #     model.eval()\n",
    "# #     model.to('cpu')\n",
    "# #     script_module = torch.jit.script(model)\n",
    "# #     os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# #     script_module.save(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# stats = {}\n",
    "# '''\n",
    "# mean: tensor[]\n",
    "# '''\n",
    "\n",
    "# for keys, values in stats_dict.items():\n",
    "#     stats[keys] = torch.tensor(values.to_list()).view(1,1,-1)\n",
    "    \n",
    "# class TFT_EXP(nn.Module):\n",
    "#     def __init__(self, model:EnhancedTFT, stats:dict):\n",
    "#         super(TFT_EXP, self).__init__()\n",
    "#         self.stats = stats\n",
    "#         self.register_buffer('mean', self.stats['mean'])\n",
    "#         self.register_buffer('std', self.stats['std'])\n",
    "#         self.register_buffer('min', self.stats['min'])\n",
    "#         self.register_buffer('max', self.stats['max'])\n",
    "#         self.TFT = model\n",
    "#         self.num_steps = model.num_steps\n",
    "#         self.num_outputs = model.num_outputs # =2\n",
    "\n",
    "#     def forward(self, x, mask: Optional[torch.Tensor]=None):\n",
    "#         single = False\n",
    "#         if len(x.shape) == 2:\n",
    "#             x = x.unsqueeze(0)\n",
    "#             single = True\n",
    "        \n",
    "#         # normalize\n",
    "#         x = (x - self.mean) / self.std\n",
    "#         x = (x - self.min) / (self.max - self.min)\n",
    "#         # residual\n",
    "#         current_pos_input = x[:, -1, :2].clone().unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "#         current_pos_output = x[:, -1, :2].clone().unsqueeze(1).repeat(1, self.num_steps, 1)\n",
    "#         x[:, :, :2] = x[:, :, :2] - current_pos_input\n",
    "        \n",
    "#         # pass through TFT\n",
    "#         outputs, vq_loss, perplexity = self.TFT(x, mask)\n",
    "#         outputs = outputs.detach()\n",
    "        \n",
    "#         # de-residual\n",
    "#         outputs[:, :, :2] = outputs[:, :, :2] + current_pos_output\n",
    "        \n",
    "#         # denormalize\n",
    "#         outputs = outputs * (self.max[:,:,:self.num_outputs] - self.min[:,:,:self.num_outputs]) + self.min[:,:,:self.num_outputs]\n",
    "#         outputs = outputs * self.std[:,:,:self.num_outputs] + self.mean[:,:,:self.num_outputs]\n",
    "        \n",
    "#         if single:\n",
    "#             outputs = outputs.squeeze(0)\n",
    "#         return outputs\n",
    "\n",
    "# tft_exp = TFT_EXP(model, stats)\n",
    "# tft_exp.to('cpu')\n",
    "# tft_exp.eval()\n",
    "# # script_module = torch.jit.script(tft_exp)\n",
    "# # os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# # script_module.save(\"../exported/model_tft_vqvae_cpu_preproc.pt\")\n",
    "\n",
    "# # export to onnx\n",
    "\n",
    "# dummy_input = torch.randn(1, lookback, feature_dim)\n",
    "# print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "# # Export the wrapped model to ONNX format\n",
    "# torch.onnx.export(\n",
    "#     tft_exp,                   # Wrapped model to export\n",
    "#     dummy_input,                     # Model input\n",
    "#     \"../exported/tft_1111.onnx\",              # Output file name\n",
    "#     export_params=True,              # Store the trained parameter weights inside the model file\n",
    "#     opset_version=13,                # Set the ONNX opset version (adjust as needed)\n",
    "#     do_constant_folding=True,        # Whether to execute constant folding for optimization\n",
    "#     input_names=['input'],           # The model's input names\n",
    "#     output_names=['output'],         # The model's output names\n",
    "#     # dynamic_axes={\n",
    "#     #     'input': {0: 'batch_size'},  # Dynamic batch_size and sequence_length\n",
    "#     #     'output': {0: 'batch_size'}  # Dynamic batch_size for the output\n",
    "#     # }\n",
    "# )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime as ort\n",
    "# import numpy as np\n",
    "\n",
    "# # Path to your ONNX model\n",
    "# model_path = \"../exported/tft_1111.onnx\"\n",
    "\n",
    "# # Create an inference session\n",
    "# session = ort.InferenceSession(model_path)\n",
    "\n",
    "# # Get the name of the input node\n",
    "# input_name = session.get_inputs()[0].name\n",
    "\n",
    "# for file in os.listdir(dir):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         df = process_data(dir+file)\n",
    "#     break\n",
    "\n",
    "# df = df[['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "#        'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "#        'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "#        'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "#        'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "#        'closest_station', 'distance_to_closest_station',\n",
    "#        'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "#        'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "#        'GazeDirection_Z', 'AGV_X', 'AGV_Y',\n",
    "#        'looking_at_closest_station']]\n",
    "\n",
    "# start_idx = 100\n",
    "# input = df.iloc[200:200+lookback].astype(np.float32).values\n",
    "\n",
    "# # add batch\n",
    "# input = input[np.newaxis, :, :]\n",
    "# # Run the model\n",
    "# output = session.run(None, {input_name: input.astype(np.float32)})[0]\n",
    "\n",
    "# output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data (for interactive visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# test_ds = MyDataset(lookback=lookback)\n",
    "# all_ds = ds.dataset\n",
    "# test_ds.dataset = all_ds[len(all_ds)//10 :] # load the last 10% of the data\n",
    "# X_list, y_list = test_ds.generate_data(return_list=True, future_steps=future_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# normalize_dict = stats_dict\n",
    "# pred_data = []\n",
    "# truth_data = []\n",
    "# input_data = []\n",
    "# model.eval()\n",
    "# device = 'cpu'\n",
    "# for i, (X, y) in enumerate(zip(X_list, y_list)):\n",
    "#     current_pos_input = X[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "#     current_pos_output = X[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1).to(device)\n",
    "#     X[:, :, :2] = X[:, :, :2] - current_pos_input\n",
    "\n",
    "#     predictions = model(X.float().to(device))[0][:, :future_steps, :2]\n",
    "#     predictions = predictions + current_pos_output\n",
    "#     predictions = predictions.to('cpu')\n",
    "    \n",
    "#     truths = y[:, :future_steps, :2]\n",
    "#     X[:, :, :2] = X[:, :, :2] + current_pos_input\n",
    "#     model_input = X.float().to(device)[:, :lookback, :2]\n",
    "#     trajectory_id = i\n",
    "    \n",
    "#     # reverse normalization\n",
    "#     for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    \n",
    "#     for group_id in range(predictions.shape[0]):\n",
    "#         for time_step in range(predictions.shape[1]):\n",
    "#             pred_x, pred_y = predictions[group_id, time_step]\n",
    "#             pred_data.append([trajectory_id, group_id, time_step, pred_x.item(), pred_y.item()])\n",
    "\n",
    "#             truth_x, truth_y = truths[group_id, time_step]\n",
    "#             truth_data.append([trajectory_id, group_id, time_step, truth_x.item(), truth_y.item()])\n",
    "        \n",
    "#         for time_step in range(lookback):\n",
    "#             input_x, input_y = model_input[group_id, time_step]\n",
    "#             input_data.append([trajectory_id, group_id, time_step, input_x.item(), input_y.item()])\n",
    "            \n",
    "\n",
    "# pred_df = pd.DataFrame(pred_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# truth_df = pd.DataFrame(truth_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# input_df = pd.DataFrame(input_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_remove = [\n",
    "#     \"../data/pred_tra_all.pkl\",\n",
    "#     \"../data/truth_tra_all.pkl\", \n",
    "#     \"../data/input_tra_all.pkl\"\n",
    "# ]\n",
    "\n",
    "# for file_path in files_to_remove:\n",
    "#     if os.path.exists(file_path):\n",
    "#         os.remove(file_path)\n",
    "\n",
    "# truth_df.to_pickle(\"../data/truth_tra_all.pkl\")\n",
    "# pred_df.to_pickle(\"../data/pred_tra_all.pkl\")\n",
    "# input_df.to_pickle(\"../data/input_tra_all.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
