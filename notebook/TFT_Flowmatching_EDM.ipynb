{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import sys\n",
    "cur_dir = os.path.dirname(os.path.abspath(\"__file__\"))  # Gets the current notebook directory\n",
    "src_dir = os.path.join(cur_dir, '../')  # Constructs the path to the 'src' directory\n",
    "# Add the 'src' directory to sys.path\n",
    "if src_dir not in sys.path:\n",
    "    sys.path.append(src_dir)\n",
    "\n",
    "from src.constant import *\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from src.MyDataset import MyDataset, save_dataset, load_dataset\n",
    "# from src.TFT_Flowmatching import TemporalFusionTransformerDiffusion\n",
    "\n",
    "from src.VQVAE import VQVAE\n",
    "from typing import Optional\n",
    "import pickle\n",
    "\n",
    "import torch.utils\n",
    "import torch.utils.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: direct load data from Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback = 30\n",
    "future_steps = 40\n",
    "resample = False\n",
    "dir = '../data/Phase3/Modified/'\n",
    "ds = MyDataset(lookback=lookback)\n",
    "train_batch_size = 128\n",
    "test_batch_size = 256\n",
    "\n",
    "train = load_dataset('../data/.cache/train.pkl', batch_size=train_batch_size)\n",
    "test = load_dataset('../data/.cache/test.pkl', batch_size=test_batch_size)\n",
    "stats_dict = pickle.load(open('../data/.cache/stats_dict.pkl', 'rb'))\n",
    "\n",
    "# train = load_dataset('../data/.cache/opentraj_train.pkl', batch_size=train_batch_size)\n",
    "# test = load_dataset('../data/.cache/opentraj_test.pkl', batch_size=test_batch_size)\n",
    "# stats_dict = pickle.load(open('../data/.cache/opentraj_stats_dict.pkl', 'rb'))\n",
    "\n",
    "feature_dim = stats_dict['feature_dim']\n",
    "features = stats_dict['features']\n",
    "\n",
    "\n",
    "feature_dim = 38"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def process_data(df_dir : str, target_freq : int = 10):\n",
    "#     df: pd.DataFrame = pd.read_pickle(df_dir)\n",
    "#     df.columns = df.columns.str.strip() \n",
    "    \n",
    "#     df = df.rename(columns={'State': 'state'})\n",
    "\n",
    "#     states = ['At Station', 'Error', 'Wait', 'Cross', 'Approach Sidewalk',\n",
    "#        'Approach Target Station', 'Move Along Sidewalk']\n",
    "\n",
    "#     states_ohe = pd.get_dummies(df['state'], prefix='state')\n",
    "#     cur_states = df['state'].unique()\n",
    "#     for state in states:\n",
    "#         if state not in cur_states:\n",
    "#             states_ohe['state_'+state] = 0\n",
    "\n",
    "#     df = pd.concat([df, states_ohe], axis=1)\n",
    "#     df.drop(columns=['state'], inplace=True)\n",
    "    \n",
    "#     df.dropna(inplace=True, how='any')\n",
    "#     if resample:\n",
    "#         f_per_sec = df.groupby('TimestampID').count().mean().mean()\n",
    "#         if f_per_sec < target_freq:\n",
    "#             raise ValueError('The frequency of the data is lower than the target frequency')\n",
    "#         elif int(f_per_sec) == target_freq:\n",
    "#             pass\n",
    "#         else:\n",
    "#             resample_ratio = int(f_per_sec/target_freq)\n",
    "#             df = df.iloc[::resample_ratio, :]\n",
    "#     # # for origin\n",
    "#     for drop_column in ['Confidence', 'Timestamp', 'TimestampID', \n",
    "#                           'DatapointID', 'PID', 'SCN', 'U_X', 'U_Y', 'U_Z', \n",
    "#                           'AGV_Z', 'User_Z', 'GazeOrigin_Z', 'User_Pitch', 'User_Yaw', 'User_Roll', \n",
    "#                           'EyeTarget', \n",
    "#                           'start_station_X', 'start_station_Y', 'end_station_X', 'end_station_Y',\n",
    "#                           'distance_from_start_station_X',\n",
    "#                             'distance_from_start_station_Y', 'distance_from_end_station_X',\n",
    "#                             'distance_from_end_station_Y', 'facing_start_station',\n",
    "#                             'facing_end_station', \n",
    "#                             'rolling_avg', \n",
    "#                             'User', 'Type', \n",
    "#                             'possible_interaction'\n",
    "#                           ]:\n",
    "#         df = df.drop(columns=[drop_column], errors='ignore')\n",
    "\n",
    "#     target_columns = ['User_X', 'User_Y']\n",
    "#     # Reorder columns\n",
    "#     new_columns = target_columns + [col for col in df.columns if col not in target_columns]\n",
    "#     df = df[new_columns]\n",
    "    \n",
    "#     # keep numeric columns\n",
    "#     df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "#     return df\n",
    "\n",
    "# for file in os.listdir(dir):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         df = process_data(dir+file)\n",
    "#         ds.read_data(df, agv_col_name=\"scenario\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = process_data(dir+file)\n",
    "# df = df[df['scenario'] == 7]\n",
    "\n",
    "# uer_x, uer_y = df['User_X'].values[10:40], df['User_Y'].values[10:40]\n",
    "\n",
    "# plt.plot(uer_x, uer_y)\n",
    "# # same\n",
    "# plt.title('User Position')\n",
    "# plt.xlabel('X')\n",
    "# plt.ylabel('Y')\n",
    "# # equal aspect ratio\n",
    "# plt.gca().set_aspect('equal', adjustable='box')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional: shuffle the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random\n",
    "# random.shuffle(ds.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "# stats_dict = {'mean': 0, 'std': 0, 'min': 0, 'max': 0}\n",
    "# stats_dict = ds.normalize_dataset()\n",
    "# ds.generate_data(future_steps=future_steps)\n",
    "\n",
    "# train:torch.utils.data.DataLoader\n",
    "# test:torch.utils.data.DataLoader\n",
    "\n",
    "# train, test = ds.split_data(frac=0.9, shuffle=True, train_batch_size=train_batch_size, test_batch_size=test_batch_size)\n",
    "\n",
    "# feature_dim = ds.feature_dim\n",
    "# stats_dict['feature_dim'] = feature_dim\n",
    "# stats_dict['features'] = ds.dataset[0].columns\n",
    "# columns = [_ for _ in ds.dataset[0].columns if _ not in ['AGV_name']]\n",
    "# print(f\"columns : {df.columns} \\nfeature_dim : {feature_dim}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "       'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "       'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "       'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "       'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "       'closest_station', 'distance_to_closest_station',\n",
    "       'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "       'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "       'GazeDirection_Z', 'AGV_X', 'AGV_Y', 'looking_at_closest_station']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 30, 38]) torch.Size([128, 40, 38])\n",
      "317952 35328\n"
     ]
    }
   ],
   "source": [
    "for i, (X, y) in enumerate(train):\n",
    "    print(X.shape, y.shape)\n",
    "    break\n",
    "\n",
    "print(len(train) * train_batch_size, len(test) * test_batch_size)\n",
    "\n",
    "# # save it to cache to speed up\n",
    "# save_dataset(train, type='train', file_path='../data/.cache/train.pkl')\n",
    "# save_dataset(test, type='test', file_path='../data/.cache/test.pkl')\n",
    "# pickle.dump(stats_dict, open('../data/.cache/stats_dict.pkl', 'wb'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of DiT parameters:  561024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 40, 2])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from src.DiT import DiT\n",
    "\n",
    "\n",
    "class SinusoidalTimeEmbedding(nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super().__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "    def forward(self, t):\n",
    "        # t: Tensor of shape (batch, )\n",
    "        if t.dim() == 1:\n",
    "            t = t.unsqueeze(1)\n",
    "        batch, n = t.shape\n",
    "\n",
    "        half_dim = self.embedding_dim // 2\n",
    "        emb_factor = math.log(10000) / (half_dim - 1)\n",
    "        dims = torch.arange(half_dim, device=t.device, dtype=t.dtype)\n",
    "        emb = t * torch.exp(-dims * emb_factor)\n",
    "        emb = torch.cat([torch.sin(emb), torch.cos(emb)], dim=1)\n",
    "        if self.embedding_dim % 2 == 1:\n",
    "            emb = F.pad(emb, (0, 1))\n",
    "        emb = emb.view(batch, n, -1)\n",
    "        return emb\n",
    "\n",
    "\n",
    "class DiffusionDecoder(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        action_dim,\n",
    "        conditioning_dim,\n",
    "        num_diffusion_steps=10,\n",
    "        num_action_steps=20,\n",
    "        hidden_dim=128,\n",
    "        num_layers=2,\n",
    "        noise_weight=0.5,\n",
    "        num_heads=4,\n",
    "        dropout_rate=0.1,\n",
    "        sigma_min=0.001,\n",
    "        sigma_max=0.5,\n",
    "        rho=7.0,\n",
    "        sigma_data=0.25, # estimated std of the data\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.action_dim = action_dim\n",
    "        self.num_diffusion_steps = num_diffusion_steps\n",
    "        self.num_action_steps = num_action_steps\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.noise_weight = noise_weight\n",
    "\n",
    "        # EDM parameters\n",
    "        self.sigma_min = sigma_min\n",
    "        self.sigma_max = sigma_max\n",
    "        self.rho = rho\n",
    "        self.sigma_data = sigma_data\n",
    "\n",
    "        # Time embedding\n",
    "        self.time_embed = SinusoidalTimeEmbedding(hidden_dim)\n",
    "        self.time_proj = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, hidden_dim * 2),\n",
    "            nn.SiLU(),\n",
    "            nn.Linear(hidden_dim * 2, hidden_dim),\n",
    "        )\n",
    "\n",
    "        # Input encoders and embeddings\n",
    "        self.x_encoder = nn.Linear(action_dim, hidden_dim)\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(1, num_action_steps, hidden_dim))\n",
    "\n",
    "        # DiT backbone\n",
    "        self.dit = DiT(\n",
    "            num_attention_heads=num_heads,\n",
    "            attention_head_dim=hidden_dim // num_heads,\n",
    "            output_dim=hidden_dim,\n",
    "            num_layers=num_layers,\n",
    "            dropout=dropout_rate,\n",
    "            norm_elementwise_affine=True,\n",
    "        )\n",
    "\n",
    "        # Output projection\n",
    "        self.final_norm = nn.LayerNorm(hidden_dim)\n",
    "        self.proj_1 = nn.Linear(hidden_dim, hidden_dim * 2)\n",
    "        self.proj_2 = nn.Linear(hidden_dim * 2, hidden_dim)\n",
    "        self.output = nn.Linear(hidden_dim, action_dim)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def get_sigmas(self, u):\n",
    "        \"\"\"Sample sigma from EDM schedule using variable u ~ Uniform(0,1).\"\"\"\n",
    "        return (self.sigma_max ** (1 - u) * self.sigma_min**u) ** (1 / (self.rho + 1))\n",
    "\n",
    "    def get_edm_velocity(self, conditioning, x, sigma, t):\n",
    "        \"\"\"Compute one-step velocity field per EDM: combines skip, out, and network output.\"\"\"\n",
    "        c_skip = self.sigma_data**2 / (sigma**2 + self.sigma_data**2)\n",
    "        c_out = sigma * self.sigma_data / torch.sqrt(sigma**2 + self.sigma_data**2)\n",
    "        c_in = 1 / torch.sqrt(sigma**2 + self.sigma_data**2)\n",
    "        c_skip, c_out, c_in = c_skip.view(-1, 1, 1), c_out.view(-1, 1, 1), c_in.view(-1, 1, 1)\n",
    "        return c_skip * x + c_out * self.forward(conditioning, x * c_in, t)\n",
    "\n",
    "    def forward(self, conditioning, x_t, t):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            conditioning: (batch, cond_len, hidden_dim)\n",
    "            x_t: (batch, num_action_steps, action_dim)\n",
    "            t: (batch, ) in [0,1]\n",
    "        Returns:\n",
    "            output: (batch, num_action_steps, action_dim)\n",
    "        \"\"\"\n",
    "        batch_size = x_t.size(0)\n",
    "\n",
    "        # Encode input trajectory\n",
    "        x = self.x_encoder(x_t) + self.pos_embed\n",
    "\n",
    "        # Pool conditioning if necessary\n",
    "        if conditioning.size(1) > 1:\n",
    "            cond_pooled = conditioning.mean(dim=1, keepdim=True)\n",
    "        else:\n",
    "            cond_pooled = conditioning\n",
    "\n",
    "        # Time embedding\n",
    "        t_emb = self.time_embed(t)              # (batch, 1, hidden_dim)\n",
    "        t_emb = self.time_proj(t_emb.squeeze(1)).unsqueeze(1)  # (batch, 1, hidden_dim)\n",
    "\n",
    "        # Concatenate time token and trajectory tokens\n",
    "        x = torch.cat([t_emb, x], dim=1)  # (batch, 1+num_steps, hidden_dim)\n",
    "\n",
    "        # Prepare timestep indices for DiT\n",
    "        timesteps = (t * (self.num_diffusion_steps - 1)).long()\n",
    "\n",
    "        # Run through transformer backbone\n",
    "        x = self.dit(\n",
    "            hidden_states=x,\n",
    "            encoder_hidden_states=cond_pooled,\n",
    "            timestep=timesteps,\n",
    "        )\n",
    "\n",
    "        # Final MLP projection\n",
    "        x = self.final_norm(x)\n",
    "        x = F.gelu(self.proj_1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.gelu(self.proj_2(x))\n",
    "        x = self.dropout(x)\n",
    "        output = self.output(x)\n",
    "\n",
    "        # Remove the prepended time token\n",
    "        return output[:, -self.num_action_steps :, :]\n",
    "\n",
    "    def decoder_train_step(self, conditioning, y_batch, device):\n",
    "        \"\"\"Perform one EDM training step.\"\"\"\n",
    "        batch_size = y_batch.size(0)\n",
    "        u = torch.rand(batch_size, device=device)\n",
    "        sigma = self.get_sigmas(u)\n",
    "\n",
    "        noise = torch.randn_like(y_batch)\n",
    "        x_t = y_batch + sigma.unsqueeze(-1).unsqueeze(-1) * noise\n",
    "\n",
    "        x_pred = self.get_edm_velocity(conditioning, x_t, sigma, u)\n",
    "        loss = F.mse_loss(x_pred, y_batch)\n",
    "        return loss.mean()\n",
    "\n",
    "    def influence(self, conditioning, device):\n",
    "        \"\"\"One-step denoising from pure noise.\"\"\"\n",
    "        batch_size = conditioning.size(0)\n",
    "        x = torch.randn(batch_size, self.num_action_steps, self.action_dim, device=device) * self.sigma_max\n",
    "\n",
    "        u = torch.zeros(batch_size, device=device)\n",
    "        sigma = self.get_sigmas(u)\n",
    "        x = self.get_edm_velocity(conditioning, x, sigma, u)\n",
    "        return [x]\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "decoder = DiffusionDecoder(action_dim=2, conditioning_dim=feature_dim, num_diffusion_steps=10, num_action_steps=future_steps, hidden_dim=128, num_layers=2, noise_weight=0.1, num_heads=4)\n",
    "y_batch = torch.randn(16, 40, 2).to(device)\n",
    "condition = torch.randn(16, 1, 128).to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "decoder.decoder_train_step(condition, y_batch, device)\n",
    "decoder.influence(condition, device)[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from typing import Optional\n",
    "from src.VQVAE import VQVAE\n",
    "from src.DiT import SelfAttentionTransformer\n",
    "import math\n",
    "\n",
    "###############################################\n",
    "# Original Blocks (with minor efficiency tweaks)\n",
    "###############################################\n",
    "\n",
    "class GatedResidualNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size, num_layers=3, dropout_rate=0.1):\n",
    "        super(GatedResidualNetwork, self).__init__()\n",
    "        self.layers = nn.ModuleList(\n",
    "            [nn.Linear(input_size if i == 0 else hidden_size, hidden_size) for i in range(num_layers)]\n",
    "        )\n",
    "        self.norms = nn.ModuleList([nn.LayerNorm(hidden_size) for _ in range(num_layers)])\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "        self.fc3 = nn.Linear(input_size, output_size)\n",
    "        self.gate = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_input = x\n",
    "        for layer, norm in zip(self.layers, self.norms):\n",
    "            x = F.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "            x = norm(x)\n",
    "        gate = torch.sigmoid(self.gate(x))\n",
    "        x2 = self.fc2(x)\n",
    "        return self.fc3(x_input) + gate * x2\n",
    "    \n",
    "    \n",
    "class GRUEncoder(nn.Module):\n",
    "    def __init__(self, input_dim: int, hidden_dim: int):\n",
    "        super(GRUEncoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        # update gate parameters\n",
    "        self.x2z = nn.Linear(input_dim,  hidden_dim)\n",
    "        self.h2z = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        # reset  gate parameters\n",
    "        self.x2r = nn.Linear(input_dim,  hidden_dim)\n",
    "        self.h2r = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "        # candidate hidden state parameters\n",
    "        self.x2h = nn.Linear(input_dim,  hidden_dim)\n",
    "        self.h2h = nn.Linear(hidden_dim, hidden_dim, bias=False)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, h0: torch.Tensor = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          x:  Tensor of shape (batch, seq_len, input_dim)\n",
    "          h0: Optional initial hidden state, shape (batch, hidden_dim)\n",
    "        Returns:\n",
    "          outputs: Tensor of shape (batch, seq_len, hidden_dim)\n",
    "          h_t:      Tensor of shape (batch, hidden_dim), the final hidden state\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "\n",
    "        # initialize hidden state if not provided\n",
    "        if h0 is None:\n",
    "            h_t = x.new_zeros(batch_size, self.hidden_dim)\n",
    "        else:\n",
    "            h_t = h0\n",
    "\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[:, t, :]\n",
    "            \n",
    "            # compute gates\n",
    "            z_t = torch.sigmoid(self.x2z(x_t) + self.h2z(h_t))      # update gate\n",
    "            r_t = torch.sigmoid(self.x2r(x_t) + self.h2r(h_t))      # reset  gate\n",
    "            \n",
    "            # candidate hidden state\n",
    "            h_tilde = torch.tanh(self.x2h(x_t) + self.h2h(r_t * h_t))\n",
    "            \n",
    "            # new hidden state\n",
    "            h_t = (1 - z_t) * h_t + z_t * h_tilde\n",
    "\n",
    "            outputs.append(h_t.unsqueeze(1))\n",
    "\n",
    "        outputs = torch.cat(outputs, dim=1)  # (batch, seq_len, hidden_dim)\n",
    "        return outputs, h_t\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, hidden_size, num_heads, dropout_rate=0.1):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = nn.MultiheadAttention(hidden_size, num_heads, dropout=dropout_rate)\n",
    "        self.norm1 = nn.LayerNorm(hidden_size)\n",
    "        self.norm2 = nn.LayerNorm(hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(hidden_size, hidden_size * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_size * 4, hidden_size)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, mask: Optional[torch.Tensor] = None):\n",
    "        # x: (seq_len, batch, hidden_size)\n",
    "        x2 = x\n",
    "        x = self.norm1(x)\n",
    "        x, _ = self.attention(x, x, x, key_padding_mask=mask)\n",
    "        x = x + x2\n",
    "        x2 = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.feed_forward(x)\n",
    "        x = x + x2\n",
    "        return x\n",
    "\n",
    "\n",
    "def cosine_beta_schedule(timesteps, s=0.008):\n",
    "    steps = timesteps + 1\n",
    "    x = torch.linspace(0, timesteps, steps)\n",
    "    alphas_cumprod = torch.cos(((x / timesteps) + s) / (1 + s) * math.pi * 0.5) ** 2\n",
    "    alphas_cumprod = alphas_cumprod / alphas_cumprod[0]\n",
    "    betas = 1 - (alphas_cumprod[1:] / alphas_cumprod[:-1])\n",
    "    return torch.clip(betas, 0.0001, 0.9999)\n",
    "\n",
    "\n",
    "class TemporalFusionTransformerDiffusion(nn.Module):\n",
    "    def __init__(self, num_features, num_hidden, num_outputs, num_steps, his_steps = 30, \n",
    "                 num_attention_heads=8, diffusion_steps=10, vqvae: VQVAE = None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_features (int): Number of input features.\n",
    "            num_hidden (int): Hidden dimension size.\n",
    "            num_outputs (int): Dimensionality of each output (e.g. action dimension).\n",
    "            num_steps (int): Desired output sequence length (e.g. number of action steps).\n",
    "            num_attention_heads (int): Number of heads for the transformer blocks.\n",
    "            diffusion_steps (int): Number of diffusion (denoising) steps.\n",
    "        \"\"\"\n",
    "        super(TemporalFusionTransformerDiffusion, self).__init__()\n",
    "        if vqvae is None:\n",
    "            self.vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "        else:\n",
    "            self.vqvae = vqvae\n",
    "\n",
    "        self.num_hidden = num_hidden\n",
    "        num_features = num_features + self.vqvae.encoder.fc2.out_features\n",
    "        self.encoder_grn = GatedResidualNetwork(num_features, num_hidden, num_hidden)\n",
    "        \n",
    "        # self.transformer_block = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        # self.transformer_block2 = TransformerBlock(num_hidden, num_heads=num_attention_heads, dropout_rate=0.1)\n",
    "        \n",
    "        self.transformer_encoder = SelfAttentionTransformer(num_attention_heads=num_attention_heads, \n",
    "                                                            attention_head_dim=num_hidden // num_attention_heads, \n",
    "                                                            output_dim=num_hidden, \n",
    "                                                            num_layers=2, \n",
    "                                                            dropout=0.1, attention_bias=True, \n",
    "                                                            activation_fn=\"gelu-approximate\", \n",
    "                                                            max_num_positional_embeddings=512, \n",
    "                                                            compute_dtype=torch.float32, \n",
    "                                                            final_dropout=True, \n",
    "                                                            positional_embeddings=\"sinusoidal\", \n",
    "                                                            interleave_self_attention=False)\n",
    "        self.encoder_gru = GRUEncoder(num_hidden, num_hidden)\n",
    "        self.his_steps = his_steps\n",
    "\n",
    "        # Diffusion decoder: we set action_dim=num_outputs and produce a sequence of length num_steps.\n",
    "        self.diffusion_decoder = DiffusionDecoder(\n",
    "            action_dim=num_outputs,\n",
    "            conditioning_dim=num_hidden,\n",
    "            num_diffusion_steps=diffusion_steps,\n",
    "            num_action_steps=num_steps,\n",
    "            num_heads=num_attention_heads,  \n",
    "            hidden_dim=num_hidden, \n",
    "            num_layers=2,  # you can adjust as needed\n",
    "            noise_weight=1  # you can adjust as needed\n",
    "        )\n",
    "\n",
    "        self.num_steps = num_steps\n",
    "        self.num_outputs = num_outputs\n",
    "\n",
    "\n",
    "    def forward(self, x, y_batch=None , mask: Optional[torch.Tensor] = None, influence=False, return_all=False):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x: Input tensor of shape (batch, seq_len, num_features).\n",
    "            mask: Optional attention mask for the transformer blocks.\n",
    "            \n",
    "        Returns:\n",
    "            actions: Tensor of shape (batch, num_steps, num_outputs)\n",
    "        \"\"\"\n",
    "        # If given a 2D input, add a batch dimension.\n",
    "        if len(x.shape) == 2:\n",
    "            x = x.unsqueeze(0)\n",
    "        batch_size, seq_len, _ = x.shape\n",
    "\n",
    "        # VQ-VAE\n",
    "        x_recon, vq_loss, perplexity, embedding = self.vqvae(x)\n",
    "        x = torch.cat((x, embedding), dim=-1)\n",
    "        \n",
    "        # Encoder GRN.\n",
    "        x = self.encoder_grn(x)  # (batch, seq_len, num_hidden)\n",
    "        \n",
    "        # Transformer expects (seq_len, batch, hidden_size).\n",
    "        # x = x.permute(1, 0, 2)\n",
    "        # x = self.transformer_block(x, mask=mask)\n",
    "        # x = self.transformer_block2(x, mask=mask)\n",
    "        # x = x.permute(1, 0, 2)  # back to (batch, seq_len, num_hidden)\n",
    "        \n",
    "        x = self.transformer_encoder(x)\n",
    "        \n",
    "\n",
    "        # Use a summary of the encoder output as conditioning.\n",
    "        # Here we use the last time–step (you might also try an average or more complex pooling).\n",
    "        x, conditioning = self.encoder_gru(x)  # (batch, seq_len, num_hidden)\n",
    "        conditioning = conditioning.unsqueeze(1)\n",
    "        # conditioning = x[:, -1:, :] #self.condition_proj()  # (batch, 1, num_hidden)\n",
    "\n",
    "        # flow matching during training\n",
    "        self.device = next(self.parameters()).device\n",
    "        \n",
    "        if influence:\n",
    "            if return_all:\n",
    "                return [traj for traj in self.diffusion_decoder.influence(conditioning, self.device)]\n",
    "            return self.diffusion_decoder.influence(conditioning, self.device)[-1]\n",
    "        else:\n",
    "            if self.training:\n",
    "                max_displace = torch.max(y_batch, dim=1).values - torch.min(y_batch, dim=1).values\n",
    "                max_displace = torch.linalg.norm(max_displace, dim=1)\n",
    "                diff_loss = self.diffusion_decoder.decoder_train_step(conditioning, y_batch, self.device)\n",
    "                diff_loss = diff_loss.mean()\n",
    "                return diff_loss, vq_loss\n",
    "            \n",
    "\n",
    "    def influence(self, x):\n",
    "        User_trajectory = self.forward(x, influence=True)\n",
    "        return User_trajectory\n",
    "\n",
    "\n",
    "\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# print(f\"Using {device}\")\n",
    "\n",
    "# vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "# model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps, diffusion_steps=10, vqvae=vqvae)\n",
    "# optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# model.to(device)\n",
    "\n",
    "# X_batch, y_batch = next(iter(train))\n",
    "# X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "# model(X_batch, y_batch[:, :future_steps, :2], influence=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n",
      "Total number of SelfAttentionTransformer parameters:  396544\n",
      "Total number of DiT parameters:  561024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TemporalFusionTransformerDiffusion(\n",
       "  (vqvae): VQVAE(\n",
       "    (encoder): VQVAEEncoder(\n",
       "      (fc1): Linear(in_features=38, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    )\n",
       "    (quantizer): VectorQuantizer(\n",
       "      (embedding): Embedding(128, 128)\n",
       "    )\n",
       "    (decoder): VQVAEDecoder(\n",
       "      (fc1): Linear(in_features=128, out_features=512, bias=True)\n",
       "      (fc2): Linear(in_features=512, out_features=38, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (encoder_grn): GatedResidualNetwork(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=166, out_features=128, bias=True)\n",
       "      (1-2): 2 x Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (norms): ModuleList(\n",
       "      (0-2): 3 x LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (fc2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=166, out_features=128, bias=True)\n",
       "    (gate): Linear(in_features=128, out_features=128, bias=True)\n",
       "  )\n",
       "  (transformer_encoder): SelfAttentionTransformer(\n",
       "    (transformer_blocks): ModuleList(\n",
       "      (0-1): 2 x BasicTransformerBlock(\n",
       "        (pos_embed): SinusoidalPositionalEmbedding()\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn1): Attention(\n",
       "          (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "          (to_out): ModuleList(\n",
       "            (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff): FeedForward(\n",
       "          (net): ModuleList(\n",
       "            (0): GELU(\n",
       "              (proj): Linear(in_features=128, out_features=512, bias=True)\n",
       "            )\n",
       "            (1): Dropout(p=0.1, inplace=False)\n",
       "            (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "            (3): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (final_dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder_gru): GRUEncoder(\n",
       "    (x2z): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (h2z): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (x2r): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (h2r): Linear(in_features=128, out_features=128, bias=False)\n",
       "    (x2h): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (h2h): Linear(in_features=128, out_features=128, bias=False)\n",
       "  )\n",
       "  (diffusion_decoder): DiffusionDecoder(\n",
       "    (time_embed): SinusoidalTimeEmbedding()\n",
       "    (time_proj): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (1): SiLU()\n",
       "      (2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    )\n",
       "    (x_encoder): Linear(in_features=2, out_features=128, bias=True)\n",
       "    (dit): DiT(\n",
       "      (timestep_encoder): TimestepEncoder(\n",
       "        (time_proj): Timesteps()\n",
       "        (timestep_embedder): TimestepEmbedding(\n",
       "          (linear_1): Linear(in_features=256, out_features=128, bias=True)\n",
       "          (act): SiLU()\n",
       "          (linear_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (transformer_blocks): ModuleList(\n",
       "        (0-1): 2 x BasicTransformerBlock(\n",
       "          (pos_embed): SinusoidalPositionalEmbedding()\n",
       "          (norm1): AdaLayerNorm(\n",
       "            (silu): SiLU()\n",
       "            (linear): Linear(in_features=128, out_features=256, bias=True)\n",
       "            (norm): LayerNorm((128,), eps=1e-05, elementwise_affine=False)\n",
       "          )\n",
       "          (attn1): Attention(\n",
       "            (to_q): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (to_k): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (to_v): Linear(in_features=128, out_features=128, bias=True)\n",
       "            (to_out): ModuleList(\n",
       "              (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "              (1): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (norm3): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (ff): FeedForward(\n",
       "            (net): ModuleList(\n",
       "              (0): GELU(\n",
       "                (proj): Linear(in_features=128, out_features=512, bias=True)\n",
       "              )\n",
       "              (1): Dropout(p=0.1, inplace=False)\n",
       "              (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "              (3): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (final_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (norm_out): LayerNorm((128,), eps=1e-06, elementwise_affine=False)\n",
       "      (proj_out_1): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (proj_out_2): Linear(in_features=128, out_features=128, bias=True)\n",
       "    )\n",
       "    (final_norm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "    (proj_1): Linear(in_features=128, out_features=256, bias=True)\n",
       "    (proj_2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (output): Linear(in_features=128, out_features=2, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class DecayLoss(nn.Module):\n",
    "    def __init__(self, num_steps, baseline_loss_fn=nn.L1Loss()):\n",
    "        super(DecayLoss, self).__init__()\n",
    "        # Weight decreases as we move further into the future\n",
    "        self.weights = torch.linspace(1.0, 1.0, num_steps)\n",
    "        self.baseline_loss_fn = baseline_loss_fn\n",
    "        \n",
    "\n",
    "    def forward(self, predictions, targets):\n",
    "        loss = 0\n",
    "        for i in range(predictions.shape[1]):\n",
    "            loss += self.weights[i] * self.baseline_loss_fn(predictions[:, i], targets[:, i])\n",
    "        return loss.mean()\n",
    "    \n",
    "    \n",
    "baseline_loss_fn = nn.L1Loss() #nn.MSELoss()\n",
    "loss_fn = DecayLoss(future_steps, baseline_loss_fn=baseline_loss_fn)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using {device}\")\n",
    "\n",
    "vqvae = VQVAE(input_dim=feature_dim, hidden_dim=512, num_embeddings=128, embedding_dim=128, commitment_cost=0.25)\n",
    "\n",
    "model = TemporalFusionTransformerDiffusion(num_features=feature_dim, num_hidden=128, num_outputs=2, num_steps=future_steps, diffusion_steps=1, vqvae=vqvae)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "model.to(device)\n",
    "\n",
    "# model.load_state_dict(torch.load(\"/home/shaoze/Documents/Prediction/Pedestrian-Trajectory-Prediction/model/TFT_Flowmatching_EDM/Jun08_22-42-14/best_model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trainer with early stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model at ../model/TFT_Flowmatching_EDM/Jun08_23-57-33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb97ef069334bf58cfad0b0e775937b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Step 500, Loss: 0.011959, VQ Loss: 0.004717, Diff Loss: 0.007242, learning rate: 5.00e-05\n",
      "Epoch 1, Step 1000, Loss: 0.006876, VQ Loss: 0.002490, Diff Loss: 0.004386, learning rate: 5.00e-05\n",
      "Epoch 1, Step 1500, Loss: 0.005620, VQ Loss: 0.001842, Diff Loss: 0.003778, learning rate: 5.00e-05\n",
      "Epoch 1, Step 2000, Loss: 0.005151, VQ Loss: 0.001533, Diff Loss: 0.003618, learning rate: 5.00e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "231ad6da2cce4f2a8b138a4fa0251701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Step 16, Loss: 0.004697, VQ Loss: 0.001322, Diff Loss: 0.003376, learning rate: 5.00e-05\n",
      "Epoch 2, Step 516, Loss: 0.004458, VQ Loss: 0.001167, Diff Loss: 0.003291, learning rate: 5.00e-05\n",
      "Epoch 2, Step 1016, Loss: 0.004453, VQ Loss: 0.001086, Diff Loss: 0.003367, learning rate: 5.00e-05\n",
      "Epoch 2, Step 1516, Loss: 0.003978, VQ Loss: 0.000972, Diff Loss: 0.003006, learning rate: 5.00e-05\n",
      "Epoch 2, Step 2016, Loss: 0.004053, VQ Loss: 0.000914, Diff Loss: 0.003139, learning rate: 5.00e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdbf9b57bc4141f49f3f4feecb8637a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3, Step 32, Loss: 0.003791, VQ Loss: 0.000846, Diff Loss: 0.002945, learning rate: 5.00e-05\n",
      "Steps 5000: test RMSE 1.1895, moving average RMSE 1.1895, learning rate 5.00e-05\n",
      "Epoch 3, Step 532, Loss: 0.003714, VQ Loss: 0.000819, Diff Loss: 0.002895, learning rate: 5.00e-05\n",
      "Epoch 3, Step 1032, Loss: 0.003660, VQ Loss: 0.000785, Diff Loss: 0.002875, learning rate: 5.00e-05\n",
      "Epoch 3, Step 1532, Loss: 0.003466, VQ Loss: 0.000731, Diff Loss: 0.002735, learning rate: 5.00e-05\n",
      "Epoch 3, Step 2032, Loss: 0.003503, VQ Loss: 0.000708, Diff Loss: 0.002794, learning rate: 5.00e-05\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d5cf7fb826c4a638647f87d85a74be3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2484 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4, Step 48, Loss: 0.003480, VQ Loss: 0.000686, Diff Loss: 0.002794, learning rate: 5.00e-05\n",
      "Epoch 4, Step 548, Loss: 0.003364, VQ Loss: 0.000660, Diff Loss: 0.002704, learning rate: 5.00e-05\n",
      "Epoch 4, Step 1048, Loss: 0.003411, VQ Loss: 0.000668, Diff Loss: 0.002743, learning rate: 5.00e-05\n",
      "Epoch 4, Step 1548, Loss: 0.003334, VQ Loss: 0.000632, Diff Loss: 0.002702, learning rate: 5.00e-05\n",
      "Epoch 4, Step 2048, Loss: 0.003333, VQ Loss: 0.000616, Diff Loss: 0.002718, learning rate: 5.00e-05\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "n_epochs = 4\n",
    "eval_step = 5000\n",
    "save_every = 10000\n",
    "patience = 8  # Number of evaluations to wait for improvement\n",
    "cooldown = 4  # Evaluations to wait after an improvement before counting non-improvements\n",
    "smooth_factor = 0.6  # Smoothing factor for moving average\n",
    "lambda_flow = 1e-3  # Weight for flow matching loss\n",
    "print_every = 500\n",
    "\n",
    "# Setup\n",
    "train_all = len(train)\n",
    "model_name = \"TFT_Flowmatching_EDM\"\n",
    "from collections import defaultdict\n",
    "loss_all = defaultdict(list)\n",
    "best_test_rmse = float('inf')\n",
    "early_stopping_counter = 0\n",
    "cooldown_counter = cooldown\n",
    "\n",
    "now = datetime.now()\n",
    "folder_name = now.strftime(\"%b%d_%H-%M-%S\")\n",
    "print(f\"Saving model at ../model/{model_name}/{folder_name}\")\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "# scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=min(len(train) * n_epochs, 100000), eta_min=1e-8)\n",
    "# Define scheduler: ReduceLROnPlateau\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',        # 'min' because we want to minimize loss\n",
    "    factor=0.2,        # Reduce LR by factor of 0.2 (i.e., lr / 5)\n",
    "    patience=3000,     # Number of steps with no significant improvement before reducing LR\n",
    "    threshold=5e-4,    # Minimum change in loss to qualify as \"significant\"\n",
    "    min_lr=1e-8,       # Minimum LR to stop at\n",
    "    verbose=True       # Prints a message when LR is reduced\n",
    ")\n",
    "\n",
    "os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "\n",
    "\n",
    "# Initialize moving average\n",
    "moving_avg_test_rmse = None\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    for step, (X_batch, y_batch) in tqdm(enumerate(train), total=train_all):\n",
    "        X_batch = X_batch.float().to(device)\n",
    "        y_batch = y_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_batch[:, :, :2] = X_batch[:, :, :2] - current_pos_input\n",
    "        y_batch[:, :, :2] = y_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "        # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "        # y_batch = y_batch[:, ::2, :2]\n",
    "        # X_batch = X_batch[:, ::2, :]\n",
    "\n",
    "        X_batch = F.pad(X_batch, (0, feature_dim - X_batch.shape[-1]))\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # y_pred, vq_loss, perplexity = model(X_batch, y_batch=y_batch)\n",
    "        # loss = loss_fn(y_pred[:, :future_steps, :2], y_batch[:, :future_steps, :2])\n",
    "        diff_loss, vq_loss = model(X_batch, y_batch[:, :future_steps, :2])\n",
    "\n",
    "\n",
    "        loss_all['diff_loss'].append(diff_loss.item())\n",
    "        loss_all['vq_loss'].append(vq_loss.item() * 10)\n",
    "        \n",
    "        loss_all['loss'].append(diff_loss.item() + vq_loss.item() * 10)\n",
    "        # add vq_loss\n",
    "        loss = diff_loss  + 10 * vq_loss\n",
    "\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step(loss.item())\n",
    "\n",
    "        if (epoch * train_all + step + 1) % print_every == 0:\n",
    "            loss_item = sum(loss_all['loss'][-100:]) / 100\n",
    "            vq_loss_item = sum(loss_all['vq_loss'][-100:]) / 100\n",
    "            diff_loss_item = sum(loss_all['diff_loss'][-100:]) / 100\n",
    "            print(f\"Epoch {epoch+1}, Step {step+1}, Loss: {loss_item:.6f}, VQ Loss: {vq_loss_item:.6f}, Diff Loss: {diff_loss_item:.6f}, learning rate: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "        \n",
    "        # Save model\n",
    "        if (epoch * train_all + step + 1) % save_every == 0:\n",
    "            os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "            save_path = f\"../model/{model_name}/{folder_name}/model_{epoch * train_all + step + 1}.pt\"\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            print(f\"Model saved at {save_path}\")\n",
    "\n",
    "        # Validation and early stopping\n",
    "        if (epoch * train_all + step + 1) % eval_step == 0:\n",
    "            model.eval()\n",
    "            test_rmse_all = []\n",
    "            with torch.no_grad():\n",
    "                for X_test_batch, y_test_batch in test:\n",
    "                    X_test_batch = X_test_batch.float().to(device)\n",
    "                    y_test_batch = y_test_batch.float().to(device)\n",
    "                    \n",
    "                    current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "                    current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "                    X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "                    y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "                    # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "                    # y_test_batch = y_test_batch[:, ::2, :2]\n",
    "                    # X_test_batch = X_test_batch[:, ::2, :]\n",
    "                    \n",
    "                    X_test_batch = F.pad(X_test_batch, (0, feature_dim - X_test_batch.shape[-1]))\n",
    "\n",
    "\n",
    "                    y_pred_test = model(X_test_batch, influence=True)\n",
    "                    loss_test = loss_fn(y_pred_test[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "                    test_rmse = torch.sqrt(loss_test)\n",
    "                    if not torch.isnan(test_rmse):\n",
    "                        test_rmse_all.append(test_rmse.item())\n",
    "            \n",
    "            current_rmse = sum(test_rmse_all) / len(test_rmse_all)\n",
    "            if moving_avg_test_rmse is None:\n",
    "                moving_avg_test_rmse = current_rmse\n",
    "            else:\n",
    "                moving_avg_test_rmse = smooth_factor * current_rmse + (1 - smooth_factor) * moving_avg_test_rmse\n",
    "\n",
    "            print(f\"Steps {epoch * train_all + step + 1}: test RMSE {current_rmse:.4f}, moving average RMSE {moving_avg_test_rmse:.4f}, learning rate {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "            # Check if the moving average RMSE is better; if not, increment counter\n",
    "            if moving_avg_test_rmse < best_test_rmse:\n",
    "                best_test_rmse = moving_avg_test_rmse\n",
    "                early_stopping_counter = 0  # Reset counter\n",
    "                cooldown_counter = cooldown  # Reset cooldown\n",
    "                # Optionally save the best model\n",
    "                os.makedirs(f'../model/{model_name}/{folder_name}', exist_ok=True)\n",
    "                best_model_path = f\"../model/{model_name}/{folder_name}/best_model.pt\"\n",
    "                torch.save(model.state_dict(), best_model_path)\n",
    "            else:\n",
    "                if cooldown_counter > 0:\n",
    "                    cooldown_counter -= 1\n",
    "                else:\n",
    "                    early_stopping_counter += 1\n",
    "\n",
    "            if early_stopping_counter >= patience:\n",
    "                print(f\"Stopping early at epoch {epoch+1}, step {step+1}\")\n",
    "                break\n",
    "\n",
    "            model.train()\n",
    "        \n",
    "    if early_stopping_counter >= patience:\n",
    "        break\n",
    "\n",
    "print(\"Training complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f479b87f52d4f6dafac480504cc168d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/138 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 1.0986585262892903\n"
     ]
    }
   ],
   "source": [
    "validation_step = future_steps\n",
    "\n",
    "predictions = []\n",
    "truths = []\n",
    "\n",
    "max_test_batch = 200\n",
    "cur_test = 0\n",
    "\n",
    "test_loss_all = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    all_test = len(test)\n",
    "    test_rmse_all = []\n",
    "    for X_test_batch, y_test_batch in tqdm(test):\n",
    "        cur_test += 1\n",
    "        if cur_test > max_test_batch:\n",
    "            break\n",
    "\n",
    "        X_test_batch = X_test_batch.float().to(device)\n",
    "        y_test_batch = y_test_batch.float().to(device)\n",
    "        \n",
    "        current_pos_input = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "        current_pos_output = X_test_batch[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1)\n",
    "        X_test_batch[:, :, :2] = X_test_batch[:, :, :2] - current_pos_input\n",
    "        y_test_batch[:, :, :2] = y_test_batch[:, :, :2] - current_pos_output\n",
    "\n",
    "        X_test_batch = F.pad(X_test_batch, (0, feature_dim - X_test_batch.shape[-1]))\n",
    "\n",
    "\n",
    "        # # only take 0, 2, 4, 6, 8, 10, 12, 14, 16, 18\n",
    "        # y_test_batch = y_test_batch[:, ::2, :2]\n",
    "        # X_test_batch = X_test_batch[:, ::2, :]\n",
    "        \n",
    "        y_preds = model(X_test_batch, influence=True, return_all=True)\n",
    "        # slect the one with minimum loss\n",
    "\n",
    "        min_loss = float('inf')\n",
    "        best_pred = None\n",
    "        for y_pred in y_preds:\n",
    "            loss_test = loss_fn(y_pred[:, :future_steps, :2], y_test_batch[:, :future_steps, :2])\n",
    "            test_rmse = torch.sqrt(loss_test)\n",
    "            if test_rmse < min_loss:\n",
    "                min_loss = test_rmse\n",
    "                best_pred = y_pred\n",
    "        \n",
    "        test_loss_all.append(min_loss.item())\n",
    "\n",
    "        predictions.append(y_pred[:, :validation_step, :2] + current_pos_output[:, :y_pred.shape[1], :2])\n",
    "        truths.append(y_test_batch[:, :validation_step, :2] + current_pos_output[:, :y_pred.shape[1], :2])\n",
    "\n",
    "\n",
    "print(f\"Test RMSE: {sum(test_loss_all) / len(test_loss_all)}\")       \n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "truths = torch.cat(truths, dim=0)\n",
    "\n",
    "# reverse normalization\n",
    "normalize_dict = stats_dict\n",
    "\n",
    "for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "    truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Assume predictions and truths are torch tensors of shape (batch_size, num_steps, num_dims)\n",
    "# # Also assume model_name and folder_name are defined strings for saving the plot.\n",
    "# criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "# steps = []\n",
    "# ade_loss = []\n",
    "# fde_loss = []\n",
    "\n",
    "# # Loop over each prediction horizon (step)\n",
    "# for step in range(1, predictions.size(1) + 1):\n",
    "#     # Compute MSE loss for the first 'step' timesteps for all samples\n",
    "#     raw_loss = criterion(predictions[:, :step, :], truths[:, :step, :])\n",
    "#     # Sum loss over the coordinate dimension and take square root to get RMSE per timestep per sample\n",
    "#     raw_rmse = torch.sqrt(torch.sum(raw_loss, dim=-1))\n",
    "    \n",
    "#     # ADE: average RMSE over all time steps for each sample\n",
    "#     current_ade = raw_rmse.mean(dim=-1)\n",
    "#     # FDE: RMSE error at the final timestep for each sample\n",
    "#     current_fde = raw_rmse[:, -1]  # Alternatively, use: raw_rmse.max(dim=-1).values\n",
    "    \n",
    "#     ade_loss.append(current_ade)\n",
    "#     fde_loss.append(current_fde)\n",
    "#     steps.extend([step] * len(current_ade))\n",
    "\n",
    "# # Concatenate results across all steps and move to CPU numpy arrays\n",
    "# ade_loss = torch.cat(ade_loss).cpu().numpy()\n",
    "# fde_loss = torch.cat(fde_loss).cpu().numpy()\n",
    "\n",
    "# # Create DataFrames for ADE and FDE\n",
    "# df_ade = pd.DataFrame({'Step': steps, 'Loss': ade_loss, 'Metric': 'ADE'})\n",
    "# df_fde = pd.DataFrame({'Step': steps, 'Loss': fde_loss, 'Metric': 'FDE'})\n",
    "\n",
    "# # Combine both DataFrames\n",
    "# df = pd.concat([df_ade, df_fde], ignore_index=True)\n",
    "\n",
    "# # Convert step count to seconds and scale the RMSE error to meters\n",
    "# df['Second (s)'] = df['Step'] / 10   # For example, if 5 steps equal 1 second\n",
    "# df['RMSE Error (m)'] = df['Loss'] / 100  # Convert error to meters\n",
    "\n",
    "# # Plot the ADE and FDE curves using seaborn\n",
    "# sns.lineplot(data=df, x='Second (s)', y='RMSE Error (m)', hue='Metric')\n",
    "# plt.title(\"Trajectory Prediction Error: ADE vs FDE\")\n",
    "# plt.xlabel(\"Time (s)\")\n",
    "# plt.ylabel(\"RMSE Error (m)\")\n",
    "# # plt.savefig(f'../model/{model_name}/{folder_name}/res.png')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "criterion = nn.MSELoss(reduction=\"none\")\n",
    "\n",
    "steps = []\n",
    "loss = []\n",
    "max_loss = []\n",
    "for step in range(1, predictions.size(1) + 1):\n",
    "    raw_rmse_loss = criterion(predictions[:, :step, :], truths[:, :step, :])\n",
    "    raw_rmse_loss = torch.sqrt(torch.sum(raw_rmse_loss, dim=-1))\n",
    "    mean_rmse_loss = raw_rmse_loss.mean(dim=-1)\n",
    "    max_rmse_loss = raw_rmse_loss.max(dim=-1).values\n",
    "    loss.append(mean_rmse_loss)\n",
    "    max_loss.append(max_rmse_loss)\n",
    "    steps.extend([step] * len(mean_rmse_loss))\n",
    "    \n",
    "max_loss = torch.cat(max_loss).cpu().numpy()\n",
    "loss = torch.cat(loss).cpu().numpy()\n",
    "\n",
    "df = pd.DataFrame({'Second (s)': steps, 'loss': loss})\n",
    "df1 = pd.DataFrame({'Second (s)': steps, 'loss': max_loss})\n",
    "df['type'] = 'mean'\n",
    "df1['type'] = 'max'\n",
    "df = pd.concat([df, df1])\n",
    "\n",
    "\n",
    "df['RMSE Error (m)'] = df['loss'] / 100 # to meters\n",
    "df['Second (s)'] = df['Second (s)'] / 10 # to seconds\n",
    "sns.lineplot(data = df, x='Second (s)', y='RMSE Error (m)', hue='type',) #  errorbar=('sd', 1),\n",
    "plt.savefig(f'../model/{model_name}/{folder_name}/res.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize\n",
    "\n",
    "time_stamp = 25599\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "pred = predictions[time_stamp, :, :].cpu().numpy()\n",
    "truth = truths[time_stamp, :, :].cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# equal axis\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "ax.plot(pred[:, 0], pred[:, 1], color='blue', label='Predicted Trajectory')\n",
    "ax.plot(truth[:, 0], truth[:, 1], color='red', label='Ground Truth Trajectory')\n",
    "ax.set_xlabel('X Coordinate')\n",
    "ax.set_ylabel('Y Coordinate')\n",
    "ax.set_title('Predicted vs Ground Truth Trajectory')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>type</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Second (s)</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.1</th>\n",
       "      <td>0.309250</td>\n",
       "      <td>0.309250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.2</th>\n",
       "      <td>0.412005</td>\n",
       "      <td>0.318500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.3</th>\n",
       "      <td>0.478484</td>\n",
       "      <td>0.328508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.4</th>\n",
       "      <td>0.530038</td>\n",
       "      <td>0.338647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.5</th>\n",
       "      <td>0.573530</td>\n",
       "      <td>0.349218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.6</th>\n",
       "      <td>0.613160</td>\n",
       "      <td>0.360200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.7</th>\n",
       "      <td>0.650252</td>\n",
       "      <td>0.371428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.8</th>\n",
       "      <td>0.684237</td>\n",
       "      <td>0.382608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0.9</th>\n",
       "      <td>0.717390</td>\n",
       "      <td>0.393968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.748565</td>\n",
       "      <td>0.405438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.1</th>\n",
       "      <td>0.779645</td>\n",
       "      <td>0.416925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.2</th>\n",
       "      <td>0.809259</td>\n",
       "      <td>0.428403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.3</th>\n",
       "      <td>0.838818</td>\n",
       "      <td>0.440124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.4</th>\n",
       "      <td>0.866316</td>\n",
       "      <td>0.451620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.5</th>\n",
       "      <td>0.892222</td>\n",
       "      <td>0.462898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.6</th>\n",
       "      <td>0.917373</td>\n",
       "      <td>0.474045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.7</th>\n",
       "      <td>0.941082</td>\n",
       "      <td>0.484980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.8</th>\n",
       "      <td>0.965436</td>\n",
       "      <td>0.495888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.9</th>\n",
       "      <td>0.989496</td>\n",
       "      <td>0.506672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1.014044</td>\n",
       "      <td>0.517463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.1</th>\n",
       "      <td>1.037849</td>\n",
       "      <td>0.528277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.2</th>\n",
       "      <td>1.061466</td>\n",
       "      <td>0.539008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.3</th>\n",
       "      <td>1.084506</td>\n",
       "      <td>0.549649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.4</th>\n",
       "      <td>1.106734</td>\n",
       "      <td>0.560176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.5</th>\n",
       "      <td>1.129703</td>\n",
       "      <td>0.570659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.6</th>\n",
       "      <td>1.152417</td>\n",
       "      <td>0.581159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.7</th>\n",
       "      <td>1.175226</td>\n",
       "      <td>0.591677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.8</th>\n",
       "      <td>1.197460</td>\n",
       "      <td>0.602135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.9</th>\n",
       "      <td>1.220177</td>\n",
       "      <td>0.612541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1.242283</td>\n",
       "      <td>0.622895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.1</th>\n",
       "      <td>1.265189</td>\n",
       "      <td>0.633269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.2</th>\n",
       "      <td>1.288420</td>\n",
       "      <td>0.643655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.3</th>\n",
       "      <td>1.311467</td>\n",
       "      <td>0.654066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.4</th>\n",
       "      <td>1.333956</td>\n",
       "      <td>0.664413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.5</th>\n",
       "      <td>1.356983</td>\n",
       "      <td>0.674736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.6</th>\n",
       "      <td>1.380419</td>\n",
       "      <td>0.685049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.7</th>\n",
       "      <td>1.403955</td>\n",
       "      <td>0.695390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.8</th>\n",
       "      <td>1.428045</td>\n",
       "      <td>0.705812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.9</th>\n",
       "      <td>1.452107</td>\n",
       "      <td>0.716211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>1.476596</td>\n",
       "      <td>0.726654</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "type             max      mean\n",
       "Second (s)                    \n",
       "0.1         0.309250  0.309250\n",
       "0.2         0.412005  0.318500\n",
       "0.3         0.478484  0.328508\n",
       "0.4         0.530038  0.338647\n",
       "0.5         0.573530  0.349218\n",
       "0.6         0.613160  0.360200\n",
       "0.7         0.650252  0.371428\n",
       "0.8         0.684237  0.382608\n",
       "0.9         0.717390  0.393968\n",
       "1.0         0.748565  0.405438\n",
       "1.1         0.779645  0.416925\n",
       "1.2         0.809259  0.428403\n",
       "1.3         0.838818  0.440124\n",
       "1.4         0.866316  0.451620\n",
       "1.5         0.892222  0.462898\n",
       "1.6         0.917373  0.474045\n",
       "1.7         0.941082  0.484980\n",
       "1.8         0.965436  0.495888\n",
       "1.9         0.989496  0.506672\n",
       "2.0         1.014044  0.517463\n",
       "2.1         1.037849  0.528277\n",
       "2.2         1.061466  0.539008\n",
       "2.3         1.084506  0.549649\n",
       "2.4         1.106734  0.560176\n",
       "2.5         1.129703  0.570659\n",
       "2.6         1.152417  0.581159\n",
       "2.7         1.175226  0.591677\n",
       "2.8         1.197460  0.602135\n",
       "2.9         1.220177  0.612541\n",
       "3.0         1.242283  0.622895\n",
       "3.1         1.265189  0.633269\n",
       "3.2         1.288420  0.643655\n",
       "3.3         1.311467  0.654066\n",
       "3.4         1.333956  0.664413\n",
       "3.5         1.356983  0.674736\n",
       "3.6         1.380419  0.685049\n",
       "3.7         1.403955  0.695390\n",
       "3.8         1.428045  0.705812\n",
       "3.9         1.452107  0.716211\n",
       "4.0         1.476596  0.726654"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_results = df.groupby(by=['Second (s)', 'type']).mean().unstack()['RMSE Error (m)']\n",
    "exp_results.to_csv(f'../model/{model_name}/{folder_name}/result.csv')\n",
    "exp_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export JIT Model\n",
    "\n",
    "Integrate partial of data processing into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EXPORT_MODEL = True\n",
    "\n",
    "# # # model.load_state_dict(torch.load(\"/home/shaoze/Documents/Boeing/Boeing-Trajectory-Prediction/model/Jul09_20-37-37/model_40000.pt\"))\n",
    "# # if EXPORT_MODEL:\n",
    "# #     model.eval()\n",
    "# #     model.to('cpu')\n",
    "# #     script_module = torch.jit.script(model)\n",
    "# #     os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# #     script_module.save(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# stats = {}\n",
    "# '''\n",
    "# mean: tensor[]\n",
    "# '''\n",
    "\n",
    "# for keys, values in stats_dict.items():\n",
    "#     stats[keys] = torch.tensor(values.to_list()).view(1,1,-1)\n",
    "    \n",
    "# class TFT_EXP(nn.Module):\n",
    "#     def __init__(self, model:EnhancedTFT, stats:dict):\n",
    "#         super(TFT_EXP, self).__init__()\n",
    "#         self.stats = stats\n",
    "#         self.register_buffer('mean', self.stats['mean'])\n",
    "#         self.register_buffer('std', self.stats['std'])\n",
    "#         self.register_buffer('min', self.stats['min'])\n",
    "#         self.register_buffer('max', self.stats['max'])\n",
    "#         self.TFT = model\n",
    "#         self.num_steps = model.num_steps\n",
    "#         self.num_outputs = model.num_outputs # =2\n",
    "\n",
    "#     def forward(self, x, mask: Optional[torch.Tensor]=None):\n",
    "#         single = False\n",
    "#         if len(x.shape) == 2:\n",
    "#             x = x.unsqueeze(0)\n",
    "#             single = True\n",
    "        \n",
    "#         # normalize\n",
    "#         x = (x - self.mean) / self.std\n",
    "#         x = (x - self.min) / (self.max - self.min)\n",
    "#         # residual\n",
    "#         current_pos_input = x[:, -1, :2].clone().unsqueeze(1).repeat(1, x.shape[1], 1)\n",
    "#         current_pos_output = x[:, -1, :2].clone().unsqueeze(1).repeat(1, self.num_steps, 1)\n",
    "#         x[:, :, :2] = x[:, :, :2] - current_pos_input\n",
    "        \n",
    "#         # pass through TFT\n",
    "#         outputs, vq_loss, perplexity = self.TFT(x, mask)\n",
    "#         outputs = outputs.detach()\n",
    "        \n",
    "#         # de-residual\n",
    "#         outputs[:, :, :2] = outputs[:, :, :2] + current_pos_output\n",
    "        \n",
    "#         # denormalize\n",
    "#         outputs = outputs * (self.max[:,:,:self.num_outputs] - self.min[:,:,:self.num_outputs]) + self.min[:,:,:self.num_outputs]\n",
    "#         outputs = outputs * self.std[:,:,:self.num_outputs] + self.mean[:,:,:self.num_outputs]\n",
    "        \n",
    "#         if single:\n",
    "#             outputs = outputs.squeeze(0)\n",
    "#         return outputs\n",
    "\n",
    "# tft_exp = TFT_EXP(model, stats)\n",
    "# tft_exp.to('cpu')\n",
    "# tft_exp.eval()\n",
    "# # script_module = torch.jit.script(tft_exp)\n",
    "# # os.makedirs(f'../model/exported/', exist_ok=True)\n",
    "# # script_module.save(\"../exported/model_tft_vqvae_cpu_preproc.pt\")\n",
    "\n",
    "# # export to onnx\n",
    "\n",
    "# dummy_input = torch.randn(1, lookback, feature_dim)\n",
    "# print(f\"Input shape: {dummy_input.shape}\")\n",
    "\n",
    "# # Export the wrapped model to ONNX format\n",
    "# torch.onnx.export(\n",
    "#     tft_exp,                   # Wrapped model to export\n",
    "#     dummy_input,                     # Model input\n",
    "#     \"../exported/tft_1111.onnx\",              # Output file name\n",
    "#     export_params=True,              # Store the trained parameter weights inside the model file\n",
    "#     opset_version=13,                # Set the ONNX opset version (adjust as needed)\n",
    "#     do_constant_folding=True,        # Whether to execute constant folding for optimization\n",
    "#     input_names=['input'],           # The model's input names\n",
    "#     output_names=['output'],         # The model's output names\n",
    "#     # dynamic_axes={\n",
    "#     #     'input': {0: 'batch_size'},  # Dynamic batch_size and sequence_length\n",
    "#     #     'output': {0: 'batch_size'}  # Dynamic batch_size for the output\n",
    "#     # }\n",
    "# )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import onnxruntime as ort\n",
    "# import numpy as np\n",
    "\n",
    "# # Path to your ONNX model\n",
    "# model_path = \"../exported/tft_1111.onnx\"\n",
    "\n",
    "# # Create an inference session\n",
    "# session = ort.InferenceSession(model_path)\n",
    "\n",
    "# # Get the name of the input node\n",
    "# input_name = session.get_inputs()[0].name\n",
    "\n",
    "# for file in os.listdir(dir):\n",
    "#     if file.endswith('.pkl'):\n",
    "#         df = process_data(dir+file)\n",
    "#     break\n",
    "\n",
    "# df = df[['User_X', 'User_Y', 'AGV_distance_X', 'AGV_distance_Y', 'AGV_speed_X',\n",
    "#        'AGV_speed_Y', 'AGV_speed', 'User_speed_X', 'User_speed_Y',\n",
    "#        'User_speed', 'User_velocity_X', 'User_velocity_Y', 'Wait_time',\n",
    "#        'intent_to_cross', 'Gazing_station', 'possible_interaction',\n",
    "#        'facing_along_sidewalk', 'facing_to_road', 'On_sidewalks', 'On_road',\n",
    "#        'closest_station', 'distance_to_closest_station',\n",
    "#        'distance_to_closest_station_X', 'distance_to_closest_station_Y',\n",
    "#        'looking_at_AGV', 'GazeDirection_X', 'GazeDirection_Y',\n",
    "#        'GazeDirection_Z', 'AGV_X', 'AGV_Y',\n",
    "#        'looking_at_closest_station']]\n",
    "\n",
    "# start_idx = 100\n",
    "# input = df.iloc[200:200+lookback].astype(np.float32).values\n",
    "\n",
    "# # add batch\n",
    "# input = input[np.newaxis, :, :]\n",
    "# # Run the model\n",
    "# output = session.run(None, {input_name: input.astype(np.float32)})[0]\n",
    "\n",
    "# output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data (for interactive visualization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = torch.jit.load(\"../exported/model_tft_vqvae_cpu.pt\")\n",
    "\n",
    "# test_ds = MyDataset(lookback=lookback)\n",
    "# all_ds = ds.dataset\n",
    "# test_ds.dataset = all_ds[len(all_ds)//10 :] # load the last 10% of the data\n",
    "# X_list, y_list = test_ds.generate_data(return_list=True, future_steps=future_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "\n",
    "# normalize_dict = stats_dict\n",
    "# pred_data = []\n",
    "# truth_data = []\n",
    "# input_data = []\n",
    "# model.eval()\n",
    "# device = 'cpu'\n",
    "# for i, (X, y) in enumerate(zip(X_list, y_list)):\n",
    "#     current_pos_input = X[:, -1, :2].clone().unsqueeze(1).repeat(1, lookback, 1)\n",
    "#     current_pos_output = X[:, -1, :2].clone().unsqueeze(1).repeat(1, future_steps, 1).to(device)\n",
    "#     X[:, :, :2] = X[:, :, :2] - current_pos_input\n",
    "\n",
    "#     predictions = model(X.float().to(device))[0][:, :future_steps, :2]\n",
    "#     predictions = predictions + current_pos_output\n",
    "#     predictions = predictions.to('cpu')\n",
    "    \n",
    "#     truths = y[:, :future_steps, :2]\n",
    "#     X[:, :, :2] = X[:, :, :2] + current_pos_input\n",
    "#     model_input = X.float().to(device)[:, :lookback, :2]\n",
    "#     trajectory_id = i\n",
    "    \n",
    "#     # reverse normalization\n",
    "#     for idx, key_ in enumerate([\"User_X\", \"User_Y\"]):\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         predictions[:, :, idx] = predictions[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         truths[:, :, idx] = truths[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * (normalize_dict['max'][key_] - normalize_dict['min'][key_]) + normalize_dict['min'][key_]\n",
    "#         model_input[:, :, idx] = model_input[:, :, idx] * normalize_dict['std'][key_] + normalize_dict['mean'][key_]\n",
    "    \n",
    "#     for group_id in range(predictions.shape[0]):\n",
    "#         for time_step in range(predictions.shape[1]):\n",
    "#             pred_x, pred_y = predictions[group_id, time_step]\n",
    "#             pred_data.append([trajectory_id, group_id, time_step, pred_x.item(), pred_y.item()])\n",
    "\n",
    "#             truth_x, truth_y = truths[group_id, time_step]\n",
    "#             truth_data.append([trajectory_id, group_id, time_step, truth_x.item(), truth_y.item()])\n",
    "        \n",
    "#         for time_step in range(lookback):\n",
    "#             input_x, input_y = model_input[group_id, time_step]\n",
    "#             input_data.append([trajectory_id, group_id, time_step, input_x.item(), input_y.item()])\n",
    "            \n",
    "\n",
    "# pred_df = pd.DataFrame(pred_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# truth_df = pd.DataFrame(truth_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n",
    "# input_df = pd.DataFrame(input_data, columns=['trajectory_id', 'Group_ID', 'Time_Step', 'X', 'Y'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# files_to_remove = [\n",
    "#     \"../data/pred_tra_all.pkl\",\n",
    "#     \"../data/truth_tra_all.pkl\", \n",
    "#     \"../data/input_tra_all.pkl\"\n",
    "# ]\n",
    "\n",
    "# for file_path in files_to_remove:\n",
    "#     if os.path.exists(file_path):\n",
    "#         os.remove(file_path)\n",
    "\n",
    "# truth_df.to_pickle(\"../data/truth_tra_all.pkl\")\n",
    "# pred_df.to_pickle(\"../data/pred_tra_all.pkl\")\n",
    "# input_df.to_pickle(\"../data/input_tra_all.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
